{
    "subreddit_info": {
        "name": "StableDiffusion",
        "title": "StableDiffusion",
        "subscribers": 578255,
        "public_description": "/r/StableDiffusion is an unofficial community embracing the open-source material of all related. Post art, ask questions, create discussions, contribute new tech, or browse the subreddit. It’s up to you."
    },
    "posts": [
        {
            "id": "1gshg95",
            "title": "Help for Lora Trainer by Hollowstrawberry",
            "author": "Rhodostannite",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731739092.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gshg95/help_for_lora_trainer_by_hollowstrawberry/",
            "permalink": "/r/StableDiffusion/comments/1gshg95/help_for_lora_trainer_by_hollowstrawberry/",
            "selftext": "I made my first Lora with that useful guide. I am a total ignorant... Is it possible to change the training model (eg Pony)? There is a field called optional custom training model url. Well, what is the URL of a model? Which file i have to point at? ",
            "comments": [
                {
                    "id": "lxecnja",
                    "author": "Relevant_One_2261",
                    "body": "> Which file i have to point at?\n\nThe checkpoint, .safetensors.\n\nIIRC you could use CivitAi links as long as you include your API token in the URL, but (public) HF links work as is.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731740111.0,
                    "parent_id": "t3_1gshg95",
                    "link_id": "t3_1gshg95",
                    "permalink": "/r/StableDiffusion/comments/1gshg95/help_for_lora_trainer_by_hollowstrawberry/lxecnja/"
                },
                {
                    "id": "lxef0e1",
                    "author": "Rhodostannite",
                    "body": "For example, this?\nhttps://civitai.com/api/download/models/1006775?type=Model&format=SafeTensor&size=full&fp=fp8\n\n\nWhere I put the API token? \nForgive me but for me it's Greek.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731741529.0,
                    "parent_id": "t1_lxecnja",
                    "link_id": "t3_1gshg95",
                    "permalink": "/r/StableDiffusion/comments/1gshg95/help_for_lora_trainer_by_hollowstrawberry/lxef0e1/"
                }
            ]
        },
        {
            "id": "1gsggeb",
            "title": "Have you ever heard of the Shirime?",
            "author": "Otherwise-Ad-2073",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731735392.0,
            "url": "https://v.redd.it/e822214ca71e1",
            "permalink": "/r/StableDiffusion/comments/1gsggeb/have_you_ever_heard_of_the_shirime/",
            "selftext": "",
            "comments": [
                {
                    "id": "lxeajzo",
                    "author": "xmattar",
                    "body": "https://preview.redd.it/y7we7kqwk71e1.png?width=1080&format=pjpg&auto=webp&s=d2758fc5f666b41a448e9e09bac89506e3302c70",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731738920.0,
                    "parent_id": "t3_1gsggeb",
                    "link_id": "t3_1gsggeb",
                    "permalink": "/r/StableDiffusion/comments/1gsggeb/have_you_ever_heard_of_the_shirime/lxeajzo/"
                },
                {
                    "id": "lxe93h8",
                    "author": "None",
                    "body": "[removed]",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731738130.0,
                    "parent_id": "t3_1gsggeb",
                    "link_id": "t3_1gsggeb",
                    "permalink": "/r/StableDiffusion/comments/1gsggeb/have_you_ever_heard_of_the_shirime/lxe93h8/"
                },
                {
                    "id": "lxea0g0",
                    "author": "StableDiffusion-ModTeam",
                    "body": "If you are not going to include a workflow and discuss how you created the images you posted, then please post them - videos, single images alone, or multiple images in a group/slide show format - that you wish to share with the community in our [Weekly Showcase thread](https://www.reddit.com/r/stablediffusion/about/sticky) instead of any other sort of post.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731738622.0,
                    "parent_id": "t1_lxe93h8",
                    "link_id": "t3_1gsggeb",
                    "permalink": "/r/StableDiffusion/comments/1gsggeb/have_you_ever_heard_of_the_shirime/lxea0g0/"
                }
            ]
        },
        {
            "id": "1gsg3fa",
            "title": "Filtered words and alternatives",
            "author": "ababana97653",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731733835.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsg3fa/filtered_words_and_alternatives/",
            "permalink": "/r/StableDiffusion/comments/1gsg3fa/filtered_words_and_alternatives/",
            "selftext": "I am trying to make a drawing style image of a rat holding a bazoka that looks like a dildo. I’m not going for realism. \n\nRats and bazoka, no problem. But I can’t get the bazoka looking like a dildo or generally make it look phallic. \n\nI presume phallic and dildos have been excluded from the training data set?",
            "comments": [
                {
                    "id": "lxe1x8p",
                    "author": "Enshitification",
                    "body": "![gif](giphy|k5zlrQQEptX7BmNAlh|downsized)",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731734558.0,
                    "parent_id": "t3_1gsg3fa",
                    "link_id": "t3_1gsg3fa",
                    "permalink": "/r/StableDiffusion/comments/1gsg3fa/filtered_words_and_alternatives/lxe1x8p/"
                },
                {
                    "id": "lxe1t1o",
                    "author": "HellkerN",
                    "body": "Try a different model, something Pony based maybe, those usually have more knowledge about stuff like that.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731734495.0,
                    "parent_id": "t3_1gsg3fa",
                    "link_id": "t3_1gsg3fa",
                    "permalink": "/r/StableDiffusion/comments/1gsg3fa/filtered_words_and_alternatives/lxe1t1o/"
                },
                {
                    "id": "lxe7sth",
                    "author": "Gyramuur",
                    "body": "Pony is definitely not going to gen the rat just holding the bazooka, lmao",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731737464.0,
                    "parent_id": "t1_lxe1t1o",
                    "link_id": "t3_1gsg3fa",
                    "permalink": "/r/StableDiffusion/comments/1gsg3fa/filtered_words_and_alternatives/lxe7sth/"
                }
            ]
        },
        {
            "id": "1gsey1n",
            "title": "How can I use three loras at once? Any workflows?",
            "author": "learning-machine1964",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 14,
            "created_utc": 1731729516.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/",
            "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/",
            "selftext": "I have one lora which is for generating a consistent character. The other is for generating a realistic image. The last one is for erm... not work stuff for sure but that's unrelated. Is there a workflow I could use to do this? I'm currently able to use the first two at once without a workflow but if I add in the third one there's significant distortions. ",
            "comments": [
                {
                    "id": "lxdrhnj",
                    "author": "SteamZerjack",
                    "body": "That just means the third one is busted. Or supposed to go with another model. Loras don’t always play nice between each other.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731729711.0,
                    "parent_id": "t3_1gsey1n",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdrhnj/"
                },
                {
                    "id": "lxdrex7",
                    "author": "Jazzlike_Top3702",
                    "body": "using Comfy?  There is a stacker node for layering them up.  it can take some tweaking of proportions to get right.  Lora weight, and clip weight for each.  Also, time step control over application.  Throwing a control net in there can alter behaviour a lot as well.  Sometimes for the better, even if it is a small amount of control.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729678.0,
                    "parent_id": "t3_1gsey1n",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdrex7/"
                },
                {
                    "id": "lxebch2",
                    "author": "pomonews",
                    "body": "I got consistent characters by putting the same very detailed description of their clothes, hair and age in each prompt and then doing a faceswap, depending on the objective it works. Then used a lora to apply the style.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731739371.0,
                    "parent_id": "t3_1gsey1n",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxebch2/"
                },
                {
                    "id": "lxds1p7",
                    "author": "learning-machine1964",
                    "body": "im not sure if I'm even doing it properly. I'm just using [https://replicate.com/lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) and included all 3 models. With 2 models it was kinda working.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729957.0,
                    "parent_id": "t1_lxdrhnj",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxds1p7/"
                },
                {
                    "id": "lxdrxxf",
                    "author": "learning-machine1964",
                    "body": "How do u learn all this stuff? I have no clue how to work with comfy UI tbh. Is there a workflow I can follow?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731729910.0,
                    "parent_id": "t1_lxdrex7",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdrxxf/"
                },
                {
                    "id": "lxdt10v",
                    "author": "SteamZerjack",
                    "body": "Ah, you’re using flux? Yeah can’t help you there. Much less online. I know however that loras are picky and you can’t always make them work combined with others.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730393.0,
                    "parent_id": "t1_lxds1p7",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdt10v/"
                },
                {
                    "id": "lxdtaav",
                    "author": "SteamZerjack",
                    "body": "Comfy is local. You need a kinda beefy computer.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731730502.0,
                    "parent_id": "t1_lxdrxxf",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdtaav/"
                },
                {
                    "id": "lxdubui",
                    "author": "Jazzlike_Top3702",
                    "body": "https://preview.redd.it/0arshx6aw61e1.png?width=1440&format=png&auto=webp&s=5dd0530f9b6ced1e48891d5d988f6cdf7c4958e9\n\nThis generation used about 4 LoRas I think - I can't remember.  just a lot of time fiddling around with values.  You can get radically different results with a LorA stacker when you have 5-6 LoRas layered up.  Tweak some of the values up and down by 0.1 or 0.2.  Some combinations are trash, others are fantastic.  Basically, just generate images, tweak some values.  If the tweaked values produce a 'better' image, you're moving them in the right direction.  Good to generate at least 4 at once to avoid weird random results, or just stick to a fixed seed to nail a very nice set of values for the stack.  The above image is a combination of a character LoRa, plus a style LoRa, along with some face detailing - I think it was a 50/50 blend of two people? I forget.  It is also possible to blend checkpoints, so you can smush them together as well.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730945.0,
                    "parent_id": "t1_lxdrxxf",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdubui/"
                },
                {
                    "id": "lxds4eo",
                    "author": "_kitmeng",
                    "body": "Liblib.art",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731729990.0,
                    "parent_id": "t1_lxdrxxf",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxds4eo/"
                },
                {
                    "id": "lxdtic4",
                    "author": "learning-machine1964",
                    "body": "I can run it on dedicated GPU servers through cloud I think",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730592.0,
                    "parent_id": "t1_lxdtaav",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdtic4/"
                },
                {
                    "id": "lxduwx1",
                    "author": "learning-machine1964",
                    "body": "I haven't worked with comfy UI before. Do u have a workflow u would recommend to generate images with multiple loras?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731193.0,
                    "parent_id": "t1_lxdubui",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxduwx1/"
                },
                {
                    "id": "lxefvta",
                    "author": "RASTAGAMER420",
                    "body": "Yes you can. I think Rundiffusion has a nice setup that's not as complicated as runpod, haven't used it myself tho. Anyway as for learning there might be some decent stuff on youtube if you find the right channel. Ferniclestix has some great stuff, his videos aren't as polished and \"content\" as other channels but the knowledge is there, and Latent Vision has a lot of great stuff about using IPA as well. But what I learned the most from was just looking through the manager for node packs and just messing around pressing buttons until I figured out what they do",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731742081.0,
                    "parent_id": "t1_lxdtic4",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxefvta/"
                },
                {
                    "id": "lxdwwnd",
                    "author": "Jazzlike_Top3702",
                    "body": "i can make you one.  this is the basic idea here.  I've got two loras loaded in here.  One for a 70's style horror film look.  and another for the actress Mathilda May - happened to be an alien vampire in a 70's horror movie  :)   \n\nedit: looking this up, I find that Lifeforce was made in 1985.  My mistake.\n\nhttps://preview.redd.it/z8adtcug071e1.png?width=1851&format=png&auto=webp&s=817b25b79f8cfec025bd472f68c0cb211d816454",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731732046.0,
                    "parent_id": "t1_lxduwx1",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdwwnd/"
                },
                {
                    "id": "lxdz3fg",
                    "author": "learning-machine1964",
                    "body": "thanks!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733052.0,
                    "parent_id": "t1_lxdwwnd",
                    "link_id": "t3_1gsey1n",
                    "permalink": "/r/StableDiffusion/comments/1gsey1n/how_can_i_use_three_loras_at_once_any_workflows/lxdz3fg/"
                }
            ]
        },
        {
            "id": "1gse3ln",
            "title": "SD crashing",
            "author": "fliberdygibits",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731726652.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gse3ln/sd_crashing/",
            "permalink": "/r/StableDiffusion/comments/1gse3ln/sd_crashing/",
            "selftext": "https://preview.redd.it/69di87dni61e1.png?width=1242&format=png&auto=webp&s=d15f8f59baf43caa830c967e1627caedf3ee236c\n\nFirst, I'm not super adept with python.  I can skim thru and pick out 10% of it but trying to parse out any of this just gives me brain cramps.\n\nStarting a few weeks ago I started seeing the above message when I tried to generate an image.  A google search turned up a TINY bit of info but nothing that went anywhere.  I've pulled and reinstalled rocm (radeon GPU) as well as comfyUI several times to no effect.  This evening before I dug in deeper I pulled my boot drive and threw in a spare drive on which I installed a brand new instance of endeavouros as well as rocm and comfyui using the same process as on my current desktop and on a BRAND new install of everything I get the same error.  GPU seems fine.... games run..... rocm still works for blender....\n\nI've tried adding the above \"TORCH\\_USE\\_HIP\\_DSA\" line to no avail.\n\nI'm about to dig in and track down logs and do some more extensive tinkering but I thought I'd get this poker in the fire first and see if anyone had any thoughts.\n\nEndeavourOS\n\nkernel 6.11.5-arch1-1\n\nGnome 47\n\nRocm 6.2\n\nryzen 3900x\n\nradeon 7800 xt\n\n64gb ram",
            "comments": [
                {
                    "id": "lxdrtm7",
                    "author": "Pretend_Potential",
                    "body": "from the error i'm guessing you have an AMD gpu?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729857.0,
                    "parent_id": "t3_1gse3ln",
                    "link_id": "t3_1gse3ln",
                    "permalink": "/r/StableDiffusion/comments/1gse3ln/sd_crashing/lxdrtm7/"
                },
                {
                    "id": "lxedowm",
                    "author": "thirteen-bit",
                    "body": "1. What is \"SD\" that is crashing? a1111, forge, comfyui, anything else?\n\n2. You have successfully hidden information needed to help you. It's probably under the \"Show Report\" button. Also, screenshot of the text is the worst possible way to ask for help -> it's much better to copy and paste as text information.\n\n3. radeon 7800 xt -> looks like you forgot to check the last step of the installation guide: [For AMD cards not officially supported by ROCm](https://github.com/comfyanonymous/ComfyUI/?tab=readme-ov-file#for-amd-cards-not-officially-supported-by-rocm). You've probably forgot to export environment variable HSA\\_OVERRIDE\\_GFX\\_VERSION:\n\n    HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py\n    # or\n    export HSA_OVERRIDE_GFX_VERSION=11.0.0\n    python main.py\n    \n    # or set it once for all your sessions:\n    echo \"export HSA_OVERRIDE_GFX_VERSION=11.0.0\" >> ~/.bashrc",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731740724.0,
                    "parent_id": "t3_1gse3ln",
                    "link_id": "t3_1gse3ln",
                    "permalink": "/r/StableDiffusion/comments/1gse3ln/sd_crashing/lxedowm/"
                },
                {
                    "id": "lxdtovx",
                    "author": "fliberdygibits",
                    "body": ">Rocm 6.2\n\n>ryzen 3900x\n\n>radeon 7800 xt",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730670.0,
                    "parent_id": "t1_lxdrtm7",
                    "link_id": "t3_1gse3ln",
                    "permalink": "/r/StableDiffusion/comments/1gse3ln/sd_crashing/lxdtovx/"
                }
            ]
        },
        {
            "id": "1gsdygl",
            "title": "KoboldCpp now supports generating images locally with Flux and SD3.5",
            "author": "HadesThrowaway",
            "score": 11,
            "upvotes": 11,
            "downvotes": 0,
            "num_comments": 15,
            "created_utc": 1731726190.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/",
            "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/",
            "selftext": "&#x200B;\n\nhttps://preview.redd.it/ndg9d58ui61e1.png?width=1920&format=png&auto=webp&s=704706dc073e4c9797d2536226b51dcb7381d102\n\nFor those that have not heard of KoboldCpp, it's a lightweight, single-executable standalone tool with no installation required and no dependencies, for running **text-generation and image-generation models** locally with low-end hardware (based on llama.cpp and stable-diffusion.cpp).\n\nAbout 6 months ago, [KoboldCpp added support for SD1.5 and SDXL local image generation](https://old.reddit.com/r/StableDiffusion/comments/1cp7f6s/koboldcpp_fully_local_stable_diffusion_backend/)\n\nNow, with the latest release, usage of **Flux and SD3.5 large/medium models** are now supported! Sure, ComfyUI may be more powerful and versatile, but KoboldCpp allows image gen with a single .exe file with **no installation needed**. Considering A1111 is basically dead, and Forge still hasn't added SD3.5 support to the main branch, I thought people might be interested to give this a try.\n\nNote that loading full fp16 Flux will take over 20gb VRAM, so select \"Compress Weights\" if you have less GPU mem than that and are loading safetensors (at the expense of load time). Compatible with most flux/sd3.5 models out there, though pre-quantized GGUFs will load faster since runtime compression is avoided.\n\nDetails and instructions are in the release notes. Check it out here:  [**https://github.com/LostRuins/koboldcpp/releases/latest**](https://github.com/LostRuins/koboldcpp/releases/latest)",
            "comments": [
                {
                    "id": "lxdl87j",
                    "author": "Ramdak",
                    "body": "It says it's a pyinstaller, wouldn't it install python and all de dependencies?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727195.0,
                    "parent_id": "t3_1gsdygl",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdl87j/"
                },
                {
                    "id": "lxdw244",
                    "author": "Slight-Living-8098",
                    "body": "Guess I need to revisit my OpenKlyde project and add this in place of the external SD API calls, huh?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731682.0,
                    "parent_id": "t3_1gsdygl",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdw244/"
                },
                {
                    "id": "lxdyf7l",
                    "author": "AIPornCollector",
                    "body": "As tempting as it is, ComfyUI will always be the one for me. <3 comfy.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731732743.0,
                    "parent_id": "t3_1gsdygl",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdyf7l/"
                },
                {
                    "id": "lxdmpxu",
                    "author": "sanobawitch",
                    "body": "Tried both the diffusers and the comfy compatible safetensors file for SD3.5 Medium, it complains about \"Could not load image model\". F16 weights.\n\nEdit: I have separate vae, clips and transformer model. Everything loads up fine but the transformer part of it.\n\n2nd Edit: Not sure why the downvote, and why reporting this outside github deserves a downvote. Github issues and failed files are linked below.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731727773.0,
                    "parent_id": "t3_1gsdygl",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdmpxu/"
                },
                {
                    "id": "lxdodhy",
                    "author": "Nenotriple",
                    "body": "Yes, but it's all contained unlike an unpackaged Python project.\n\nIt's like saying that Google Chrome requires dependencies, sure it *does*, but it's not something you have to worry about in any way.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731728431.0,
                    "parent_id": "t1_lxdl87j",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdodhy/"
                },
                {
                    "id": "lxdxwi1",
                    "author": "HadesThrowaway",
                    "body": "You could, it exposes a a1111 compatible api. Documentation is available at https://lite.koboldai.net/koboldcpp_api",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731732504.0,
                    "parent_id": "t1_lxdw244",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdxwi1/"
                },
                {
                    "id": "lxe00by",
                    "author": "HadesThrowaway",
                    "body": "For sure. But they have different goals, comfy is like Photoshop with all the bells and whistles. Koboldcpp is like mspaint, simple, easy to use and compact. Open one file, load another file, done ready to use",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733497.0,
                    "parent_id": "t1_lxdyf7l",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxe00by/"
                },
                {
                    "id": "lxdqjlp",
                    "author": "fish312",
                    "body": "Did you load all the auxiliary files too? Modern models often have them split into multiple parts like T5_xxl, VAE, Clip-G etc and you need all of them.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729312.0,
                    "parent_id": "t1_lxdmpxu",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdqjlp/"
                },
                {
                    "id": "lxdya7c",
                    "author": "Slight-Living-8098",
                    "body": "I know. lol\n\n[https://github.com/badgids/OpenKlyde](https://github.com/badgids/OpenKlyde)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731732678.0,
                    "parent_id": "t1_lxdxwi1",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdya7c/"
                },
                {
                    "id": "lxdz81r",
                    "author": "Slight-Living-8098",
                    "body": "I've been following you on GitHub for quite some while now. I am not ashamed to admit your code taught me a lot. Thanks my man",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733111.0,
                    "parent_id": "t1_lxdxwi1",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdz81r/"
                },
                {
                    "id": "lxe0dq7",
                    "author": "AIPornCollector",
                    "body": "Koboldcpp is mostly for LLMs from my experience. I'll keep it in mind next time I try to get into text generation again. Having flux and sd3.5 capabilities in the same package can only help.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733697.0,
                    "parent_id": "t1_lxe00by",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxe0dq7/"
                },
                {
                    "id": "lxdszdo",
                    "author": "sanobawitch",
                    "body": "I don't think it has been implemented yet for SD3.5, see the [related issue](https://github.com/leejet/stable-diffusion.cpp/issues/352). What I've been trying to do is load these modules separately. Sdcpp's documentation only refers to the all-in-one checkpoint from:\n\n[https://huggingface.co/stabilityai/stable-diffusion-3-medium/resolve/main/sd3\\_medium\\_incl\\_clips\\_t5xxlfp16.safetensors](https://huggingface.co/stabilityai/stable-diffusion-3-medium/resolve/main/sd3_medium_incl_clips_t5xxlfp16.safetensors)\n\nKobold inherits [sdcpp](https://github.com/LostRuins/koboldcpp/blob/fedc3874bd54ad7fd43f55ae52595ffb0144afc4/otherarch/sdcpp/SDCPP_LICENSE)'s code.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730373.0,
                    "parent_id": "t1_lxdqjlp",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdszdo/"
                },
                {
                    "id": "lxdxq54",
                    "author": "HadesThrowaway",
                    "body": "Does https://huggingface.co/Comfy-Org/stable-diffusion-3.5-fp8/blob/main/sd3.5_medium_incl_clips_t5xxlfp8scaled.safetensors work for you?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731732424.0,
                    "parent_id": "t1_lxdszdo",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxdxq54/"
                },
                {
                    "id": "lxe0mjz",
                    "author": "sanobawitch",
                    "body": "Ty for the reply. I don't have enough bandwidth for this month to download this large file and run it locally to tell if that works (ISP decided to pull the plug from my area, I'm on a daily bandwidth cap). Sorry about that.\n\nThe files I've tried are:  \n[https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/blob/main/sd3.5\\_medium.safetensors](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/blob/main/sd3.5_medium.safetensors)\n\n[https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/blob/main/transformer/diffusion\\_pytorch\\_model.safetensors](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/blob/main/transformer/diffusion_pytorch_model.safetensors)\n\nNot having to redownload text encoders also helped me (in other backends), since sd3.5 large (released first) and medium share VAE and TEs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733836.0,
                    "parent_id": "t1_lxdxq54",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxe0mjz/"
                },
                {
                    "id": "lxe3nt8",
                    "author": "fish312",
                    "body": "Also a silly thing to check but make sure you select the model as an image model not a text model (there are different file boxes and koboldcpp can load both)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735486.0,
                    "parent_id": "t1_lxe0mjz",
                    "link_id": "t3_1gsdygl",
                    "permalink": "/r/StableDiffusion/comments/1gsdygl/koboldcpp_now_supports_generating_images_locally/lxe3nt8/"
                }
            ]
        },
        {
            "id": "1gsdo8t",
            "title": "Help, please. ¿RTX 3060 12 GB o RTX 4060 TI 16GB for SDXL with múltiples Loras?",
            "author": "Independent-Nature10",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731725215.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/",
            "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/",
            "selftext": "I am currently interested in getting started with SD and using many Loras at once to generate images, as well as train LLM. I want to start with one of these graphics cards (for economic reasons and availability in my country). Which of these two would be the best option? Is there a marked difference between the two or is the advantage of the 4060 over the 3060 not much (in performance, generation results, etc.)? Your guidance will be appreciated :)",
            "comments": [
                {
                    "id": "lxdgp7n",
                    "author": "TheDailySpank",
                    "body": "Would you purchase a 4 seater for your family of 6?",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731725398.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxdgp7n/"
                },
                {
                    "id": "lxe35bt",
                    "author": "Bazookasajizo",
                    "body": "4060 ti. 16gb > 12 gb",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731735236.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxe35bt/"
                },
                {
                    "id": "lxe8rj3",
                    "author": "DemoEvolved",
                    "body": "This is the 16gb card and it’s not even a fair fight",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731737957.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxe8rj3/"
                },
                {
                    "id": "lxdm53q",
                    "author": "Puzzled-Background-5",
                    "body": "VRAM reigns supreme with Generative AI.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727551.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxdm53q/"
                },
                {
                    "id": "lxdn5w9",
                    "author": "raviteja777",
                    "body": "If you are looking for a one time investment and can stretch your budget , then go for atleast 24 GB of VRAM. You can always target SDXL and maybe FLUX lora too. \n\nwhile 3060 12 GB is good for basic SDXL image generation. Training Lora takes lot of time.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727948.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxdn5w9/"
                },
                {
                    "id": "lxeeyl8",
                    "author": "rookan",
                    "body": "If you want to generate only - 12gb is enough. For training even 16gb might be too little",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731741500.0,
                    "parent_id": "t3_1gsdo8t",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxeeyl8/"
                },
                {
                    "id": "lxe6c7u",
                    "author": "Independent-Nature10",
                    "body": "I am aware that 24gb would be the best option, but that component is absurdly expensive in my country. That is why I was asking about the 16gb 4060ti. Is it much better than the 12gb 3060 or is the difference minimal? Because, if we talk about money, with what a 16gb 4060 ti costs I can buy two 12gb 3060s. Is it also possible to use two graphics cards for Stable Diffusion?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731736749.0,
                    "parent_id": "t1_lxdn5w9",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxe6c7u/"
                },
                {
                    "id": "lxe75c3",
                    "author": "constPxl",
                    "body": "simple answer: you cant.   \n  \nlong answer: you can use tools like stableswarm for multiple renders on different gpus, but you cant, say render an image using 2 different gpu to speed things up\n\nfor llm and many other ai works, having multiple gpus is very useful but always remember the bottleneck that is the motherboard/cpu between the different gpu",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731737141.0,
                    "parent_id": "t1_lxe6c7u",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxe75c3/"
                },
                {
                    "id": "lxe7uqv",
                    "author": "Most_Way_9754",
                    "body": "Unless you want to do 2 generations at once for production and are very sure that you won't use anything but SDXL, I would recommend 1x 4060Ti 16gb over 2x 3060 12gb. \n\nModels show trends of getting larger and even the 16gb of the 4060Ti already starts to feel limiting.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731737491.0,
                    "parent_id": "t1_lxe6c7u",
                    "link_id": "t3_1gsdo8t",
                    "permalink": "/r/StableDiffusion/comments/1gsdo8t/help_please_rtx_3060_12_gb_o_rtx_4060_ti_16gb_for/lxe7uqv/"
                }
            ]
        },
        {
            "id": "1gsb8tt",
            "title": "Roop Unleashed Intsallation failed.",
            "author": "DowntownMiddle7277",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731717365.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsb8tt/roop_unleashed_intsallation_failed/",
            "permalink": "/r/StableDiffusion/comments/1gsb8tt/roop_unleashed_intsallation_failed/",
            "selftext": "Hey, can anybody help me with a problem while trying to install Roop Unleashed? When I run the Windows run file, it takes me straight to CMD and waits for download, but this following message popped out :\n\n\" ERROR: Conda environment creation failed.  \nPress any key to continue...\"\n\n  \nPlease, if anybody here knows how to fix it? thanks",
            "comments": []
        },
        {
            "id": "1gsdb0u",
            "title": "Is there any free ai model to stylize existing game textures (.png/.dds)?",
            "author": "kiminifurete_",
            "score": 20,
            "upvotes": 20,
            "downvotes": 0,
            "num_comments": 7,
            "created_utc": 1731723939.0,
            "url": "https://www.reddit.com/gallery/1gsdb0u",
            "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/",
            "selftext": "",
            "comments": [
                {
                    "id": "lxden29",
                    "author": "PwanaZana",
                    "body": "Yes, stable diffusion, using Tiling mode, can do this very well. There are Loras/checkpoints made for making warcraft-style textures, on [civit.ai](http://civit.ai)",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731724560.0,
                    "parent_id": "t3_1gsdb0u",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxden29/"
                },
                {
                    "id": "lxdxeo6",
                    "author": "aeroumbria",
                    "body": "You can try the circular VAE in this repo: https://github.com/FlyingFireCo/tiled_ksampler\n\nIt ensures the tiles have interconnecting edges. You can then inpaint the middle to add some variety.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731732276.0,
                    "parent_id": "t3_1gsdb0u",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxdxeo6/"
                },
                {
                    "id": "lxeg0b5",
                    "author": "DsDman",
                    "body": "For creating tillable textures Tiling Mode is perfect. You can also tile only horizontally or only vertically. \n\nIf you want to texture a more complicated model, StableProjectorz is excellent",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731742160.0,
                    "parent_id": "t3_1gsdb0u",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxeg0b5/"
                },
                {
                    "id": "lxdi0gf",
                    "author": "kiminifurete_",
                    "body": "thanks! I'll try that",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731725928.0,
                    "parent_id": "t1_lxden29",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxdi0gf/"
                },
                {
                    "id": "lxdub11",
                    "author": "agent_wolfe",
                    "body": "What is a Lora? I always hear ppl mention them but I’m too scared to ask.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730935.0,
                    "parent_id": "t1_lxden29",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxdub11/"
                },
                {
                    "id": "lxdw261",
                    "author": "Synyster328",
                    "body": "Basically like mods you can apply to manipulate the base models in different ways. That's the simple explanation. So someone could train a LoRA for watercolor, and any time you include it in your generations, it would influence the output towards that style. Or if you train it on images of a particular person, now you can generate consistent images of that person in different scenes.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731731683.0,
                    "parent_id": "t1_lxdub11",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxdw261/"
                },
                {
                    "id": "lxe3vdh",
                    "author": "Hyokkuda",
                    "body": "LoRAs are used for things that a base model might fail to create accurately. For instance, you might want to generate a specific character from a Final Fantasy title but somehow you can never get it right. Like the hair are always wrong no matter what prompts you use, or the face or eyes or lips are always inaccurately shaped, etc... Using the proper LoRA to create the character that you want, will most definitely solve most of your issues.\n\nLoRAs can be used for anything. Objects, scenery, characters, effects, etc...",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735586.0,
                    "parent_id": "t1_lxdub11",
                    "link_id": "t3_1gsdb0u",
                    "permalink": "/r/StableDiffusion/comments/1gsdb0u/is_there_any_free_ai_model_to_stylize_existing/lxe3vdh/"
                }
            ]
        },
        {
            "id": "1gsd31e",
            "title": "A new regional prompting for FLUX.1",
            "author": "haofanw",
            "score": 78,
            "upvotes": 78,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731723211.0,
            "url": "https://github.com/NJU-PCALab/RAG-Diffusion",
            "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/",
            "selftext": "",
            "comments": [
                {
                    "id": "lxdhwep",
                    "author": "sanobawitch",
                    "body": "Instead of doing the already seen: region = background\\_prompt \\* 0.2 + region\\_prompt \\* 0.8, they seem to mix all the regions together. See the other [implementation](https://github.com/instantX-research/Regional-Prompting-FLUX/blob/main/assets/demo_pipeline.png), which has sharp contrast between regions.\n\nhttps://preview.redd.it/h5e3xuj5f61e1.png?width=966&format=png&auto=webp&s=bcc3fd7fb7ef5709fae34b78f52e82c15f108775\n\nAnd then: \"Region-Aware Text-to-Image Generation novelly makes image repainting feasible, allowing users to modify specific unsatisfactory regions in the previous generation while keeping all other regions intact without need for additional inpainting models.\"\n\nAnd this demo is for Flux dev. (Smaller models get no love.)",
                    "score": 17,
                    "upvotes": 17,
                    "downvotes": 0,
                    "created_utc": 1731725884.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxdhwep/"
                },
                {
                    "id": "lxdbfgp",
                    "author": "haofanw",
                    "body": "Arxiv: [https://arxiv.org/abs/2411.06558](https://arxiv.org/abs/2411.06558)",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731723278.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxdbfgp/"
                },
                {
                    "id": "lxdp0z9",
                    "author": "Parabacles",
                    "body": "This is beautiful, exactly what I was looking for",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731728695.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxdp0z9/"
                },
                {
                    "id": "lxdkurq",
                    "author": "0nlyhooman6I1",
                    "body": "Any plans to port this to forge?",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731727049.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxdkurq/"
                },
                {
                    "id": "lxe28ey",
                    "author": "GoofAckYoorsElf",
                    "body": "Sorry to say so, but did you really have to call it RAG (Region Aware Generation)? We already have RAG (Retriever Augmented Generation) in generative AI. This massively adds to confusion.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731734737.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxe28ey/"
                },
                {
                    "id": "lxdbe8d",
                    "author": "haofanw",
                    "body": "https://preview.redd.it/eablbr4ba61e1.jpeg?width=1905&format=pjpg&auto=webp&s=efe1ac373c8007f5fac2f8761e2f66e2b2fcd523",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731723264.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxdbe8d/"
                },
                {
                    "id": "lxe2wx1",
                    "author": "butthe4d",
                    "body": "Is there a comfy node?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731735117.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxe2wx1/"
                },
                {
                    "id": "lxe30n9",
                    "author": "fauni-7",
                    "body": "Comfy?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735169.0,
                    "parent_id": "t3_1gsd31e",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxe30n9/"
                },
                {
                    "id": "lxeb2ro",
                    "author": "chickenofthewoods",
                    "body": "Yep.  Upon first glance I was like wtf?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731739220.0,
                    "parent_id": "t1_lxe28ey",
                    "link_id": "t3_1gsd31e",
                    "permalink": "/r/StableDiffusion/comments/1gsd31e/a_new_regional_prompting_for_flux1/lxeb2ro/"
                }
            ]
        },
        {
            "id": "1gscpb2",
            "title": "Difference in quality of images  (Local vs Online Generator)",
            "author": "MarksmanKNG",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731721985.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gscpb2/difference_in_quality_of_images_local_vs_online/",
            "permalink": "/r/StableDiffusion/comments/1gscpb2/difference_in_quality_of_images_local_vs_online/",
            "selftext": "Good day, I’m having a problem and would like some insight from the community.\n\nI’ve been having some quality issues on my local setup (SwarmUI + RTX2060 Super). Compared to the platform I use concurrently (Pixai), the quality difference is significant and I don’t know why.\n\nSome key details. \n\n1)      Same model, LORA & VAE used\n\n2)      Same prompt, seed and sampling configurations \n\n3)      Addetailer / Segment (SwarmUI) on & off\n\n4)     No upscaling used for both sides\n\n5)     No Controlnets being used.\n\n6)      Repeated (1) with different model with consistent disparity.\n\nPictures below.\n\nLocal (SwarmUI): [https://imgur.com/A8FG5ia](https://imgur.com/A8FG5ia) (Metadata should be included)\n\nPixai:  [https://imgur.com/O8qNAmY](https://imgur.com/O8qNAmY)\n\n \n\nI’ve checked this sub and found these links for ideas but seems not able to resolve it either.\n\n[https://www.reddit.com/r/StableDiffusion/comments/1bdbyey/bad\\_quality\\_images\\_when\\_generated\\_locally/](https://www.reddit.com/r/StableDiffusion/comments/1bdbyey/bad_quality_images_when_generated_locally/)\n\n[https://www.reddit.com/r/StableDiffusion/comments/156c5r7/why\\_am\\_i\\_not\\_getting\\_the\\_same\\_quality\\_images/](https://www.reddit.com/r/StableDiffusion/comments/156c5r7/why_am_i_not_getting_the_same_quality_images/)\n\nThis has me thinking of whether there’s additional workflows / extensions I’m not aware about. My SwarmUI is updated as of today but stock on extensions.\n\nHope for some insights on what may be wrong.\n\nThanks for your time.",
            "comments": [
                {
                    "id": "lxdharl",
                    "author": "Pretend_Potential",
                    "body": "Pixai almost certainly has different settings than you do. have you gotten hold of them to see if you can get them to tell you what samplers and schedulers, and other settings, they are using?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731725640.0,
                    "parent_id": "t3_1gscpb2",
                    "link_id": "t3_1gscpb2",
                    "permalink": "/r/StableDiffusion/comments/1gscpb2/difference_in_quality_of_images_local_vs_online/lxdharl/"
                },
                {
                    "id": "lxdwm6t",
                    "author": "BimBomBom",
                    "body": "Most likely it adds bunch of additional negative tags/embeddings (bad-aritist, bad-art etc) to negative prompt to make it look more polished",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731918.0,
                    "parent_id": "t3_1gscpb2",
                    "link_id": "t3_1gscpb2",
                    "permalink": "/r/StableDiffusion/comments/1gscpb2/difference_in_quality_of_images_local_vs_online/lxdwm6t/"
                },
                {
                    "id": "lxdwwqt",
                    "author": "Enshitification",
                    "body": "It could be as simple as a difference in seed implementation.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731732047.0,
                    "parent_id": "t3_1gscpb2",
                    "link_id": "t3_1gscpb2",
                    "permalink": "/r/StableDiffusion/comments/1gscpb2/difference_in_quality_of_images_local_vs_online/lxdwwqt/"
                }
            ]
        },
        {
            "id": "1gsce1j",
            "title": "Mochi issues, please advise.",
            "author": "LucidFir",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731720980.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsce1j/mochi_issues_please_advise/",
            "permalink": "/r/StableDiffusion/comments/1gsce1j/mochi_issues_please_advise/",
            "selftext": "I got as far as making Mochi work, I had to eventually make an entirely separate install of ComfyUI dedicated to running Mochi.\n\nNow... Sage Attention is meant to be fastest, but I don't have it - can anyone ELI5 getting it working, and can anyone ELI5 everything else I should do to get this running as well as possible? I've run out of mental energy to problem solve just getting this far, sorry, so I'm hoping for help.\n\n\n\nhttps://preview.redd.it/xev2y1b1361e1.png?width=3403&format=png&auto=webp&s=85d93cb3435fe07678b22133b1396d3cb5545c27\n\n  \nPSA to anyone having difficulties with missing nodes or permission issues: Make a separate ComfyUI install just for Mochi - and temporarily change the ComfyManager node config.ini security level from normal to weak whilst you install, and change back after.",
            "comments": [
                {
                    "id": "lxd7v58",
                    "author": "throttlekitty",
                    "body": "There's a good guide here: https://purz.notion.site/Get-Windows-Triton-working-for-Mochi-6a0c055e21c84cfba7f1dd628e624e97\n\nUse that to set up the environment, and install triton. After that, you should be able to pip install sageattention. If that fails, follow the steps to build it [here](https://github.com/thu-ml/SageAttention).",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731721901.0,
                    "parent_id": "t3_1gsce1j",
                    "link_id": "t3_1gsce1j",
                    "permalink": "/r/StableDiffusion/comments/1gsce1j/mochi_issues_please_advise/lxd7v58/"
                },
                {
                    "id": "lxdkdm4",
                    "author": "LucidFir",
                    "body": "Thanks I'll try this tomorrow hopefully.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731726860.0,
                    "parent_id": "t1_lxd7v58",
                    "link_id": "t3_1gsce1j",
                    "permalink": "/r/StableDiffusion/comments/1gsce1j/mochi_issues_please_advise/lxdkdm4/"
                },
                {
                    "id": "lxef1v9",
                    "author": "LucidFir",
                    "body": "I probably just need to go to bed, but why can't I find a dedicated Build Tools installer? What's it part of?\n\nhttps://preview.redd.it/vdt1o4gps71e1.png?width=1483&format=png&auto=webp&s=4a30498cfb222da658018608d6cc4f3cc286c932\n\n  \n[https://duckduckgo.com/?q=visual+studio+build+tools+2022+download&ia=web](https://duckduckgo.com/?q=visual+studio+build+tools+2022+download&ia=web)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731741555.0,
                    "parent_id": "t1_lxd7v58",
                    "link_id": "t3_1gsce1j",
                    "permalink": "/r/StableDiffusion/comments/1gsce1j/mochi_issues_please_advise/lxef1v9/"
                }
            ]
        },
        {
            "id": "1gsc3zm",
            "title": "Has anyone tried MiGraphX?",
            "author": "hahaeggsarecool",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731720074.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsc3zm/has_anyone_tried_migraphx/",
            "permalink": "/r/StableDiffusion/comments/1gsc3zm/has_anyone_tried_migraphx/",
            "selftext": "migraphx is amd's program for optimizing ai models for their GPUs. Before I waste a bunch of time on it, I'm curious if anyone else has tried it with stable diffusion and if they got any sort of speedup. I know it will be a hassle because AMD tends to have a track record of making this stuff only work well on their pricey instinct gpus. Also if you happen to already know whether it would work or not with my GPU, I have a radeon pro wx9100(actually a reflashed instinct mi25). If it does work well then this could make AMD GPUs competitive with nvidias but then also why tf is it something you have to dig so deep into amds docs to even know about.",
            "comments": []
        },
        {
            "id": "1gsbhp9",
            "title": "How To Fix This Error While Installing Roop Unleashed?",
            "author": "Pure_Specialist_4232",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731718103.0,
            "url": "https://i.redd.it/7f67g9a0v51e1.jpeg",
            "permalink": "/r/StableDiffusion/comments/1gsbhp9/how_to_fix_this_error_while_installing_roop/",
            "selftext": "can someone help me with this? I can't install  Roop,  stuck at this stage.",
            "comments": [
                {
                    "id": "lxcz4xf",
                    "author": "happysquish",
                    "body": "Just install rope-pearl",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731718527.0,
                    "parent_id": "t3_1gsbhp9",
                    "link_id": "t3_1gsbhp9",
                    "permalink": "/r/StableDiffusion/comments/1gsbhp9/how_to_fix_this_error_while_installing_roop/lxcz4xf/"
                },
                {
                    "id": "lxd55t8",
                    "author": "Pure_Specialist_4232",
                    "body": "what is that? another version of roop-unleashed?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731720852.0,
                    "parent_id": "t1_lxcz4xf",
                    "link_id": "t3_1gsbhp9",
                    "permalink": "/r/StableDiffusion/comments/1gsbhp9/how_to_fix_this_error_while_installing_roop/lxd55t8/"
                },
                {
                    "id": "lxdjbfd",
                    "author": "happysquish",
                    "body": "https://github.com/Hillobar/Rope",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731726447.0,
                    "parent_id": "t1_lxd55t8",
                    "link_id": "t3_1gsbhp9",
                    "permalink": "/r/StableDiffusion/comments/1gsbhp9/how_to_fix_this_error_while_installing_roop/lxdjbfd/"
                }
            ]
        },
        {
            "id": "1gsb3y6",
            "title": "How to merge / \"Bake\" Loras into a checkpoint?",
            "author": "braveheart20",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731716959.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsb3y6/how_to_merge_bake_loras_into_a_checkpoint/",
            "permalink": "/r/StableDiffusion/comments/1gsb3y6/how_to_merge_bake_loras_into_a_checkpoint/",
            "selftext": "Hello, I am reaching out because I haven't seen this anywhere on reddit. On quite a few checkpoints on Civitai, I notice that the author has permanently \"baked\" in multiple style Loras. I see the benefit of this, as you free up prompt space if you have multiple Loras you use every time. In my case, there are 3-4 Loras that I always use to achieve a certain style, and I would love to just have them be part of the checkpoint. \n\nI typically use Pony based models, and SD Forge is my main UI. My only experience has come from merging checkpoints, but I couldn't find any setting for including Loras. \n\nI am hoping to find advice on this, much appreciated! ",
            "comments": [
                {
                    "id": "lxcwruq",
                    "author": "a_beautiful_rhind",
                    "body": "In comfy there are nodes to save the checkpoint after loras are applied, among others.\n\nYou can also use: https://github.com/kohya-ss/sd-scripts\n\nAll the plugins I tried for A1111 didn't work that well and probably don't work on new forge.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731717650.0,
                    "parent_id": "t3_1gsb3y6",
                    "link_id": "t3_1gsb3y6",
                    "permalink": "/r/StableDiffusion/comments/1gsb3y6/how_to_merge_bake_loras_into_a_checkpoint/lxcwruq/"
                }
            ]
        },
        {
            "id": "1gsb0y4",
            "title": "ComfyUI Crash Course, Part II (2024): SEGS, Workflow Execution and Traffic Cones",
            "author": "WingsOfPhoenix",
            "score": 4,
            "upvotes": 4,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731716707.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gsb0y4/comfyui_crash_course_part_ii_2024_segs_workflow/",
            "permalink": "/r/StableDiffusion/comments/1gsb0y4/comfyui_crash_course_part_ii_2024_segs_workflow/",
            "selftext": "The course is aimed at users of Automatic1111 and other Gradio-based WebUIs.\n\nVideo Link: [https://youtu.be/9fL66UOQjQ0](https://youtu.be/9fL66UOQjQ0)\n\nPart II covers:\n\n* Traffic Cones\n* Workflow Execution\n* Noise Mode Differences\n* Weight Normalization Differences\n* SEGS Education",
            "comments": []
        },
        {
            "id": "1gs9v1s",
            "title": "Cogvideo X error",
            "author": "Loocheeow",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731713298.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs9v1s/cogvideo_x_error/",
            "permalink": "/r/StableDiffusion/comments/1gs9v1s/cogvideo_x_error/",
            "selftext": "I installed cogvideox on Comfyui but as soon as I queue I get this error, any ideas? :)\n\nPrompt outputs failed validation  \nCogVideoSampler:  \n\\- Value not in list: scheduler: 'DPM' not in \\['DPM++', 'Euler', 'Euler A', 'PNDM', 'DDIM', 'CogVideoXDDIM', 'CogVideoXDPMScheduler', 'SASolverScheduler', 'UniPCMultistepScheduler', 'HeunDiscreteScheduler', 'DEISMultistepScheduler', 'LCMScheduler'\\]",
            "comments": [
                {
                    "id": "lxclmcc",
                    "author": "Pretend_Potential",
                    "body": "can you change the sampler used with it?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731713535.0,
                    "parent_id": "t3_1gs9v1s",
                    "link_id": "t3_1gs9v1s",
                    "permalink": "/r/StableDiffusion/comments/1gs9v1s/cogvideo_x_error/lxclmcc/"
                }
            ]
        },
        {
            "id": "1gs8if1",
            "title": "Resources to learn the math behind diffusion?",
            "author": "bgighjigftuik",
            "score": 4,
            "upvotes": 4,
            "downvotes": 0,
            "num_comments": 10,
            "created_utc": 1731709534.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/",
            "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/",
            "selftext": "I believe that most of us use these models without a thorough understanding on how they work. However, I would like to get deeper on how the underlying magic works.\n\nI have searched a little bit and most papers explain the math, but take a lot of shortcuts for the sake of brevity, especially when it comes to the math derivation.\n\nDoes anyone know some resources that explain the math behind diffusion models thoroughly?\n\nThanks!",
            "comments": [
                {
                    "id": "lxcb9k2",
                    "author": "derpydino24",
                    "body": "I recently attended some lectures at university on the topic. The slides are available here: https://github.com/julioasotodv/ie-c4-466671-diffusion-models\n\nJust check the Readme. The appendices mentioned in the slides explain the math with a lot of detail and I found them easy to follow. I took my time to go over them, but I actually understood pretty much everything (I am undergrad)",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731709930.0,
                    "parent_id": "t3_1gs8if1",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxcb9k2/"
                },
                {
                    "id": "lxcrva8",
                    "author": "Illustrious-Ad-6944",
                    "body": "[https://chatgpt.com/share/6737e21a-c59c-8004-9730-3657566bd482](https://chatgpt.com/share/6737e21a-c59c-8004-9730-3657566bd482)\n\nhere is a link with relevant information (taking note that you should probably check the papers due to the nature of llms, although usually accurate)",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731715832.0,
                    "parent_id": "t3_1gs8if1",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxcrva8/"
                },
                {
                    "id": "lxdml6s",
                    "author": "Old_Formal_1129",
                    "body": "It’s hard to answer without knowing your background tbh. Do you have some working knowledge about probabilistic modeling and/or (stochastic) differential equations, and machine learning?  In any case, the following blog is a great starting point that visually explains the basic ideas better than most materials on the internet, and straight from a leading young researcher behind many algorithms people use today (who also worked at openAI). \n\nhttp://yang-song.net/blog/2021/score/",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731727723.0,
                    "parent_id": "t3_1gs8if1",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxdml6s/"
                },
                {
                    "id": "lxdn4es",
                    "author": "Apprehensive_Sky892",
                    "body": "[https://lilianweng.github.io/posts/2021-07-11-diffusion-models/](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)\n\nThere is some math there, plus links to some of the original papers.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731727932.0,
                    "parent_id": "t3_1gs8if1",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxdn4es/"
                },
                {
                    "id": "lxcbz81",
                    "author": "bgighjigftuik",
                    "body": "Thank you! They actually look good (will read them thoroughly later). Is there a recording of the lecture?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731710168.0,
                    "parent_id": "t1_lxcb9k2",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxcbz81/"
                },
                {
                    "id": "lxcs1jk",
                    "author": "Illustrious-Ad-6944",
                    "body": "just skip past all my input text though, its not relevant",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731715896.0,
                    "parent_id": "t1_lxcrva8",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxcs1jk/"
                },
                {
                    "id": "lxe1bci",
                    "author": "bgighjigftuik",
                    "body": "Thank you!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731734218.0,
                    "parent_id": "t1_lxdml6s",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxe1bci/"
                },
                {
                    "id": "lxe1aqq",
                    "author": "bgighjigftuik",
                    "body": "Thanks!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731734208.0,
                    "parent_id": "t1_lxdn4es",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxe1aqq/"
                },
                {
                    "id": "lxccp8f",
                    "author": "derpydino24",
                    "body": "Unfortunately not. However, I believe they prepare the slides so they can be followed outside the lecture",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731710410.0,
                    "parent_id": "t1_lxcbz81",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxccp8f/"
                },
                {
                    "id": "lxcfhxo",
                    "author": "bgighjigftuik",
                    "body": "I see. Thank you!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711364.0,
                    "parent_id": "t1_lxccp8f",
                    "link_id": "t3_1gs8if1",
                    "permalink": "/r/StableDiffusion/comments/1gs8if1/resources_to_learn_the_math_behind_diffusion/lxcfhxo/"
                }
            ]
        },
        {
            "id": "1gs6sqq",
            "title": "ComfyUI Inpainting changes the original image beyond the mask?",
            "author": "skate_nbw",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731704974.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/",
            "permalink": "/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/",
            "selftext": "I have worked with A1111 and Forge so far. I am currently exploring ComfyUI and I recognised a weird behaviour when trying to inpaint photos. I created the example with the basic differential diffusion workflow from this website: [How to Do Soft Inpainting in ComfyUI with Differential Diffusion](https://promptingpixels.com/soft-inpainting-in-comfyui/). However I have this behaviour with several different workflows.\n\nWhat happens: The KSampler does do major changes in the mask area but does additionally make tiny changes to the whole picture beyond the mask. For the sake of this exmaple I only put a small dot on the front of the woman on the photo (see link in the comments). The changes outside the mask area are particularly visible at the eyes and the sweater. It happens with all real photos, all checkpoints (inpaint and regular), with all samplers (euler, dpmpp, etc.), all schedulars, with differential diffusion switched on or off. It even happens with other nodes than the KSampler, for example with the Detailers from the Impact Pack.\n\nIn A1111 and Forge, only the parts in the photo are changed that are masked. Does ComfyUI have a bug when impainting, is it my installation or what could be the problem?",
            "comments": [
                {
                    "id": "lxdlllv",
                    "author": "Botoni",
                    "body": "I think it is because the proces of vae encoding and decoding is lossy, and thus the image slightly changes.\n\nYou can fix that pasting the inpainted part into the original image before the vae encode, you can do that with an image blend node and the same mask used to inpaint.\n\nHere you have a workflow that does that and more: https://ko-fi.com/s/f182f75c13\n\nI have the same but for flux if that's what you need, check the other workflows.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731727341.0,
                    "parent_id": "t3_1gs6sqq",
                    "link_id": "t3_1gs6sqq",
                    "permalink": "/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/lxdlllv/"
                },
                {
                    "id": "lxcrj13",
                    "author": "skate_nbw",
                    "body": "Here is a link with comparison of an original image (left) and an Inpainted image that had only a very small mask, but the whole image was changed. [https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=a9837a42-a3ae-11ef-9397-d93975fe8866](https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html?uid=a9837a42-a3ae-11ef-9397-d93975fe8866)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731715707.0,
                    "parent_id": "t3_1gs6sqq",
                    "link_id": "t3_1gs6sqq",
                    "permalink": "/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/lxcrj13/"
                },
                {
                    "id": "lxef7fj",
                    "author": "skate_nbw",
                    "body": "Thank you very much, I will try that!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731741650.0,
                    "parent_id": "t1_lxdlllv",
                    "link_id": "t3_1gs6sqq",
                    "permalink": "/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/lxef7fj/"
                },
                {
                    "id": "lxcrnkc",
                    "author": "skate_nbw",
                    "body": "https://preview.redd.it/1n54nuxzn51e1.png?width=900&format=png&auto=webp&s=fac7b05bcdc9448a99968a57ea8a3becdf4ad436\n\nThe mask.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731715753.0,
                    "parent_id": "t1_lxcrj13",
                    "link_id": "t3_1gs6sqq",
                    "permalink": "/r/StableDiffusion/comments/1gs6sqq/comfyui_inpainting_changes_the_original_image/lxcrnkc/"
                }
            ]
        },
        {
            "id": "1gs6x6o",
            "title": "A simple to guide for Image Generation on Linux (Mint) with a Radeon RX580?",
            "author": "DinDinDin_",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731705306.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs6x6o/a_simple_to_guide_for_image_generation_on_linux/",
            "permalink": "/r/StableDiffusion/comments/1gs6x6o/a_simple_to_guide_for_image_generation_on_linux/",
            "selftext": "I'm unable to find an appropriate guide so I'm asking here...",
            "comments": [
                {
                    "id": "lxcxesq",
                    "author": "a_beautiful_rhind",
                    "body": "There was nothing simple about this card. I had to install custom patches to rocm and I doubt any of that is updated.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731717886.0,
                    "parent_id": "t3_1gs6x6o",
                    "link_id": "t3_1gs6x6o",
                    "permalink": "/r/StableDiffusion/comments/1gs6x6o/a_simple_to_guide_for_image_generation_on_linux/lxcxesq/"
                },
                {
                    "id": "lxd9tmd",
                    "author": "Mundane-Apricot6981",
                    "body": "On Linux - nothing simple awaits you, it will be hell combining proper torch version which maybe will work with bugged Amd ROCm device.\n\nOn Windows you can easily use Comfy UI with command argument --directml, it works out of the box.  \nI use Comfy UI with Rx470 (4Gb).  \n  \n\"\"\"  \npython.exe -s ComfyUI\\\\main.py --windows-standalone-build --directml --lowvram --preview-method auto --use-split-cross-attention --listen  \n\"\"\"",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731722646.0,
                    "parent_id": "t3_1gs6x6o",
                    "link_id": "t3_1gs6x6o",
                    "permalink": "/r/StableDiffusion/comments/1gs6x6o/a_simple_to_guide_for_image_generation_on_linux/lxd9tmd/"
                }
            ]
        },
        {
            "id": "1gs6rdn",
            "title": "Badly generated images",
            "author": "Certain_Upstairs_424",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731704871.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/",
            "permalink": "/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/",
            "selftext": "Does anyone know the reason why after some time generating images correctly in SD, it starts to generate wrong images, I would like to clarify that I don't have very demanding parameters, I use normal parameters. I use the Google Colab version\n\nhttps://preview.redd.it/bi6l9sykr41e1.png?width=1000&format=png&auto=webp&s=c3067e59b87815b965eb942802218d79fe83b65a\n\nhttps://preview.redd.it/86od5yykr41e1.png?width=960&format=png&auto=webp&s=2d10d25c88026d23d459f4be645633ffeab6ec4e\n\n",
            "comments": [
                {
                    "id": "lxc1ddk",
                    "author": "TurbTastic",
                    "body": "Seems like bad VAE, but it's almost impossible to help when you give virtually no info. The summary of image settings helps a lot, otherwise a screenshot showing everything",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731706762.0,
                    "parent_id": "t3_1gs6rdn",
                    "link_id": "t3_1gs6rdn",
                    "permalink": "/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/lxc1ddk/"
                },
                {
                    "id": "lxcui9h",
                    "author": "Lucaspittol",
                    "body": "Keep your prompts under 75 tokens.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716813.0,
                    "parent_id": "t3_1gs6rdn",
                    "link_id": "t3_1gs6rdn",
                    "permalink": "/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/lxcui9h/"
                },
                {
                    "id": "lxd83ih",
                    "author": "Dwedit",
                    "body": "Set Emphasis mode: No Norm\n\nSearch the settings page.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731721991.0,
                    "parent_id": "t3_1gs6rdn",
                    "link_id": "t3_1gs6rdn",
                    "permalink": "/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/lxd83ih/"
                },
                {
                    "id": "lxcfyw6",
                    "author": "Pretend_Potential",
                    "body": "when it's my machine this happens on, it's memory corruption and time for a reboot",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731711530.0,
                    "parent_id": "t3_1gs6rdn",
                    "link_id": "t3_1gs6rdn",
                    "permalink": "/r/StableDiffusion/comments/1gs6rdn/badly_generated_images/lxcfyw6/"
                }
            ]
        },
        {
            "id": "1gs6gri",
            "title": "Lora for multiple concepts? Ok or avoid?",
            "author": "X3liteninjaX",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731704104.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs6gri/lora_for_multiple_concepts_ok_or_avoid/",
            "permalink": "/r/StableDiffusion/comments/1gs6gri/lora_for_multiple_concepts_ok_or_avoid/",
            "selftext": "I'm training out a lora for some concepts I feel that Flux is lacking in. I've been using OneTrainer and am producing some really good loras. However, as expected, using multiple loras in generations can have a negative effect on the output. \n\n**Would using OneTrainer's \"concepts\" section to bake multiple concepts into one lora work and make sense?** \n\nThe concepts are not totally different but they are distinct enough that I originally planned to do multiple loras. My issue though is that two loras at 1.0 weights seem to be the limit before the quality starts to nosedive and I'm trying to combat this as best as I can. I'm aware there probably isn't an ideal solution but I'd love to hear what you guys would recommend. Thanks in advance.",
            "comments": [
                {
                    "id": "lxcebau",
                    "author": "chickenofthewoods",
                    "body": "I've had success training multi-concept loras.  My most successful one was trained on 6 different species of mushroom, and the trigger would evoke them really well and it learned the mushrooms well enough to be convincing images.\n\nHowever, I don't think I've tried to call on the separate concepts together in one generation.  In fact, when I called on the separate concepts in one prompt they blended together so well that my results were very fun and interesting.\n\nI don't think training separate objects or characters into one lora will let you create an image with multiple characters without bleeding and blending.  \n\nRegional prompting may be what you are looking for if you haven't tried that.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731710958.0,
                    "parent_id": "t3_1gs6gri",
                    "link_id": "t3_1gs6gri",
                    "permalink": "/r/StableDiffusion/comments/1gs6gri/lora_for_multiple_concepts_ok_or_avoid/lxcebau/"
                },
                {
                    "id": "lxbttsn",
                    "author": "AuryGlenz",
                    "body": "If the objects are very different, it can work. \n\nOtherwise doing a lokr with SimpleTuner would probably work better, but that’s another can of worms.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704460.0,
                    "parent_id": "t3_1gs6gri",
                    "link_id": "t3_1gs6gri",
                    "permalink": "/r/StableDiffusion/comments/1gs6gri/lora_for_multiple_concepts_ok_or_avoid/lxbttsn/"
                },
                {
                    "id": "lxcek8o",
                    "author": "chickenofthewoods",
                    "body": "Oh maybe this could help:\n\nhttps://civitai.com/models/929592?modelVersionId=1040555",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711043.0,
                    "parent_id": "t1_lxcebau",
                    "link_id": "t3_1gs6gri",
                    "permalink": "/r/StableDiffusion/comments/1gs6gri/lora_for_multiple_concepts_ok_or_avoid/lxcek8o/"
                }
            ]
        },
        {
            "id": "1gs6ch8",
            "title": "Procedurally generated prompt engineering advice",
            "author": "Quantumtroll",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731703784.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs6ch8/procedurally_generated_prompt_engineering_advice/",
            "permalink": "/r/StableDiffusion/comments/1gs6ch8/procedurally_generated_prompt_engineering_advice/",
            "selftext": "Brief background: I've got a pet project that generates a galaxy filled with thousands of alien organisms in a big evolutionary tree, from single-celled to sessile phototrophs to ones that build an interstellar civilisation.\n\nI've just started trying to generate pictures of these things, and I've come upon a very expected problem — two closely related species often end up looking very different from one another.\n\nMy question: I'm a noob at StableDiffusion prompt engineering. Can any of you give me tips, advice, pointers, or (god forbid) a solution? \n\nSome more context: \n\n* I'm only generating images for organisms the user/player wants to see, when they click a button.\n* The system does know the evolutionary relationship/distance between any two organisms.\n* Organisms are pretty \"feature rich\", with up to 30 or more traits that may or may not be macroscopically visible.\n* I use an LLM to describe the organism based on the list of traits. I suspect tweaking the way this prompt generation works is an avenue to explore.\n* I can get a pretty uniform style of image by asking for a \"zoological diagram of the following creature\". Any uniform look would be great, honestly.",
            "comments": [
                {
                    "id": "lxefw56",
                    "author": "Quantumtroll",
                    "body": "Sooo  not the right place for questions then.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731742087.0,
                    "parent_id": "t3_1gs6ch8",
                    "link_id": "t3_1gs6ch8",
                    "permalink": "/r/StableDiffusion/comments/1gs6ch8/procedurally_generated_prompt_engineering_advice/lxefw56/"
                }
            ]
        },
        {
            "id": "1gs48tj",
            "title": "Pony Diffusion For Commercial Use",
            "author": "Barkito",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 7,
            "created_utc": 1731698209.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/",
            "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/",
            "selftext": "Hello, I was wondering if I can use a Pony based checkpoint for commercial use mainly for some parts of a game art, and if I am allowed anything I have to do? Like sharing Pony license. Thank you!",
            "comments": [
                {
                    "id": "lxbbaqg",
                    "author": "Herr_Drosselmeyer",
                    "body": "Depends on the model but at least for base pony, the answer is yes. From the license they use:\n\n>The Output You Generate.\n\n>Except as set forth herein, Licensor claims no rights in the Output You generate using\n\n>the Model. You are accountable for the Output you generate and its subsequent uses. No\n\n>use of the output can contravene any provision as stated in the License.\n\nSo any image you generate can be used however you see fit (unless otherwise illegal, of course). This is the same for most models though you may want to check on a case by case basis.\n\nTLDR: it's fine to use generated images for your game.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731698770.0,
                    "parent_id": "t3_1gs48tj",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxbbaqg/"
                },
                {
                    "id": "lxcknel",
                    "author": "VisualMojo",
                    "body": "You will need a Community License from Stability AI for commercial use- sign up is free...  [https://stability.ai/license](https://stability.ai/license)",
                    "score": -3,
                    "upvotes": -3,
                    "downvotes": 0,
                    "created_utc": 1731713186.0,
                    "parent_id": "t3_1gs48tj",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxcknel/"
                },
                {
                    "id": "lxbc1iu",
                    "author": "Barkito",
                    "body": "Thank you, and do you know if I need to buy commercial license for SDXL?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731698994.0,
                    "parent_id": "t1_lxbbaqg",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxbc1iu/"
                },
                {
                    "id": "lxdnqz4",
                    "author": "kyuubi840",
                    "body": "This is for SD3 and SDXL Turbo, not Pony or SDXL",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728181.0,
                    "parent_id": "t1_lxcknel",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxdnqz4/"
                },
                {
                    "id": "lxbfp9l",
                    "author": "Herr_Drosselmeyer",
                    "body": "No. Straight from Stability AI's site [https://stability.ai/community-license-agreement](https://stability.ai/community-license-agreement) :\n\n>(iii) *Ownership of Outputs.* As between You and Stability AI, You own any outputs generated from the Models or Derivative Works to the extent permitted by applicable law. \n\nGenerally speaking, outputs are almost never restricted. This is mostly, imho, because proving that an image was created using a specific model is quite difficult and copyright on AI generated is also something that would be a major hurdle if the creator of a model would attempt to sue.\n\nSome creators may attempt to place restrictions on the outputs but I doubt they would be successful in enforcing them.\n\nOn the flip side, it also means you will have trouble preventing others from using your game's art assets. The game itself will be covered by copyright but the AI generated assets probably won't.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731700148.0,
                    "parent_id": "t1_lxbc1iu",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxbfp9l/"
                },
                {
                    "id": "lxdpl7r",
                    "author": "VisualMojo",
                    "body": "Oh, I see now- thanks...I got confused there... [https://ponydiffusion.com/faq](https://ponydiffusion.com/faq)\n\n# Can Pony Diffusion be used for commercial purposes?\n\nYes, Pony Diffusion is available under the CreativeML OpenRAIL-M license, permitting commercial use and redistribution. However, certain restrictions apply, such as the prohibition of using the model to generate illegal or harmful content.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731728925.0,
                    "parent_id": "t1_lxdnqz4",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxdpl7r/"
                },
                {
                    "id": "lxbkt5u",
                    "author": "Barkito",
                    "body": "Thank you <3",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731701710.0,
                    "parent_id": "t1_lxbfp9l",
                    "link_id": "t3_1gs48tj",
                    "permalink": "/r/StableDiffusion/comments/1gs48tj/pony_diffusion_for_commercial_use/lxbkt5u/"
                }
            ]
        },
        {
            "id": "1gs3vg1",
            "title": "How can I do this online? (Openpose Controlnet)",
            "author": "dietpapita",
            "score": 105,
            "upvotes": 105,
            "downvotes": 0,
            "num_comments": 33,
            "created_utc": 1731697280.0,
            "url": "https://i.redd.it/pej7suvw441e1.png",
            "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/",
            "selftext": "",
            "comments": [
                {
                    "id": "lxb98y7",
                    "author": "KrasterII",
                    "body": "You can use on Tensor.Art.",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731698153.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxb98y7/"
                },
                {
                    "id": "lxbobgb",
                    "author": "ImNotARobotFOSHO",
                    "body": "Where can we get this fine open pose template?",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731702784.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbobgb/"
                },
                {
                    "id": "lxdexvw",
                    "author": "decker12",
                    "body": "My first thought was to skip any turnkey online services that may or may not have what you want, and put $20 into Runpod and do it there, using a 48GB A40, for 35 cents an hour. You can load anything you want on it and if you're unsure WHAT you need, just select a template that already has all the extensions you could possible want, and use it's settings and download your own models to it.\n\nWhen you're done for the day, just delete the Runpod. Your $20 will last you a month and at no time will you have to worry about VRAM or your GPU screaming and warming up your whole house.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731724681.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdexvw/"
                },
                {
                    "id": "lxb6d9e",
                    "author": "dietpapita",
                    "body": "I'm trying to create a character sheet for an animation film using controlnet. Unfortunately, I don't have a PC powerful enough to run models locally. Is there a way I can do this online?",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731697291.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxb6d9e/"
                },
                {
                    "id": "lxbzr64",
                    "author": "3deal",
                    "body": "I have an Idea of a controlnet.  \nMaking consistant character with this placeholder as image input.  \nFirst step, create an image using this template, step two, use an other sampling using the constency controlnet to create consistant character without using Lora.  \nWho can train this type of controlnet for Flux ?\n\nI just have 24Gb of Vram, but i can help for the dataset.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731706265.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbzr64/"
                },
                {
                    "id": "lxba4yw",
                    "author": "CodeMichaelD",
                    "body": "start with something? i.e. [https://zhuyu1997.github.io/open-pose-editor/](https://zhuyu1997.github.io/open-pose-editor/)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731698422.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxba4yw/"
                },
                {
                    "id": "lxc0ha1",
                    "author": "zit_abslm",
                    "body": "Runcomfy has it as a template you don't need to setup anything.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731706486.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxc0ha1/"
                },
                {
                    "id": "lxcc67j",
                    "author": "mohamed_am83",
                    "body": "You can run inference here with controlnet\n\n[https://cogniwerk.ai/run-model/flux-dev](https://cogniwerk.ai/run-model/flux-dev)\n\nI managed to create a passable character sheet with minimal prompting. ~~The side view is funky though!~~ Edit: got better results with a different seed!  \n  \nprompt used:\n\n>create a character sheet of a man with various poses. the man has mustache, glasses. dressed in shirt.. without beard. brown hair. 3d. headshots should look straight, not angled and not looking up or down. plain background.\n\n\n\nhttps://preview.redd.it/xw9bp9zwa71e1.png?width=1024&format=png&auto=webp&s=7a35d7d077922b5808b15616f9c5395ef09fb138",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731710234.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxcc67j/"
                },
                {
                    "id": "lxdbcox",
                    "author": "Enshitification",
                    "body": "That workflow is from Mickmumpitz' channel      \nhttps://www.youtube.com/watch?v=Uls_jXy9RuU",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731723248.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdbcox/"
                },
                {
                    "id": "lxe0aa9",
                    "author": "itsjimnotjames",
                    "body": "I previously used runpod but the startup times are hellacious. I started using mimicpc instead. Not quite as cheap as runpod (50 cents or $1/hr vs .35 cents on an A4).",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733641.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxe0aa9/"
                },
                {
                    "id": "lxe2w3x",
                    "author": "cgpixel23",
                    "body": "you can check this tutorial [https://youtu.be/v7PWCpYyaKE](https://youtu.be/v7PWCpYyaKE)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735106.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxe2w3x/"
                },
                {
                    "id": "lxbax8b",
                    "author": "agent_wolfe",
                    "body": "Bookmarked!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698657.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbax8b/"
                },
                {
                    "id": "lxcp7qk",
                    "author": "ExhYZ",
                    "body": "Maybe this: https://huggingface.co/spaces/InstantX/InstantID",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731714848.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxcp7qk/"
                },
                {
                    "id": "lxbbwf5",
                    "author": "unitedpanjab",
                    "body": "Just did it today with the exact tutorial dm for more",
                    "score": -4,
                    "upvotes": -4,
                    "downvotes": 0,
                    "created_utc": 1731698950.0,
                    "parent_id": "t3_1gs3vg1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbbwf5/"
                },
                {
                    "id": "lxcxmk5",
                    "author": "abahjajang",
                    "body": "https://preview.redd.it/g1didubiu51e1.png?width=1421&format=png&auto=webp&s=f39900305219289e32d16406208c60d0cad949a9\n\nYes the site does it.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731717966.0,
                    "parent_id": "t1_lxb98y7",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxcxmk5/"
                },
                {
                    "id": "lxc0c3k",
                    "author": "TheDailySpank",
                    "body": "https://preview.redd.it/2lorhmp4w41e1.png?width=2028&format=png&auto=webp&s=9a4403d201a1ade3d9b6666831680a12a3dd72b2\n\nThe original poster of this image said to use it in a different post either here in r/StableDiffusion or r/comfyui\n\nEDIT: It was [https://www.reddit.com/r/comfyui/comments/1g38upw/what\\_would\\_be\\_the\\_easiest\\_way\\_to\\_make\\_a\\_character/](https://www.reddit.com/r/comfyui/comments/1g38upw/what_would_be_the_easiest_way_to_make_a_character/) and I mixed up who posted it with top comment referring to their superhero pose maker.",
                    "score": 18,
                    "upvotes": 18,
                    "downvotes": 0,
                    "created_utc": 1731706443.0,
                    "parent_id": "t1_lxbobgb",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxc0c3k/"
                },
                {
                    "id": "lxbhpi2",
                    "author": "Positive-Motor-5275",
                    "body": "Runpod + comfyui",
                    "score": 11,
                    "upvotes": 11,
                    "downvotes": 0,
                    "created_utc": 1731700763.0,
                    "parent_id": "t1_lxb6d9e",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbhpi2/"
                },
                {
                    "id": "lxbcq6a",
                    "author": "CodeMichaelD",
                    "body": "If your ram is enough just use FastSDCpu. It's slow, but it just works out of the box, intel and amd.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731699206.0,
                    "parent_id": "t1_lxb6d9e",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbcq6a/"
                },
                {
                    "id": "lxbaq10",
                    "author": "dietpapita",
                    "body": "I have the openpose image file. But I want to find a way to run the controlnet online.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731698597.0,
                    "parent_id": "t1_lxba4yw",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbaq10/"
                },
                {
                    "id": "lxdqguh",
                    "author": "dietpapita",
                    "body": "Thanks mate! I'll try that :)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729280.0,
                    "parent_id": "t1_lxc0ha1",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdqguh/"
                },
                {
                    "id": "lxcnbcb",
                    "author": "justifun",
                    "body": "Tried with the default settings (and using the wireframe image as an input image) but I only ended up with 6 - 3/4 angle heads.  What other settings did you adjust?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731714151.0,
                    "parent_id": "t1_lxcc67j",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxcnbcb/"
                },
                {
                    "id": "lxdq1wl",
                    "author": "dietpapita",
                    "body": "Yeah, I've tried a similar approach on replicate with flux dev. But faced the same problem. I need the views to be consistent and \"non funky\", as I want to train a lora on the upscaled character sheet.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729109.0,
                    "parent_id": "t1_lxcc67j",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdq1wl/"
                },
                {
                    "id": "lxdpog4",
                    "author": "dietpapita",
                    "body": "yes, it is. But I'm trying to figure out how to do it online. I don't have a powerful PC :/",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728960.0,
                    "parent_id": "t1_lxdbcox",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdpog4/"
                },
                {
                    "id": "lxe33qi",
                    "author": "dietpapita",
                    "body": "I just learnt about runcomfy. They have ready-to-run workflows as well. I found this one for my problem statement: [https://www.runcomfy.com/comfyui-workflows/flux-consistent-characters-input-image](https://www.runcomfy.com/comfyui-workflows/flux-consistent-characters-input-image)\n\nIt was really easy to run, and the speed is good too.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735213.0,
                    "parent_id": "t1_lxe0aa9",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxe33qi/"
                },
                {
                    "id": "lxbpofl",
                    "author": "lifeofrevelations",
                    "body": "Just post it here so everyone can see it",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731703195.0,
                    "parent_id": "t1_lxbbwf5",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxbpofl/"
                },
                {
                    "id": "lxdr112",
                    "author": "dietpapita",
                    "body": "Thanks! I'll try it :)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729514.0,
                    "parent_id": "t1_lxcxmk5",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdr112/"
                },
                {
                    "id": "lxcrkrm",
                    "author": "ImNotARobotFOSHO",
                    "body": "Thank you sir",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731715725.0,
                    "parent_id": "t1_lxc0c3k",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxcrkrm/"
                },
                {
                    "id": "lxdrdj7",
                    "author": "Helpful-Birthday-388",
                    "body": "Where i get original image ?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729662.0,
                    "parent_id": "t1_lxc0c3k",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdrdj7/"
                },
                {
                    "id": "lxe0a1a",
                    "author": "dietpapita",
                    "body": "Really good suggestion! I tried it and it really is easy to use. Very good for beginners like me. Thanks a ton! :)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733637.0,
                    "parent_id": "t1_lxdqguh",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxe0a1a/"
                },
                {
                    "id": "lxe3iku",
                    "author": "mohamed_am83",
                    "body": "I used: Human-AI collaboration: 10, under controlnet I unchecked \"auto detection\", expanded advanced, set \"control weight\" to the max and left controlnet influence from 0 to 1.\n\nThis seed seems to work 456791.\n\nhttps://preview.redd.it/ke58kc7h971e1.png?width=1024&format=png&auto=webp&s=c6ab0623998404f0a5b1f571dd3af96272e4748b",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735417.0,
                    "parent_id": "t1_lxcnbcb",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxe3iku/"
                },
                {
                    "id": "lxdr9xz",
                    "author": "Enshitification",
                    "body": "Whoops. That was supposed to be a response to another comment rather than a direct answer to you. I guess you could spin up a Runpod or rent some GPU time on vast.ai. It's a pretty VRAM hungry workflow. It takes almost all of my 4090 VRAM when it runs.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731729619.0,
                    "parent_id": "t1_lxdpog4",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxdr9xz/"
                },
                {
                    "id": "lxd9b6d",
                    "author": "TheDailySpank",
                    "body": "Thank OP in the linked post. I just remembered I saved it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731722449.0,
                    "parent_id": "t1_lxcrkrm",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxd9b6d/"
                },
                {
                    "id": "lxds1jg",
                    "author": "TheDailySpank",
                    "body": "In the edit I made before you asked?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729955.0,
                    "parent_id": "t1_lxdrdj7",
                    "link_id": "t3_1gs3vg1",
                    "permalink": "/r/StableDiffusion/comments/1gs3vg1/how_can_i_do_this_online_openpose_controlnet/lxds1jg/"
                }
            ]
        },
        {
            "id": "1gs3tc2",
            "title": "How can I do this online? (Openpose Controlnet)",
            "author": "dietpapita",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731697144.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs3tc2/how_can_i_do_this_online_openpose_controlnet/",
            "permalink": "/r/StableDiffusion/comments/1gs3tc2/how_can_i_do_this_online_openpose_controlnet/",
            "selftext": "https://preview.redd.it/w5s0850e441e1.png?width=1920&format=png&auto=webp&s=89a38754836f28dc5990e464192a233b1050c39d\n\nI'm trying to create a character sheet for an animation film using controlnet. Unfortunately, I don't have a PC powerful enough to run models locally. Is there a way I can do this online?",
            "comments": [
                {
                    "id": "lxb8nek",
                    "author": "weshouldhaveshotguns",
                    "body": "you could run comfyui on runpod or something similar.  youll have to pay to use their GPUs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731697973.0,
                    "parent_id": "t3_1gs3tc2",
                    "link_id": "t3_1gs3tc2",
                    "permalink": "/r/StableDiffusion/comments/1gs3tc2/how_can_i_do_this_online_openpose_controlnet/lxb8nek/"
                },
                {
                    "id": "lxb996w",
                    "author": "dietpapita",
                    "body": "Is there a simpler way? Like running a model on replicate/huggingface? Sorry if that's a noob question. I'm new to this.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698155.0,
                    "parent_id": "t1_lxb8nek",
                    "link_id": "t3_1gs3tc2",
                    "permalink": "/r/StableDiffusion/comments/1gs3tc2/how_can_i_do_this_online_openpose_controlnet/lxb996w/"
                },
                {
                    "id": "lxbd4x2",
                    "author": "weshouldhaveshotguns",
                    "body": "You may be getting ahead of yourself. This is not the simplest of workflows. But, easiest way I can think of would be find the .json of the workflow you want to emulate, and use comfyui on rundiffusion to avoid some of the more technical stuff of setting up on runpod. Import the workflow, your input and press the queue button, pray that it works right the first time lol There may be a way to use it on some of the more user friendly UIs, but I'm not sure.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731699332.0,
                    "parent_id": "t1_lxb996w",
                    "link_id": "t3_1gs3tc2",
                    "permalink": "/r/StableDiffusion/comments/1gs3tc2/how_can_i_do_this_online_openpose_controlnet/lxbd4x2/"
                }
            ]
        },
        {
            "id": "1gs37rm",
            "title": "What checkpoint do you use with Ultimate Upscale? (SD 1.5)",
            "author": "Unwitting_Observer",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 5,
            "created_utc": 1731695584.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/",
            "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/",
            "selftext": "Edit: Specifically asking about the Checkpoint...I think I'm happy with my upscale model [https://github.com/Phhofm/models/releases/4xNomos8k\\_atd\\_jpg](https://github.com/Phhofm/models/releases/4xNomos8k_atd_jpg) )\n\nI know most are probably just plugging in the checkpoint that was used to generate the source image, but wondering if anyone has found a specific checkpoint that gives better results than others.",
            "comments": [
                {
                    "id": "lxbcat8",
                    "author": "Calm_Mix_3776",
                    "body": "For realistic stuff, most of the time I use [Photon](https://civitai.com/models/84728/photon) and [STOIQO NewReality](https://civitai.com/models/161068?modelVersionId=634949). I'm also interested to know what others prefer, especially for realistic images.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731699073.0,
                    "parent_id": "t3_1gs37rm",
                    "link_id": "t3_1gs37rm",
                    "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/lxbcat8/"
                },
                {
                    "id": "lxdrehs",
                    "author": "CesarEric",
                    "body": "[majicmix-realistic](https://civitai.com/models/43331/majicmix-realistic) and lora [sdxlrender](https://civitai.com/models/171159/sdxlrender)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731729673.0,
                    "parent_id": "t3_1gs37rm",
                    "link_id": "t3_1gs37rm",
                    "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/lxdrehs/"
                },
                {
                    "id": "lxb34eg",
                    "author": "weshouldhaveshotguns",
                    "body": "I use 4x-ultrasharp to upscale from flux.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696331.0,
                    "parent_id": "t3_1gs37rm",
                    "link_id": "t3_1gs37rm",
                    "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/lxb34eg/"
                },
                {
                    "id": "lxc8mya",
                    "author": "Unwitting_Observer",
                    "body": "Thanks...I just started using Photon and it seems great...will check out New Reality, it looks promising. Have you used the Flux version of that?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731709065.0,
                    "parent_id": "t1_lxbcat8",
                    "link_id": "t3_1gs37rm",
                    "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/lxc8mya/"
                },
                {
                    "id": "lxckadc",
                    "author": "Calm_Mix_3776",
                    "body": "Yes, I have used the Flux version of STOIQO. I think it's pretty good at tiled upscaling of photos.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731713054.0,
                    "parent_id": "t1_lxc8mya",
                    "link_id": "t3_1gs37rm",
                    "permalink": "/r/StableDiffusion/comments/1gs37rm/what_checkpoint_do_you_use_with_ultimate_upscale/lxckadc/"
                }
            ]
        },
        {
            "id": "1gs293k",
            "title": "Can you recommend me SD1.5 Models?",
            "author": "mobaisland",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 26,
            "created_utc": 1731693175.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/",
            "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/",
            "selftext": "Hi can you recommend me some regular sd1.5 models from civitAI please?\n\nI am using them with DrawThings app, but somehow most of the models are trained for p\\*rn hent\\*i and nsf\\*... I am struggling to find a stable model that generates normal AI like Chatgpt or Bing...\n\nThank you 🫶🏻",
            "comments": [
                {
                    "id": "lxax7r7",
                    "author": "Nyao",
                    "body": "DreamShaper is a good SD 1.5 general model : https://civitai.com/models/4384/dreamshaper",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731694589.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxax7r7/"
                },
                {
                    "id": "lxcgo40",
                    "author": "Same-Pizza-6724",
                    "body": "Unfortunately the best 1.5 models for realism will always be NSFW.\n\nBut if you....\n\nAlways prompt clothes, and neg \"(naked:1.2), nude, (nipples:1.2), NSFW,\" then you shouldn't have a problem with any checkpoint.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731711776.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxcgo40/"
                },
                {
                    "id": "lxayjqw",
                    "author": "pumukidelfuturo",
                    "body": "Photorealistic, Cyberrealistic. For \"styles\" probably Dreamshaper which is really old... maybe Juggernaut? SDXL has a lot more variety in the \"western art\" department checkpoints.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731694982.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxayjqw/"
                },
                {
                    "id": "lxaziht",
                    "author": "Version-Strong",
                    "body": "[https://deliberate.pro/](https://deliberate.pro/)\n\nDeliberate was my go to model on 1.5 for ages. He has a SFW version too. Brilliant model.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731695264.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxaziht/"
                },
                {
                    "id": "lxcq81u",
                    "author": "OwnPomegranate5906",
                    "body": "realistic universal base build: https://civitai.com/models/839017/realistic-universal-base-build\n\nIts a merge of a bunch of realistic models (including newer ones) that have fine tuning and don't have licensing restrictions.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731715218.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxcq81u/"
                },
                {
                    "id": "lxd0pif",
                    "author": "Shockbum",
                    "body": "I used for fun one called Paragon 1.0 before SDXL and Flux, it wasn't the best but it was the most versatile I found.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731719132.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxd0pif/"
                },
                {
                    "id": "lxdc3b0",
                    "author": "Mundane-Apricot6981",
                    "body": "So you put porn prompts and blaming model that it follows YOURS prompts?  \nALL models can output NSFW - even official censored vanilla SD 1.5. Specifically for such cases all models have mandatory NSFW filter.  \n  \nDo you know why Bing and GPT not output nudity?  \nJust because they filter prompts.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731723540.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxdc3b0/"
                },
                {
                    "id": "lxdnk18",
                    "author": "Botoni",
                    "body": "The best would be that you could use ELLA, it improves a lot the prompt understanding and adherence and tones down the NSFW nature of the sd1.5 models, because it uses a text encoder not trained in that concepts I guess. As for the model, use anything that looks made for general use and not for explicit content.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728104.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxdnk18/"
                },
                {
                    "id": "lxatsqz",
                    "author": "Ubuntu_20_04_LTS",
                    "body": "The base model of 1.5 was trained with moderate nudity. If you don't want that, you should just use Flux.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731693566.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxatsqz/"
                },
                {
                    "id": "lxbcgkw",
                    "author": "Mutaclone",
                    "body": "I don't know which models would be *guaranteed* to not produce nsfw, but generally I've found that doing the following is enough:\n\n- Put \"nsfw\" in the negative prompt.  If you want to go further you can do \"nsfw, naked, nude\"\n- In the main prompt describe the subject(s)'s clothes.  It doesn't need to be detailed - it can be as simple as \"business attire\" or \"brown jacket, jeans\".  Just something to steer the model towards giving them an outfit of some kind.\n- I don't know if this helps or is a coincidence, but almost all my prompts describe a scene and/or activity (outdoor cafe, library, etc).  This gives the model even more context which might help steer things in a more sfw direction than just describing a person without any context.\n\nFor me, this has worked for the overwhelming majority of models I've used.  For the rare cases it doesn't, I just toss the model and try another one.\n\nOne final note, some models (especially anime ones) were trained using \"quality\" tags (e.g. \"masterpiece\").  In some cases, \"quality\" was determined by user rating on whatever board the image came from.  This had the unfortunate side effect of pushing the images in a more nsfw direction.  So you could also try cutting out \"masterpiece\" if you're using it, and if the model doesn't work without it try a different one.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731699123.0,
                    "parent_id": "t3_1gs293k",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbcgkw/"
                },
                {
                    "id": "lxay1vo",
                    "author": "mobaisland",
                    "body": "Thank you will try it right now",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731694836.0,
                    "parent_id": "t1_lxax7r7",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxay1vo/"
                },
                {
                    "id": "lxcqogz",
                    "author": "mobaisland",
                    "body": "Different topic but may I ask how does copyrighting works with AI? I mean how can be AI generated images be copyrighted, who knows what is made with what, if I generate a tree image who will know how many licensed tree images used in it?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731715390.0,
                    "parent_id": "t1_lxcq81u",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxcqogz/"
                },
                {
                    "id": "lxdkctf",
                    "author": "mobaisland",
                    "body": "Did I mention my prompts anywhere? It adds nipples to a monster generated by a prompt like this \"a giant monster shredding a house\" or even makes the monster as an atractive woman",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731726852.0,
                    "parent_id": "t1_lxdc3b0",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxdkctf/"
                },
                {
                    "id": "lxavd3o",
                    "author": "mobaisland",
                    "body": "My macbook air m1 only works great with sd1.5 but I can try some flux models if you suggest me some please",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731694035.0,
                    "parent_id": "t1_lxatsqz",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxavd3o/"
                },
                {
                    "id": "lxcwgbx",
                    "author": "OwnPomegranate5906",
                    "body": "Depending on how a model is licensed, you either have to give credit, or can't share model merges, or can't use it on a publicly available generation service, or any other licensing restrictions that have been spelled out for a given model.  The models that have no license restrictions, you can pretty much do whatever you want with it, whereever you want with it, whenever you want with it.\n\nThat being said, I don't think there's actually been a good legal precedent set for actually enforcing model licensing restrictions other than sites like civitai make you select a license type if you want them to host it, and they follow the licensing for that model with their own generation service.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731717532.0,
                    "parent_id": "t1_lxcqogz",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxcwgbx/"
                },
                {
                    "id": "lxbd0f3",
                    "author": "Mutaclone",
                    "body": "For a Macbook Air I wouldn't recommend Flux - it's got harsher hardware requirements than SDXL.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731699294.0,
                    "parent_id": "t1_lxavd3o",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbd0f3/"
                },
                {
                    "id": "lxazyfs",
                    "author": "Ubuntu_20_04_LTS",
                    "body": "How much VRAM do you have? Q4 is the most memory efficient Flux model you can go: [https://huggingface.co/city96/FLUX.1-dev-gguf/blob/main/flux1-dev-Q4\\_0.gguf](https://huggingface.co/city96/FLUX.1-dev-gguf/blob/main/flux1-dev-Q4_0.gguf)\n\nYou also need to load CLIP and VAE so 8G VRAM would be recommended.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731695396.0,
                    "parent_id": "t1_lxavd3o",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxazyfs/"
                },
                {
                    "id": "lxbfuit",
                    "author": "mobaisland",
                    "body": "Is sdxl better than 1.5 ?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700194.0,
                    "parent_id": "t1_lxbd0f3",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbfuit/"
                },
                {
                    "id": "lxb1b23",
                    "author": "mobaisland",
                    "body": "Depeding on google results, none :) It says 'None. It is shared with main memory.'\n\nTo be honest I don't know how to setup those clip, vae etc.   \nIn drawthings I basically go manage modals, paste the civitai model and it is done after downloading automatically ready to use.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731695793.0,
                    "parent_id": "t1_lxazyfs",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxb1b23/"
                },
                {
                    "id": "lxbjn78",
                    "author": "Arcival_2",
                    "body": "It's more consistent with the prompt usually.Better or worse depends on the person, in my opinion sdxl is great for consistency and quality while sd1.5 is great for its hallucinations (some images have a unique style) , let's say sd1.5 might surprise or shock you.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731701352.0,
                    "parent_id": "t1_lxbfuit",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbjn78/"
                },
                {
                    "id": "lxbls21",
                    "author": "Mutaclone",
                    "body": "It took a while to get there but I like it a bit better (SD.15 is still good though).  My comment was more in relation to hardware requirements:\n\nFlux > SDXL > 1.5\n\n1.5 came out first and has the lightest hardware requirements.  SDXL is newer and can create images at higher resolutions, but requires more memory.  Flux is the newest.  I have a MBP and Flux takes ~5-6 min to render a single image if I use the dev version at 20 steps.  There's a schnell version which is slightly worse but only needs 2-4 steps, and that takes around 1 min.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731702006.0,
                    "parent_id": "t1_lxbfuit",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbls21/"
                },
                {
                    "id": "lxb2bo1",
                    "author": "Ubuntu_20_04_LTS",
                    "body": "I see. Have you tried adding nsfw/hentai/nude in your negative prompt? It should work reasonably well with 1.5",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696095.0,
                    "parent_id": "t1_lxb1b23",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxb2bo1/"
                },
                {
                    "id": "lxb9hvd",
                    "author": "red__dragon",
                    "body": "> Depeding on google results, none :) It says 'None. It is shared with main memory.'\n\nMac VRAM and System RAM is shared, yes. How much system RAM do you have?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698228.0,
                    "parent_id": "t1_lxb1b23",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxb9hvd/"
                },
                {
                    "id": "lxb5xn1",
                    "author": "mobaisland",
                    "body": "Yes I am always adding but it seems like its just giving them clothes but the human portraits usually have some sexual style, even monsters have nipples",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731697161.0,
                    "parent_id": "t1_lxb2bo1",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxb5xn1/"
                },
                {
                    "id": "lxbfe2e",
                    "author": "mobaisland",
                    "body": "8GB",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700047.0,
                    "parent_id": "t1_lxb9hvd",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxbfe2e/"
                },
                {
                    "id": "lxc2hlu",
                    "author": "Ubuntu_20_04_LTS",
                    "body": "lol…well, you can consider adding any words you don’t like to see: sexual, nipple, cleavage, etc. You can even emphasize the weight like (nipple: 2)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731707106.0,
                    "parent_id": "t1_lxb5xn1",
                    "link_id": "t3_1gs293k",
                    "permalink": "/r/StableDiffusion/comments/1gs293k/can_you_recommend_me_sd15_models/lxc2hlu/"
                }
            ]
        },
        {
            "id": "1gs28wf",
            "title": "SDXL and a little in-painting",
            "author": "EldrichArchive",
            "score": 15,
            "upvotes": 15,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731693162.0,
            "url": "https://i.redd.it/6a8o4rfss31e1.jpeg",
            "permalink": "/r/StableDiffusion/comments/1gs28wf/sdxl_and_a_little_inpainting/",
            "selftext": "",
            "comments": []
        },
        {
            "id": "1gs23wr",
            "title": "To all Researcher Scientists & Engineers, please tell me your pain!",
            "author": "MrForExample",
            "score": 5,
            "upvotes": 5,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731692813.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/",
            "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/",
            "selftext": "Hey all, I am [Mr. For Example](https://twitter.com/MrForExample), the author of [Comfy3D](https://github.com/MrForExample/ComfyUI-3D-Pack), because researchers worldwide aren't getting nearly enough of the support they need for the groundbreaking work they are doing, that’s why I’m thinking about build some tools to help researchers to save their time & energy\n\nSo, to all Researcher Scientists & Engineers, which of the following steps in the research process takes the most of your time or cost you the most pain?\n\n[View Poll](https://www.reddit.com/poll/1gs23wr)",
            "comments": [
                {
                    "id": "lxbhow4",
                    "author": "-techman-",
                    "body": "None of the above. It's writing grant applications.",
                    "score": 10,
                    "upvotes": 10,
                    "downvotes": 0,
                    "created_utc": 1731700758.0,
                    "parent_id": "t3_1gs23wr",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxbhow4/"
                },
                {
                    "id": "lxbzzjr",
                    "author": "lostinspaz",
                    "body": "Your post looks a little bit like cross-forum spam. Doesnt realy have anything specifically to do with stable diffusion, far as I can see.\n\nIn that vein, the most useful and relevant tool you could come up with, would be one with a collection of sliders and input boxes. Kind of like a mortgage calculator, but for SD.\n\nYou put in values for:\n\n\\- model type\n\n\\- training precision\n\n\\- dataset size\n\n\\- image resolution size range\n\n\\- Optimizer\n\n\\- Scheduler\n\n\\- Batch size\n\nThen it will have sliders for all the typical tunables like EMA values, LR, steps, epochs, ....  \nBut it will grey out ranges that are going to be stupid to use, given your inputs.\n\nAdditionally, it would estimate VRAM required.\n\nAnd/or it would let you specify a hard limit to VRAM, so it would pop up an error if you try to put in values that would exceed your VRAM.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731706336.0,
                    "parent_id": "t3_1gs23wr",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxbzzjr/"
                },
                {
                    "id": "lxccukl",
                    "author": "HarambeTenSei",
                    "body": "Libraries are never compatible with each other. Getting environments set up is a pain\n\n\nAlso tools like comfy may give a nice front end but what would really save my time would be a good python wrapper around the models and libraries themselves ",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731710461.0,
                    "parent_id": "t3_1gs23wr",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxccukl/"
                },
                {
                    "id": "lxb6wzb",
                    "author": "beti88",
                    "body": "Yeah, I don't think they're here",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731697454.0,
                    "parent_id": "t3_1gs23wr",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxb6wzb/"
                },
                {
                    "id": "lxe8odz",
                    "author": "Ambili_TS",
                    "body": "Setting up proper environment for running the code is painful. Need more effective containerization tool .",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731737911.0,
                    "parent_id": "t3_1gs23wr",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxe8odz/"
                },
                {
                    "id": "lxd041a",
                    "author": "Heart-of-Silicon",
                    "body": "It's called diffusers.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731718896.0,
                    "parent_id": "t1_lxccukl",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxd041a/"
                },
                {
                    "id": "lxb7hzc",
                    "author": "MrForExample",
                    "body": "Well, I know some of my researcher friends are here sometime, and I'm here, so with 500k+ member there should be at least 50+ of researchers here, sometime.  \nIf you know some better places, then please let me know, cheers",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731697629.0,
                    "parent_id": "t1_lxb6wzb",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxb7hzc/"
                },
                {
                    "id": "lxb71rs",
                    "author": "ThenExtension9196",
                    "body": "Haha seriously.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731697494.0,
                    "parent_id": "t1_lxb6wzb",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxb71rs/"
                },
                {
                    "id": "lxdkvm7",
                    "author": "HarambeTenSei",
                    "body": "It's also garbage ",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727058.0,
                    "parent_id": "t1_lxd041a",
                    "link_id": "t3_1gs23wr",
                    "permalink": "/r/StableDiffusion/comments/1gs23wr/to_all_researcher_scientists_engineers_please/lxdkvm7/"
                }
            ]
        },
        {
            "id": "1gs1ptw",
            "title": "Fluxgym with Arc a770?",
            "author": "fablevi321",
            "score": 3,
            "upvotes": 3,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731691825.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs1ptw/fluxgym_with_arc_a770/",
            "permalink": "/r/StableDiffusion/comments/1gs1ptw/fluxgym_with_arc_a770/",
            "selftext": "Hey, is it possible to use intel arc a770/a750 via openvino with Fluxgym? If it possible how can i do it?\nThanks for help:)",
            "comments": [
                {
                    "id": "lxc8fa7",
                    "author": "Najbox",
                    "body": "Yes, I managed to get it working on Ubuntu with an A770. I haven't tried on WSL.  \nFollow the normal installation instructions, then reinstall Pyrorch at the end:\n\npip install torch==2.6.0.dev20241115+xpu pytorch-triton-xpu==3.1.0+91b14bf559 torchvision==0.20.0.dev20241115+xpu torchaudio==2.5.0.dev20241115+xpu torchao==0.7.0.dev20241113+xpu --index-url [https://download.pytorch.org/whl/nightly/xpu](https://download.pytorch.org/whl/nightly/xpu)\n\npip installer Torchmetrics\n\nedit the file \"fluxgym/sd-scripts/library/flux\\_models.py\" at line 459 replace dtype=torch.float64 with dtype=torch.bfloat16",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731708994.0,
                    "parent_id": "t3_1gs1ptw",
                    "link_id": "t3_1gs1ptw",
                    "permalink": "/r/StableDiffusion/comments/1gs1ptw/fluxgym_with_arc_a770/lxc8fa7/"
                },
                {
                    "id": "lxe5150",
                    "author": "fablevi321",
                    "body": "I love you, thanks♥️♥️",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731736128.0,
                    "parent_id": "t1_lxc8fa7",
                    "link_id": "t3_1gs1ptw",
                    "permalink": "/r/StableDiffusion/comments/1gs1ptw/fluxgym_with_arc_a770/lxe5150/"
                }
            ]
        },
        {
            "id": "1gs1gbo",
            "title": "AI Art Tool",
            "author": "Far_Pin7024",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731691159.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs1gbo/ai_art_tool/",
            "permalink": "/r/StableDiffusion/comments/1gs1gbo/ai_art_tool/",
            "selftext": "Hi everyone,\n\nI’m looking for an AI tool that lets me upload multiple photos (e.g., of people, pets, or objects) and combines them into a single, creative artwork. My goal is to create a personalized piece of art that integrates these images in a meaningful or artistic way.\n\nThere are so many AI art tools out there, and I’m unsure which one works best for this kind of task. Has anyone tried something similar? If so, what tool would you recommend for high-quality, creative results?\n\nThanks in advance for your suggestions!",
            "comments": [
                {
                    "id": "lxapx83",
                    "author": "TurbTastic",
                    "body": "Checkout OmniGen, relatively new",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731692414.0,
                    "parent_id": "t3_1gs1gbo",
                    "link_id": "t3_1gs1gbo",
                    "permalink": "/r/StableDiffusion/comments/1gs1gbo/ai_art_tool/lxapx83/"
                }
            ]
        },
        {
            "id": "1gs1c3h",
            "title": "New in lora training so need help",
            "author": "Elain_6",
            "score": 3,
            "upvotes": 3,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731690853.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs1c3h/new_in_lora_training_so_need_help/",
            "permalink": "/r/StableDiffusion/comments/1gs1c3h/new_in_lora_training_so_need_help/",
            "selftext": "Hi, ı want to make a style lora from those images. I have many of it. It's combinations of couple of artist's style and produced with NAI 3. I want to produce this with sdxl format and use it with pony diffusion, but every time pony's own style have much more impact to images. Am ı doing something wrong or is it imposible to use a style with sdxl models without changing the exact style. Would be very appreciated if get help. I have mobile rtx 4060 with 8 gb vram, maybe this is the reason. Btw it is the one from pixiv who created this \"**随机掉落的心理医生小姐\"**. Sorry for the typos, english is not my native.\n\nhttps://preview.redd.it/f1vuqtbem31e1.jpg?width=822&format=pjpg&auto=webp&s=b4ff6db609147dc79cfb436213814c9117702626\n\nhttps://preview.redd.it/2xfmmtbem31e1.jpg?width=822&format=pjpg&auto=webp&s=972c0e5471373147c55002c89324de9d4c3a4f3a",
            "comments": [
                {
                    "id": "lxbflxd",
                    "author": "Flimsy_Tumbleweed_35",
                    "body": "How many samples do you have? For a style you need more, ideally 50+.\n\n  \nAre you using base Pony or a merge?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700118.0,
                    "parent_id": "t3_1gs1c3h",
                    "link_id": "t3_1gs1c3h",
                    "permalink": "/r/StableDiffusion/comments/1gs1c3h/new_in_lora_training_so_need_help/lxbflxd/"
                },
                {
                    "id": "lxbk0j8",
                    "author": "Elain_6",
                    "body": "I tried with 50, 100, 200 samples but nothing worked. Also ı use pony and base xl separately, dont know anything on merge though.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731701466.0,
                    "parent_id": "t1_lxbflxd",
                    "link_id": "t3_1gs1c3h",
                    "permalink": "/r/StableDiffusion/comments/1gs1c3h/new_in_lora_training_so_need_help/lxbk0j8/"
                }
            ]
        },
        {
            "id": "1gs1az7",
            "title": "CUDA out of memory ONLY ON LINUX",
            "author": "vrili",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 13,
            "created_utc": 1731690773.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/",
            "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/",
            "selftext": "I’m encountering a “CUDA out of memory” error, but only on Linux. I’m using the same model, command line arguments, resolution, LoRAs, and prompts across platforms—everything is identical. I’ve tried rebooting my computer, reloading the model, and even reinstalling Stable Diffusion, but the issue persists.\n\nHere’s my setup:\n\n\t•\tStable Diffusion Web UI: Automatic1111\n\n\t•\tGPU: NVIDIA 2060 Super\n\n\t•\tOperating System: Linux Mint\n\nI’m not sure why this is happening on Linux but not on other operating systems. Any insights or suggestions? Yes I am using —medvram and it will work but I didn’t have to do this on Windows. Also, the medvram argument messes with the quality of the output image. So I don’t really wanna use that.",
            "comments": [
                {
                    "id": "lxamyo7",
                    "author": "Pretend_Potential",
                    "body": "The error occurs because you ran out of vram. Take a look at how you have your system set up with linux and ensure it's handling vram correctly",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731691532.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxamyo7/"
                },
                {
                    "id": "lxbk634",
                    "author": "Ok-Budget6619",
                    "body": "Windows allows Nvidia driver to fall back on system memory as a sort of extended vram. I don't think this feature is available in linux",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731701513.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxbk634/"
                },
                {
                    "id": "lxb34vc",
                    "author": "Paulonemillionand3",
                    "body": "maybe your windows drivers were swapping out to disk and these drivers are just aborting instead?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696335.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxb34vc/"
                },
                {
                    "id": "lxb8gx6",
                    "author": "ShengrenR",
                    "body": "Not a solution, but food to chew on:\n\nAutomatic1111 is essentially a python package - it relies on a BUNCH of OTHER python packages under the hood and builds a python software environment based on the requirements set forth in their launch script (they do a lot of really bad practice stuff for env management, but that's another story) - some of those packages will be fundamentally different between operating systems - they're compiled with different math libraries, or who knows - so you're absolutely, certainly, \\*not\\* in a case where \"everything is identical\" (e.g. 'pytorch v2.1' on win64 isn't 'pytorch v 2.1' on linux64.. your numpy may have different math libraries underlying the calls) - maybe a driver, maybe a package, maybe an underlying library - but it's very likely that something, somewhere has a very different process for loading a model or processing a request, which is why you get the difference. This could all just as well be BS and it's just some default option is flagged on in one place vs another - just know that your installations are for sure not identical and that might be a place to start teasing back where the issue comes from.\n\nWhile you're running in linux have \\`watch -n1 nvidia-smi\\` up in another window and see if you can see where it falls off the cliff, might be a point to start from.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731697919.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxb8gx6/"
                },
                {
                    "id": "lxcfzey",
                    "author": "Illustrious-Ad-6944",
                    "body": "first off i don't use linux. (often or really at all) but i think you could probably increase your swap file, i did the same thing on a windows system and it helped me.\n\n  \nthe first one talks about not using fallocate, and the 2nd one says to use fallocate, im no linux user so look into it yourself, but it is a thing. here the links\n\n1st: [https://www.howtogeek.com/455981/how-to-create-a-swap-file-on-linux/](https://www.howtogeek.com/455981/how-to-create-a-swap-file-on-linux/)\n\n2nd: [https://www.digitalocean.com/community/tutorials/how-to-add-swap-space-on-ubuntu-20-04](https://www.digitalocean.com/community/tutorials/how-to-add-swap-space-on-ubuntu-20-04)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711535.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxcfzey/"
                },
                {
                    "id": "lxddd27",
                    "author": "Mundane-Apricot6981",
                    "body": "If you enable logs - in most cases you will see something which you can use for Google and GPT.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731724044.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxddd27/"
                },
                {
                    "id": "lxdqluj",
                    "author": "Ken-g6",
                    "body": "11 hours and nobody's recommended Forge yet?  Try [Forge](https://github.com/lllyasviel/stable-diffusion-webui-forge/).  It's very similar to A1111, but it does things like handling memory better.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729338.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxdqluj/"
                },
                {
                    "id": "lxaspm7",
                    "author": "Arcival_2",
                    "body": "What desktop environment do you use? Linux usually relies on the GPU, which Windows rarely does. It could be that or the drivers which are a little interesting for Linux...",
                    "score": -1,
                    "upvotes": -1,
                    "downvotes": 0,
                    "created_utc": 1731693242.0,
                    "parent_id": "t3_1gs1az7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxaspm7/"
                },
                {
                    "id": "lxbyv50",
                    "author": "Striking_Pumpkin8901",
                    "body": "that is cuda not windows, and yes you can read the drivers documentation at least",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731705994.0,
                    "parent_id": "t1_lxbk634",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxbyv50/"
                },
                {
                    "id": "lxecsyj",
                    "author": "ArsNeph",
                    "body": "This. This is the answer.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731740200.0,
                    "parent_id": "t1_lxbk634",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxecsyj/"
                },
                {
                    "id": "lxaysqv",
                    "author": "MayorWolf",
                    "body": "Linux shells, even the most robust, are far less resource intensive than windows explorer.exe.  Linux desktops are commonly more lean than windows and it's insane that you're here saying otherwise so confidently. \n\nDude is using linux mint, which uses cinnamon or xfce. Both are objectively lighter shells than explorer.exe.\n\nThe issue likely is with his driver configuration.  On windows, it falls back to sysmem by default.  On linux, the driver configuration isn't set up for \"users\" and is meant more for system operators.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731695055.0,
                    "parent_id": "t1_lxaspm7",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxaysqv/"
                },
                {
                    "id": "lxbhmll",
                    "author": "iDeNoh",
                    "body": "This is 100% the cause. It's dipping into vram on windows and can't do that on Linux by default, not hard to hit oom conditions there.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700738.0,
                    "parent_id": "t1_lxaysqv",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxbhmll/"
                },
                {
                    "id": "lxbi0kq",
                    "author": "Arcival_2",
                    "body": "On Linux it is true that its desktop is lighter, but as I have often seen, many users install widgets and interfaces for everything, greatly weighing down the experience. And in that case the desktop, just like xfce, with Nvidia is very buggy (with 2 rtx 3090 it gives stuttering problems). The drivers, however, even if for \"expert operators\" are not yet up to speed with the Windows drivers; several applications that we have written for CUDA, even with the same driver versions and the same hardware, were much less performing in multi block in Linux (and usually we started from machines with Linux, realizing it later when they also asked us for the Windows versions).",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700854.0,
                    "parent_id": "t1_lxaysqv",
                    "link_id": "t3_1gs1az7",
                    "permalink": "/r/StableDiffusion/comments/1gs1az7/cuda_out_of_memory_only_on_linux/lxbi0kq/"
                }
            ]
        },
        {
            "id": "1gs13yz",
            "title": "What \"prompts\" did you find most effective with \"CogVideoX\"? ",
            "author": "Successful_AI",
            "score": 10,
            "upvotes": 10,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731690290.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/",
            "permalink": "/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/",
            "selftext": "Especialy (Image to vid).\n\nEdit: or if you are experiencing with other img to vid models, I am also interested.",
            "comments": [
                {
                    "id": "lxbinor",
                    "author": "the_bollo",
                    "body": "I do a lot with I2V CogVideo. I feel the trick is to call out the camera motion and object motion very separately, and very explicitly. For example: A picture of a dog. The camera pulls out. The dog walks forward.\n\nAlso, just like image generation, don’t expect perfection in one go. I usually spam Cog with 4 iterations (at least) then pick my favorite.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731701049.0,
                    "parent_id": "t3_1gs13yz",
                    "link_id": "t3_1gs13yz",
                    "permalink": "/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/lxbinor/"
                },
                {
                    "id": "lxbvln7",
                    "author": "HotNCuteBoxing",
                    "body": "I didn't find any reliable prompting method. \n\nI've gotten more desirable results using CogVideoX + TORA. The spline used for trajectory seems to add an extra dimension of control. Typical prompt used is very simple: panning shot of an anime girl breathing in and out, waving her hand. I set the spline for small movements near the chest.\n\nIt's okay.\n\nJust looking to do simple living portraits, like the character is breathing in and out while the wind blows their hair gently. Without TORA I was constantly getting flickering face motions or non-stop talking.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731704998.0,
                    "parent_id": "t3_1gs13yz",
                    "link_id": "t3_1gs13yz",
                    "permalink": "/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/lxbvln7/"
                },
                {
                    "id": "lxakuhm",
                    "author": "NoHopeHubert",
                    "body": "It really does depend on what image you’re using and what you’re looking for. My best ones so far have been done with the assistance of ChatGPT though honestly.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731690899.0,
                    "parent_id": "t3_1gs13yz",
                    "link_id": "t3_1gs13yz",
                    "permalink": "/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/lxakuhm/"
                },
                {
                    "id": "lxawf88",
                    "author": "Successful_AI",
                    "body": "I tried that. I showed the image to chatGPT asked it to describe it then create prompt to animate it. It was not all that great.  \nDo you have an example of a successful generation?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731694352.0,
                    "parent_id": "t1_lxakuhm",
                    "link_id": "t3_1gs13yz",
                    "permalink": "/r/StableDiffusion/comments/1gs13yz/what_prompts_did_you_find_most_effective_with/lxawf88/"
                }
            ]
        },
        {
            "id": "1gs0zom",
            "title": "Best detailer inpainting nodes for ComfyUI?",
            "author": "jonesaid",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731690014.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs0zom/best_detailer_inpainting_nodes_for_comfyui/",
            "permalink": "/r/StableDiffusion/comments/1gs0zom/best_detailer_inpainting_nodes_for_comfyui/",
            "selftext": "What are the best nodes for automatic detailer inpainting in ComfyUI? I'm used to adetailer in Automatic1111/Forge, and I'm looking for something similar/better for ComfyUI.",
            "comments": [
                {
                    "id": "lxb5zxf",
                    "author": "SurveyOk3252",
                    "body": "https://github.com/ltdrdata/ComfyUI-extension-tutorials/blob/Main/ComfyUI-Impact-Pack/workflow/simple.png\n\nYou can use Impact Pack.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731697181.0,
                    "parent_id": "t3_1gs0zom",
                    "link_id": "t3_1gs0zom",
                    "permalink": "/r/StableDiffusion/comments/1gs0zom/best_detailer_inpainting_nodes_for_comfyui/lxb5zxf/"
                },
                {
                    "id": "lxblmvd",
                    "author": "TurbTastic",
                    "body": "I usually use the Ultralytics node to load the detection model, link that to Simple Detector (SEGS), then use Inpaint Crop and Stitch nodes to inpaint in the cropped masked area via Ksampler instead of using the premade Detailer nodes.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731701962.0,
                    "parent_id": "t3_1gs0zom",
                    "link_id": "t3_1gs0zom",
                    "permalink": "/r/StableDiffusion/comments/1gs0zom/best_detailer_inpainting_nodes_for_comfyui/lxblmvd/"
                }
            ]
        },
        {
            "id": "1gs0gei",
            "title": "Flux Lora (FluxGYM) - Am i Being Think?",
            "author": "TurnipMission",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731688650.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gs0gei/flux_lora_fluxgym_am_i_being_think/",
            "permalink": "/r/StableDiffusion/comments/1gs0gei/flux_lora_fluxgym_am_i_being_think/",
            "selftext": "I'm trying to create a lora model using Fluxgym, it's running on an RTX 3060 (12GB, yes i know it wont be quick but it should still work) with 30 images but no matter the settings, optimizations etc i get an out of cuda memory error, what the heck am i doing wrong? I've tried/applied the below, all with the same result. Fresh Windows 11 install, nothing else running - any suggestions? Many have advised the below should even run on 8GB comfortably, im clearing doing something wrong :/\n\n\\--memory\\_efficient\\_attention (enabled)\n\n12GB option selected\n\nrepeat per images - 5 (even set at 2 with epochs at 3 it still fails just to test absolute bottom)\n\nMax train epochs - 8\n\n\\--save\\_every\\_n\\_epochs - 2\n\nBase Model - [Flux.Dev](http://flux.dev/)\n\n\\--cache\\_latents - enabled\n\nSample Images - Disabled\n\nResize Image - 512",
            "comments": [
                {
                    "id": "lxaoayy",
                    "author": "twinpoops",
                    "body": "Sorry, I don't know how to tell you this - you are in fact Being Think.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731691929.0,
                    "parent_id": "t3_1gs0gei",
                    "link_id": "t3_1gs0gei",
                    "permalink": "/r/StableDiffusion/comments/1gs0gei/flux_lora_fluxgym_am_i_being_think/lxaoayy/"
                }
            ]
        },
        {
            "id": "1grsbyw",
            "title": "Last Call: The submission deadline for EvoMUSART 2025 has been extended to November 15th and will end tomorrow!",
            "author": "evomusart_conference",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731661422.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grsbyw/last_call_the_submission_deadline_for_evomusart/",
            "permalink": "/r/StableDiffusion/comments/1grsbyw/last_call_the_submission_deadline_for_evomusart/",
            "selftext": "Hi all!   \nYou still have time to submit your work to the 14th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART).  \n  \nIf you work with Artificial Intelligence techniques applied to visual art, music, sound synthesis, architecture, video, poetry, design or other creative tasks, don't miss the opportunity to submit your work to EvoMUSART.  \n  \nEvoMUSART 2022 will be held in Trieste, Italy, between 23 and 25 April 2025.\n\nhttps://preview.redd.it/35vahfkd611e1.png?width=4167&format=png&auto=webp&s=dc75fce210f4965a67f533eb95d08a9c364aaa5b\n\n  \n  \nFor more information, visit the conference webpage:  \n[**www.evostar.org/2025/evomusart/**](http://www.evostar.org/2025/evomusart/)",
            "comments": []
        },
        {
            "id": "1gryt3z",
            "title": "how I have uninstall automatic1111 webui? ",
            "author": "12wer10",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731684365.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gryt3z/how_i_have_uninstall_automatic1111_webui/",
            "permalink": "/r/StableDiffusion/comments/1gryt3z/how_i_have_uninstall_automatic1111_webui/",
            "selftext": "Hi,\n\nI've installed automatic1111 on my Macbook 13 pro, but it was making my computer very laggy. so I decided to uninstall it. \n\nMy question is this, is there a way to remove this fully from my Mac? I don't want to reset my computer, or such things...\n\nIf by any chance one of you kind souls could explain a step by step way of doing this, I'd be incredibly grateful. Thanks in advance",
            "comments": [
                {
                    "id": "lxbstpi",
                    "author": "TaiVat",
                    "body": "It certainly wasnt what was making your computer laggy.. Not when turned off. Its just not how things work. But yea, these tools have no real \"uninstall\", you just delete the folder and you're done.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731704156.0,
                    "parent_id": "t3_1gryt3z",
                    "link_id": "t3_1gryt3z",
                    "permalink": "/r/StableDiffusion/comments/1gryt3z/how_i_have_uninstall_automatic1111_webui/lxbstpi/"
                },
                {
                    "id": "lxa3gf9",
                    "author": "12wer10",
                    "body": "[https://www.reddit.com/r/StableDiffusion/comments/13klow9/how\\_to\\_completely\\_uninstall\\_stablediffusion/](https://www.reddit.com/r/StableDiffusion/comments/13klow9/how_to_completely_uninstall_stablediffusion/) \n\njust used this way... I hope there's no problem",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731685746.0,
                    "parent_id": "t3_1gryt3z",
                    "link_id": "t3_1gryt3z",
                    "permalink": "/r/StableDiffusion/comments/1gryt3z/how_i_have_uninstall_automatic1111_webui/lxa3gf9/"
                },
                {
                    "id": "lxdexyc",
                    "author": "12wer10",
                    "body": "thanks! I didn't expect removing is easy! thank you again",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731724682.0,
                    "parent_id": "t1_lxbstpi",
                    "link_id": "t3_1gryt3z",
                    "permalink": "/r/StableDiffusion/comments/1gryt3z/how_i_have_uninstall_automatic1111_webui/lxdexyc/"
                }
            ]
        },
        {
            "id": "1grzzwo",
            "title": "Where do I start please? ",
            "author": "LittlePooky",
            "score": 4,
            "upvotes": 4,
            "downvotes": 0,
            "num_comments": 15,
            "created_utc": 1731687450.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/",
            "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/",
            "selftext": "I spent some time looking for a how-to guide to get started..  the guide on Github looks like it was written for a computer programmer..  Help please. \n\nNote: I upgraded to Windows 11 Pro for Workstations a few months ago, with an i9 14900k, 128 G RAM, and RTX 4090, and I am dying to see what this can do. ",
            "comments": [
                {
                    "id": "lxad9z0",
                    "author": "Kyle_Dornez",
                    "body": "I suggest [using Stability Matrix](https://github.com/LykosAI/StabilityMatrix), to bypass a lot of installing headaches. It will install all the Python bits and environments for you in a folder you tell it to, then you'll be able to download most of the currently popular interfaces (Automatic1111, Forge, Invoke, ComfyUI, and others) at your leisure, it can also connect to your account on CivitAI to pull the checkpoints and LORAs straight from there, and it also will share those between your interfaces too. \n\nBasically, I think it's the best noob-friendly option. \n\nAlso, if it would look overwhelming and confusing, then I suggest to just install ComfyUI and Fooocus interfaces. ComfyUI would power the in-built Stability Matrix image generator, and Fooocus would download its own checkpoints for you, so you would be able to just use it right out of the box.",
                    "score": 11,
                    "upvotes": 11,
                    "downvotes": 0,
                    "created_utc": 1731688669.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxad9z0/"
                },
                {
                    "id": "lxa9ynk",
                    "author": "Unit2209",
                    "body": "Webui Forge is an easy place to start. The github has a one click installer package.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731687683.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxa9ynk/"
                },
                {
                    "id": "lxao9jh",
                    "author": "MathAndMirth",
                    "body": "YouTube videos are usually the best source of tutorials in this fast-changing space. Nerdy Rodent, Sebastian Kampf, Laura Carnevalli, and Olivio Sarikas are all excellent channels for Stable Diffusion.\n\nOne of the early decisions to make is whether to use ComfyUI, which is very powerful but can look intimidating for beginners, or something like Forge, which hides a lot of the complication behind a friendlier interface. I recommend ComfyUI if you plan to be a power user, since the latest toys seem to come faster, and the ability to customize workflows is much greater. And as long as you start with \\_beginner's\\_ tutorials and work up bit-by-bit, it's not as hard as it first appears.\n\nYou'll also want to narrow yourself to one model in the early going since the workflows for each are similar, but not identical and not always compatible. You have a powerful system, so I would suggest learning Flux. (That's for images. I'll have to punt on video recommendations.) It's an excellent modern model that's been around just long enough to have the helpful tools such as ControlNets, LoRAs, etc. that you'll want to learn.\n\nBottom line: Go look for beginners tutorials for ComfyUI with Flux on YouTube.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731691917.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxao9jh/"
                },
                {
                    "id": "lxbjzla",
                    "author": "bobrformalin",
                    "body": "Immediately send your pc to someone who knows what to do with it :D",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731701457.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxbjzla/"
                },
                {
                    "id": "lxc4c4r",
                    "author": "NefariousnessDry2736",
                    "body": "Check out https://pinokio.computer it’s a very simple and straightforward on click installer for most cutting edge Ai stuff. You should check out their discord as well",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731707679.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxc4c4r/"
                },
                {
                    "id": "lxawpw0",
                    "author": "Ok-Fondant1767",
                    "body": "Youtube. Decide what UI you want to learn on first and then decide the rest. ComfyUI, Automatic1111, or ForgeUI. There are others. I use forge right now but want to move to comfy. It's what the pros use. Forge and Automatic are very similar, but Forge is a bit faster. If you're just starting they might be nicer just to learn on. Especially Forge which is easy easy to install",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731694440.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxawpw0/"
                },
                {
                    "id": "lxbormd",
                    "author": "Heart-of-Silicon",
                    "body": "Let me know if you want specific help.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731702919.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxbormd/"
                },
                {
                    "id": "lxcxsbg",
                    "author": "Informal-Football836",
                    "body": "I recommend using SwarmUI is super easy to use. \n\nhttps://github.com/mcmonkeyprojects/SwarmUI",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731718026.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxcxsbg/"
                },
                {
                    "id": "lxaaly3",
                    "author": "octarino",
                    "body": "with https://pinokio.computer you can install several apps and run them from there.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731687875.0,
                    "parent_id": "t3_1grzzwo",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxaaly3/"
                },
                {
                    "id": "lxaqb56",
                    "author": "Scolder",
                    "body": "I second this suggestion.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731692528.0,
                    "parent_id": "t1_lxad9z0",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxaqb56/"
                },
                {
                    "id": "lxaxnkj",
                    "author": "Perfect-Campaign9551",
                    "body": "Third this suggestion",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731694720.0,
                    "parent_id": "t1_lxad9z0",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxaxnkj/"
                },
                {
                    "id": "lxc6qz1",
                    "author": "LittlePooky",
                    "body": "Hahaha!! 🤣",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731708445.0,
                    "parent_id": "t1_lxbjzla",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxc6qz1/"
                },
                {
                    "id": "lxc802d",
                    "author": "RideTheSpiralARC",
                    "body": "Also came here to suggest Stability Matrix. It's about as user friendly of a start as is possible lol",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731708854.0,
                    "parent_id": "t1_lxaxnkj",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxc802d/"
                },
                {
                    "id": "lxcn88b",
                    "author": "Perfect-Campaign9551",
                    "body": "I'm using it because I can have multiple image generator tools and they share the data, make it easy to use the best tool for what you are trying to do",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731714119.0,
                    "parent_id": "t1_lxc802d",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxcn88b/"
                },
                {
                    "id": "lxco3k5",
                    "author": "RideTheSpiralARC",
                    "body": "Yeah, when I first started with all these different tools it was a pita in the early stages having duplicate model folders ect for each UI so S.M. def makes everything easier with its shared directories",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731714436.0,
                    "parent_id": "t1_lxcn88b",
                    "link_id": "t3_1grzzwo",
                    "permalink": "/r/StableDiffusion/comments/1grzzwo/where_do_i_start_please/lxco3k5/"
                }
            ]
        },
        {
            "id": "1grzzku",
            "title": "Forge crashing on loading an SDXL model",
            "author": "Jaradis",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 7,
            "created_utc": 1731687426.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/",
            "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/",
            "selftext": "So, trying to help a friend.   She has an Nvidea 3060 with 6Gb VRAM and 8 Gb RAM (don't ask).   Forge (old pre-Flux version) runs fine for 1.5 models, but as soon as she attempt to load an SDXL model (Dreamshaper in this case) it crashes the terminal.    We tried installing the new Flux version of Forge, and it would do SDXL and work fine, but it had other problems and she hated it.    We did a clean install of the old Forge, and SDXL still crashes on loading the model.   There is plenty of hard drive space 250 Gb+ on an SSD.   The page file is set to automatic.   We have downloaded a clean Dreamshaper model to check that.\n\nIt's crashing on simply selecting the SDXL model, not during image creation.\n\nI can install this version from the same download link, and it works perfectly fine on my system.   I've seen others that have 3060s or worse that can run SDXL.   So the specs are not the issue.\n\nAny ideas what could possibly be causing this crashing?  I'm at a complete loss here.",
            "comments": [
                {
                    "id": "lxalm08",
                    "author": "BigPharmaSucks",
                    "body": "I'd download Stability Matrix and try multiple UIs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731691128.0,
                    "parent_id": "t3_1grzzku",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxalm08/"
                },
                {
                    "id": "lxaqadg",
                    "author": "Dwedit",
                    "body": "Try another 8GB of system RAM.  I can see the \"python\" process using 7.6GB after doing many gens with forge.  That wouldn't leave much for the operating system.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731692522.0,
                    "parent_id": "t3_1grzzku",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxaqadg/"
                },
                {
                    "id": "lxddot2",
                    "author": "Mundane-Apricot6981",
                    "body": "Can you logically explain how you will fit 6.6 Gb model into 6Gb VRam?  \nYou invented some new math laws which makes 6.6 < 6 ??",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731724173.0,
                    "parent_id": "t3_1grzzku",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxddot2/"
                },
                {
                    "id": "lxb39rt",
                    "author": "Jaradis",
                    "body": "How is that going to fix the problem with FORGE?   It's not.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696375.0,
                    "parent_id": "t1_lxalm08",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxb39rt/"
                },
                {
                    "id": "lxb2kr7",
                    "author": "Jaradis",
                    "body": "Yes, I've already recommended that.  But SDXL worked in the new version of Forge, so I find it hard to believe that is it.  Plus I've seen others post that it runs with lesser specs.  Hell, I used to run it on my old GTX 970 card with 8 Gb.   And this isn't even during the processing of an image.  It crashes simply on selecting the model.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696170.0,
                    "parent_id": "t1_lxaqadg",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxb2kr7/"
                },
                {
                    "id": "lxb8adq",
                    "author": "BigPharmaSucks",
                    "body": "I'm just sharing what I would do if I were troubleshooting. I'd check other UIs, for one to see if the problem is specific to forge. Can it be done in another UI? If so, then it sounds like a forge specific problem. If not, could be a system specific problem. Then at that point, if it is working in another UI, you could decide if it's worth it to continue to troubleshoot it on forge, or just use whatever works. Make sense now? You're welcome.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731697866.0,
                    "parent_id": "t1_lxb39rt",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxb8adq/"
                },
                {
                    "id": "lxde9m5",
                    "author": "Mundane-Apricot6981",
                    "body": "Open task manager, and you will be surprised - when you select model it LOADS into GPU. Unexpected?  \nModel loads not when you press start button, pipeline initialized and waits preloaded.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731724407.0,
                    "parent_id": "t1_lxb2kr7",
                    "link_id": "t3_1grzzku",
                    "permalink": "/r/StableDiffusion/comments/1grzzku/forge_crashing_on_loading_an_sdxl_model/lxde9m5/"
                }
            ]
        },
        {
            "id": "1grzt0m",
            "title": "Going into Friday like ...",
            "author": "rizzleroc",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731686979.0,
            "url": "https://i.redd.it/hwgh6geea31e1.png",
            "permalink": "/r/StableDiffusion/comments/1grzt0m/going_into_friday_like/",
            "selftext": "",
            "comments": [
                {
                    "id": "lxag04e",
                    "author": "pondermoreau",
                    "body": "why do Fridays turn you into an alien hacker??",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731689471.0,
                    "parent_id": "t3_1grzt0m",
                    "link_id": "t3_1grzt0m",
                    "permalink": "/r/StableDiffusion/comments/1grzt0m/going_into_friday_like/lxag04e/"
                },
                {
                    "id": "lxd3z1a",
                    "author": "Anueis",
                    "body": "That would be a good disguise for web videos ☝️",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731720393.0,
                    "parent_id": "t3_1grzt0m",
                    "link_id": "t3_1grzt0m",
                    "permalink": "/r/StableDiffusion/comments/1grzt0m/going_into_friday_like/lxd3z1a/"
                },
                {
                    "id": "lxa7t04",
                    "author": "rizzleroc",
                    "body": "IMG2IMG with Forge and a custom website that uses a live webcam to do IMG2IMG- here is the prompt and image metadata  \n  \nalien lifeform green skin large grey eyes, (Unreal Engine, Technique) Abstract, trending on artstation, 4k, 8k, renderman, octane  \nNegative prompt: human  \nSteps: 23, Sampler: Euler, Schedule type: Karras, CFG scale: 8.0, Seed: 2263740758, Size: 1024x768, Model hash: fec3161589, Model: starlightXLAnimated\\_v3, Denoising strength: 0.92, ControlNet 0: \"Module: depth\\_leres++, Model: depth\\_diffusion\\_pytorch\\_model.fp16 \\[d4ccdb66\\], Weight: 1, Resize Mode: Crop and Resize, Processor Res: 512, Threshold A: 0, Threshold B: 0, Guidance Start: 0, Guidance End: 1, Pixel Perfect: True, Control Mode: ControlMode.BALANCED, Hr Option: HiResFixOption.BOTH\", Noise multiplier: 0.908, Version: f2.0.1v1.10.1-previous-581-ge4ad1140",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731687049.0,
                    "parent_id": "t3_1grzt0m",
                    "link_id": "t3_1grzt0m",
                    "permalink": "/r/StableDiffusion/comments/1grzt0m/going_into_friday_like/lxa7t04/"
                }
            ]
        },
        {
            "id": "1grzriy",
            "title": "what is this sub about?",
            "author": "Camille_Jamal1",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 5,
            "created_utc": 1731686875.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/",
            "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/",
            "selftext": "is it ai? is it anti ai? is it drawing? the rules and description aren't giving me any good/useful hints.",
            "comments": [
                {
                    "id": "lxa8hh9",
                    "author": "red__dragon",
                    "body": "This is a sub supporting and in favor of Stable Diffusion, Flux, AuraFlow, and other similar **open weights** (freely downloadable and usable on your local computer) AI image generation models. \n\nMany of the discussions here center around getting started, tips on improving generations, discussing new/upcoming technologies, and showing off the generated images that bring the most pride (or laughs). \n\nAnti-AI attitudes aren't welcome here, though thoughtful critiques of AI have been entertained in the past, and often controversial nonetheless. Drawings are usually either produced by the AI or used to facilitate the AI generations and only posted alongside for comparison. In short, it's AI and we like it that way.",
                    "score": 16,
                    "upvotes": 16,
                    "downvotes": 0,
                    "created_utc": 1731687249.0,
                    "parent_id": "t3_1grzriy",
                    "link_id": "t3_1grzriy",
                    "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/lxa8hh9/"
                },
                {
                    "id": "lxa85hq",
                    "author": "weshouldhaveshotguns",
                    "body": "Its about using AI image generation. Specifically mostly local, open source image generation, discussion used to be limited to the model stable diffusion, but now it encompasses all open-source models. It could be described as a Pro-AI sub, but in reality its more about the technical aspects of AI image generation.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731687151.0,
                    "parent_id": "t3_1grzriy",
                    "link_id": "t3_1grzriy",
                    "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/lxa85hq/"
                },
                {
                    "id": "lxb4dkb",
                    "author": "ImUrFrand",
                    "body": "it's a place where the elite show off their works and laugh at the small guy trying to get good.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731696702.0,
                    "parent_id": "t3_1grzriy",
                    "link_id": "t3_1grzriy",
                    "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/lxb4dkb/"
                },
                {
                    "id": "lxa968l",
                    "author": "Flaming-Eye",
                    "body": "yes",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731687450.0,
                    "parent_id": "t3_1grzriy",
                    "link_id": "t3_1grzriy",
                    "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/lxa968l/"
                },
                {
                    "id": "lxcf1kw",
                    "author": "chickenofthewoods",
                    "body": "Exactly.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731711207.0,
                    "parent_id": "t1_lxb4dkb",
                    "link_id": "t3_1grzriy",
                    "permalink": "/r/StableDiffusion/comments/1grzriy/what_is_this_sub_about/lxcf1kw/"
                }
            ]
        },
        {
            "id": "1grz38d",
            "title": "How to make new expressions for a character?",
            "author": "Shadow-Amulet-Ambush",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731685112.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grz38d/how_to_make_new_expressions_for_a_character/",
            "permalink": "/r/StableDiffusion/comments/1grz38d/how_to_make_new_expressions_for_a_character/",
            "selftext": "I'm working in Comfy.\n\nI generated an anime character design sheet with flux from different angles. Now I want to generate the same anime character with a range of facial expressions. I have a lora for pony that is designed to generate several different expressions of a single character on one sheet.\n\nI haven't figured out how to make the new generated character expressions resemble the character that I've already generated previously. I don't think controlnet will work because I want the faces generated to have different expressions than the one I've already got. I tried the experimental \"reference only\" node. Essentially I need to find a way to have (preferably pony) take into account one picture of a character and use it as a reference to generate the same character with different expressions.\n\n# TLDR: \n\nI want to take a single reference image I've already generated and make more generations of the same character but with different expressions. How can I do this?",
            "comments": [
                {
                    "id": "lxa5uyo",
                    "author": "Enshitification",
                    "body": "https://github.com/PowerHouseMan/ComfyUI-AdvancedLivePortrait",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731686463.0,
                    "parent_id": "t3_1grz38d",
                    "link_id": "t3_1grz38d",
                    "permalink": "/r/StableDiffusion/comments/1grz38d/how_to_make_new_expressions_for_a_character/lxa5uyo/"
                }
            ]
        },
        {
            "id": "1grydi9",
            "title": "MagicQuill: inpainting with auto-prompting",
            "author": "jonesaid",
            "score": 205,
            "upvotes": 205,
            "downvotes": 0,
            "num_comments": 11,
            "created_utc": 1731683186.0,
            "url": "https://v.redd.it/a75mkgp6z21e1",
            "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/",
            "selftext": "Reminds me of the \"inpaint sketch\" in Auto1111, except this also does the prompting for you, predicting what it is you're inpainting.\n\nGitHub: https://github.com/magic-quill/magicquill",
            "comments": [
                {
                    "id": "lxbxyh8",
                    "author": "DigThatData",
                    "body": "Neat stuff! Looks like the main bit of magic here is a \"guessing game\" llava (VLM) prompt. via https://github.com/magic-quill/MagicQuill/blob/main/MagicQuill/llava_new.py#L83-L101\n\n    class LlavaModel:\n        ...\n        def process(self, image, colored_image, add_mask):\n            description = \"\"\n            answer1 = \"\"\n            answer2 = \"\"\n            \n            image_with_sketch = image.clone()\n            if torch.sum(add_mask).item() > 0:\n                x_min, y_min, x_max, y_max = get_bounding_box_from_mask(add_mask)\n                # print(x_min, y_min, x_max, y_max)\n                question = f\"This is an 'I draw, you guess' game. I will upload an image containing some sketches. To help you locate the sketch, I will give you the normalized bounding box coordinates of the sketch where their original coordinates are divided by the image width and height. The top-left corner of the bounding box is at ({x_min}, {y_min}), and the bottom-right corner is at ({x_max}, {y_max}). Now tell me, what am I trying to draw with these sketches in the image?\"\n                # image_with_sketch[add_mask > 0.5] = 1.0\n                bool_add_mask = add_mask > 0.5\n                mean_brightness = image_with_sketch[bool_add_mask].mean()\n                if mean_brightness > 0.8:\n                    image_with_sketch[bool_add_mask] = 0.0\n                else:\n                    image_with_sketch[bool_add_mask] = 1.0\n                answer1 = self.generate_description([image_with_sketch.squeeze() * 255], question)\n                print(answer1)\n\nJust the prompt:\n\n> This is an 'I draw, you guess' game. I will upload an image containing some sketches. To help you locate the sketch, I will give you the normalized bounding box coordinates of the sketch where their original coordinates are divided by the image width and height. The top-left corner of the bounding box is at ({x_min}, {y_min}), and the bottom-right corner is at ({x_max}, {y_max}). Now tell me, what am I trying to draw with these sketches in the image?",
                    "score": 17,
                    "upvotes": 17,
                    "downvotes": 0,
                    "created_utc": 1731705715.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxbxyh8/"
                },
                {
                    "id": "lxa6rm1",
                    "author": "Enshitification",
                    "body": "Looks fun. That music made me want to throw my phone though. Can it use checkpoints other than 1.5, like maybe SDXL?",
                    "score": 21,
                    "upvotes": 21,
                    "downvotes": 0,
                    "created_utc": 1731686736.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxa6rm1/"
                },
                {
                    "id": "lxcf5ux",
                    "author": "Fabulous-Ad9804",
                    "body": "The link indicates you also have to download and install 25 GB of models. Not wanting to download 25 GB of models, though. Does anyone know a way around some of this where this app can still work without having to download the entire 25 GB of models?\n\n\n\nFor instance, there are 5 checkpoint models involved. I already have one of those models but not the other 4. For example, are all 5 of them necessary or the app won't run until all 5 are installed?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731711248.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxcf5ux/"
                },
                {
                    "id": "lxbtrme",
                    "author": "FourtyMichaelMichael",
                    "body": "Looks great. SDXL is needed though.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704442.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxbtrme/"
                },
                {
                    "id": "lxbtx03",
                    "author": "diogodiogogod",
                    "body": "This looks great!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704485.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxbtx03/"
                },
                {
                    "id": "lxcwzcx",
                    "author": "terrariyum",
                    "body": "Just from this video, this looks really well executed.  This is the kind of tool that will make AI paint software go mainstream",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731717726.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxcwzcx/"
                },
                {
                    "id": "lxcxf7d",
                    "author": "Veemenothz",
                    "body": "The tool looks good, but what irks me about the video is him using the pen to draw and his finger to click when he can use the pen to click the button lol.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731717890.0,
                    "parent_id": "t3_1grydi9",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxcxf7d/"
                },
                {
                    "id": "lxctkdu",
                    "author": "kharzianMain",
                    "body": "Yeah that music was an instant nope",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716461.0,
                    "parent_id": "t1_lxa6rm1",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxctkdu/"
                },
                {
                    "id": "lxah5l7",
                    "author": "jonesaid",
                    "body": "Good question.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731689808.0,
                    "parent_id": "t1_lxa6rm1",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxah5l7/"
                },
                {
                    "id": "lxdnatv",
                    "author": "crit_thinker_heathen",
                    "body": "Y’all are so persnickety lol",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728002.0,
                    "parent_id": "t1_lxctkdu",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxdnatv/"
                },
                {
                    "id": "lxdoiuc",
                    "author": "machstem",
                    "body": "Reddit",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728490.0,
                    "parent_id": "t1_lxdnatv",
                    "link_id": "t3_1grydi9",
                    "permalink": "/r/StableDiffusion/comments/1grydi9/magicquill_inpainting_with_autoprompting/lxdoiuc/"
                }
            ]
        },
        {
            "id": "1gry6a2",
            "title": "Civitai.com versus local generation, not getting the same results?",
            "author": "EvilVegan",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 8,
            "created_utc": 1731682648.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/",
            "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/",
            "selftext": "Are results expected to be this different with the same prompts, models, sampler, scheduler, CFG, and seed?  \n\nI can tell they're both in the same ballpark, but it's kinda wildly different.  I was able to replicate the same image on the site, so I know it wasn't done off site and uploaded.\n\n\n\nCivitai generated[ this image](https://civitai.com/images/39809849):\n\n[photograhy of a \\(nun:\\(xenomorph\\)\\), black habit, in cathedral, volumetric light, dim light, red and green lights, .score\\_9, score\\_8\\_up, score\\_7\\_up,score\\_6\\_up,Negative prompt: .score\\_5, score\\_4, score\\_3, score\\_2, score\\_1, watermark, signatureSteps: 36, CFG scale: 7, Sampler: DPM++ 2M Karras, Seed: 2003085558, Size: 832x1216, extra: \\[object Object\\], Created Date: 2024-11-13T0010:39.3166491Z, Clip skip: 2](https://preview.redd.it/sblabrpwv21e1.png?width=832&format=png&auto=webp&s=25205eec452ca5a090a48a65ba0c905c7e8669b6)\n\nI downloaded all the same things and used it locally on Reforge and got this image:\n\n[photograhy of a \\(nun:\\(xenomorph\\)\\), black habit, in cathedral, volumetric light, dim light, red and green lights, .score\\_9, score\\_8\\_up, score\\_7\\_up,score\\_6\\_up,Negative prompt: .score\\_5, score\\_4, score\\_3, score\\_2, score\\_1, watermark, signatureSteps: 36, Sampler: DPM++ 2M, Schedule type: Karras, CFG scale: 7, Seed: 2003085558, Size: 832x1216, Model hash: db2578792c, Model: goddessOfRealism\\_gorPONYV2artFixVAE, Clip skip: 2, Version: f1.0.5-v1.10.1RC-latest-763-g91cb30c1](https://preview.redd.it/or2r3ug9w21e1.png?width=832&format=png&auto=webp&s=0f63b012d5f85d1c11a7cdaddfc11d93b7b3dbee)\n\n",
            "comments": [
                {
                    "id": "lx9vi7i",
                    "author": "Designer-Pair5773",
                    "body": "Different GPUs can deliver slightly different results. In the same way, Automatic will not generate the same images 1:1 as ComfyUI.",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731683326.0,
                    "parent_id": "t3_1gry6a2",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lx9vi7i/"
                },
                {
                    "id": "lx9za3h",
                    "author": "YMIR_THE_FROSTY",
                    "body": "Thing about seed.. even while its \"same\", generation method for noise might not be. You can generate initial noise via GPU or CPU and it can have various tweaks on its own, which as you can guess, might result in different output.\n\nIm not 100% confident here, but I can try by simply swapping methods for some pic and report later. Somehow GPU noise makes prettier pics for me, so I keep using that. :D Altho I think its tied to the rest of flow too.\n\nApart that, while samplers and schedulers should be implemented in similar way, I know for a fact, that even if you put same stuff into Transformers (in ComfyUI) and same stuff into regular workflow, you will get some seriously different pics. Not mentioning that Transfomers somehow dont need clip skip -2..",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731684484.0,
                    "parent_id": "t3_1gry6a2",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lx9za3h/"
                },
                {
                    "id": "lxauh2b",
                    "author": "_BreakingGood_",
                    "body": "Civitai adds some extra stuff to the prompt to prevent you from generating stuff that breaks the rules, and these tokens can affect outputs for all image s",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731693769.0,
                    "parent_id": "t3_1gry6a2",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lxauh2b/"
                },
                {
                    "id": "lxdn8d3",
                    "author": "mrdion8019",
                    "body": "So nobody ever replicate civitai gens successfully? I have tried sometime ago, and yes, i failed too. The best i can get is somehow still same ish, but not 100%. \n\nI also tried replicate tensor art gens, but it is hit and miss. I tried with the one image i like, and it works. But lately, i tried again to replicate, i cant really get it 100% same.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727975.0,
                    "parent_id": "t3_1gry6a2",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lxdn8d3/"
                },
                {
                    "id": "lxa4fir",
                    "author": "NoBuy444",
                    "body": "Many pictures you can see are usually upscale with hi res fix and with face detailers",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731686039.0,
                    "parent_id": "t3_1gry6a2",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lxa4fir/"
                },
                {
                    "id": "lx9vozv",
                    "author": "Trainraider",
                    "body": "Cuda is non-deterministic, but afaik you shouldn't really tell the difference by sight. There's probably other stuff going on in the generation pipeline",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731683385.0,
                    "parent_id": "t1_lx9vi7i",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lx9vozv/"
                },
                {
                    "id": "lxbbe8c",
                    "author": "ShengrenR",
                    "body": "There's apt to be a number of other quirky things under the hood that could start to push the 'almost nearly the same' to drift off - underlying math libraries, versions of the many packages that make up the environment, and (as I mentioned in another reply) - they're probably batching requests on the platform (maybe??), so not sure if/how they enforce the seed in that.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698798.0,
                    "parent_id": "t1_lx9za3h",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lxbbe8c/"
                },
                {
                    "id": "lxbaiyw",
                    "author": "ShengrenR",
                    "body": "One might imagine that the online/cloud service (civit) batches their generation requests for efficiency, as well - in which case the seed value won't \\*really\\* be the same.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698538.0,
                    "parent_id": "t1_lx9vozv",
                    "link_id": "t3_1gry6a2",
                    "permalink": "/r/StableDiffusion/comments/1gry6a2/civitaicom_versus_local_generation_not_getting/lxbaiyw/"
                }
            ]
        },
        {
            "id": "1grxz42",
            "title": "Is there a way to get information from a model and or LoRA file either inside or outside of stable diffusion?",
            "author": "B4N35P1R17",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731682090.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grxz42/is_there_a_way_to_get_information_from_a_model/",
            "permalink": "/r/StableDiffusion/comments/1grxz42/is_there_a_way_to_get_information_from_a_model/",
            "selftext": "How can I get the information from a model and or LoRA file that’s on my drive? \n\nI’ve tried opening them in notepad and while there is information there it’s so hard to figure out it’s worthless. Most LoRAs I’ve got don’t have any information for triggers during prompting or even a clear picture of what they are supposed to do in their name. \n\nIs there an extension for SD that lets me view that information? I was under the impression that the LoRAs tab would only show a LoRA if it was compatible with the model but all the LoRA never seem to change when I’m using different models how can I tell them apart if it’s not in the name?",
            "comments": [
                {
                    "id": "lxcfdgi",
                    "author": "chickenofthewoods",
                    "body": "I use CivitAI Helper on AUTO1111 and Forge.\n\nhttps://github.com/butaixianran/Stable-Diffusion-Webui-Civitai-Helper",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731711321.0,
                    "parent_id": "t3_1grxz42",
                    "link_id": "t3_1grxz42",
                    "permalink": "/r/StableDiffusion/comments/1grxz42/is_there_a_way_to_get_information_from_a_model/lxcfdgi/"
                },
                {
                    "id": "lxefhxl",
                    "author": "B4N35P1R17",
                    "body": "That looks pretty good but does it require a full time internet connection to stay linked to the website for that information or does it just update the information in the file itself on your drive? I don’t have the internet when I’m at work so I just download all the models and LoRA files while at home and then use them later but I find that 90% of them don’t have any information attached or their trigger words.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731741834.0,
                    "parent_id": "t1_lxcfdgi",
                    "link_id": "t3_1grxz42",
                    "permalink": "/r/StableDiffusion/comments/1grxz42/is_there_a_way_to_get_information_from_a_model/lxefhxl/"
                },
                {
                    "id": "lxeg36h",
                    "author": "chickenofthewoods",
                    "body": "Does not require internet after the initial download.  It creates a .json, a .info, and a .png, which are stored in the folder with your models/loras.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731742211.0,
                    "parent_id": "t1_lxefhxl",
                    "link_id": "t3_1grxz42",
                    "permalink": "/r/StableDiffusion/comments/1grxz42/is_there_a_way_to_get_information_from_a_model/lxeg36h/"
                }
            ]
        },
        {
            "id": "1grxlw8",
            "title": "Multiple consistent elements in one Flux Lora",
            "author": "EpicNoiseFix",
            "score": 35,
            "upvotes": 35,
            "downvotes": 0,
            "num_comments": 6,
            "created_utc": 1731681041.0,
            "url": "https://youtu.be/v6h_zbFW_XY?si=QtjMvh8dqCR7r7oA",
            "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx9yqdb",
                    "author": "RonaldoMirandah",
                    "body": "Great idea, i will teste it",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731684319.0,
                    "parent_id": "t3_1grxlw8",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lx9yqdb/"
                },
                {
                    "id": "lxb5own",
                    "author": "dddimish",
                    "body": "Where can I get this tool? Or are you just bragging? )",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731697090.0,
                    "parent_id": "t3_1grxlw8",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lxb5own/"
                },
                {
                    "id": "lxbwdfm",
                    "author": "LichJ",
                    "body": "I was able to do this in Kohya with my wife and I, and it really works well! Now I'm wondering if I can do it with me and my World of Warcraft character, and if it can handle two different styles like that.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731705234.0,
                    "parent_id": "t3_1grxlw8",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lxbwdfm/"
                },
                {
                    "id": "lxcgeem",
                    "author": "Independent-Shine-90",
                    "body": "Very cool .. it might help me with a project thank you",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711681.0,
                    "parent_id": "t3_1grxlw8",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lxcgeem/"
                },
                {
                    "id": "lxb90b7",
                    "author": "dddimish",
                    "body": "[https://github.com/cocktailpeanut/fluxgym](https://github.com/cocktailpeanut/fluxgym)  \nОК",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731698080.0,
                    "parent_id": "t1_lxb5own",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lxb90b7/"
                },
                {
                    "id": "lxds00x",
                    "author": "EpicNoiseFix",
                    "body": "Yes it can!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729936.0,
                    "parent_id": "t1_lxbwdfm",
                    "link_id": "t3_1grxlw8",
                    "permalink": "/r/StableDiffusion/comments/1grxlw8/multiple_consistent_elements_in_one_flux_lora/lxds00x/"
                }
            ]
        },
        {
            "id": "1grwwck",
            "title": "tag to lora converter?",
            "author": "Tionard",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 6,
            "created_utc": 1731678971.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/",
            "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/",
            "selftext": "I'm long time SD tools user, like A1111 and ComfyUI but I'm looking for tool or plugin where instead of selecting loras manualy I'd be able to just write my prompt normaly and if I mention certain keyword - lora would automaticly apply? I have a collection of loras on styles and settings and concepts but sometimes it's just way too time consuming when I want to play around with concepts and styles and have to spend extra few minutes to just set up things correctly and try.   \n  \nIs there a way to make life a bit easier, \"midjournify\" prompting so to speak?",
            "comments": [
                {
                    "id": "lx9lqpy",
                    "author": "elwray47",
                    "body": "Have you ever tried civitai helper?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731680136.0,
                    "parent_id": "t3_1grwwck",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lx9lqpy/"
                },
                {
                    "id": "lxa12u9",
                    "author": "no_witty_username",
                    "body": "I think nodes like that exist for comfy as I feel I ran in to them at some point, but don't remember the exact name.  Also a way to do this would be a with a word replaces ext2nsion in Automaric1111.  You simply tell it that the word \"cartoon\" should always be associated with \"Ghibli:0.7\" and it will replace cartoon with that Lora and its strength in the prompt box.  Then theres also a way of doing that with an LLM node connected to prompt node in comfy..",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731685046.0,
                    "parent_id": "t3_1grwwck",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lxa12u9/"
                },
                {
                    "id": "lxbkrfw",
                    "author": "Tionard",
                    "body": "One question.\nWhy posts like mine get downvoted?\nIs this subreddit against people asking and learning things about SD? Is my post should shoot out rainbows and show new AI advancements in order to at least not get downvoted for 0 reasons?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731701696.0,
                    "parent_id": "t3_1grwwck",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lxbkrfw/"
                },
                {
                    "id": "lx9mw3b",
                    "author": "Tionard",
                    "body": "Yeah, i use it and it's now what I mean. Civitai helper helps putting keywords from lora into prompt.\n\nWhat I need: I write prompt as normal, don't look for loras, just typing \"watercolor\" for example and I want a plagin that would replace \"watercolor\" with whatever lora call of the same name and it's keywords.  Ideally if I could also setup default strength for each lora",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731680528.0,
                    "parent_id": "t1_lx9lqpy",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lx9mw3b/"
                },
                {
                    "id": "lxa1i1x",
                    "author": "Tionard",
                    "body": "Yeah, something like that should work!\n\nThanks for pointing me in the right direction 👍",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731685158.0,
                    "parent_id": "t1_lxa12u9",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lxa1i1x/"
                },
                {
                    "id": "lx9wxoj",
                    "author": "elwray47",
                    "body": "Okay, I understand, nice idea, unfortunately, I don't know if it exists.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731683768.0,
                    "parent_id": "t1_lx9mw3b",
                    "link_id": "t3_1grwwck",
                    "permalink": "/r/StableDiffusion/comments/1grwwck/tag_to_lora_converter/lx9wxoj/"
                }
            ]
        },
        {
            "id": "1grwvdv",
            "title": "Python Program For Removing Image Backgrounds Interactively Using Open Weight Models",
            "author": "nine1seven3oh",
            "score": 4,
            "upvotes": 4,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731678888.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grwvdv/python_program_for_removing_image_backgrounds/",
            "permalink": "/r/StableDiffusion/comments/1grwvdv/python_program_for_removing_image_backgrounds/",
            "selftext": "https://github.com/pricklygorse/Interactive-Image-Background-Remover\n\nThis isn't Stable Diffusion or image generation but I've seen a few other background removal posts, so hopefully this is useful for someone.\n\n\nI've made a python program that lets you use a combination of open weight 'whole image' background removal models (rmbg, disnet, unet, birefnet) and the interactive model Segment Anything (specify points and drawn boxes). Think of it as a poor man's version of Photoroom, but no where near as feature rich yet. The models are typically limited to 1024x1024px or smaller masks, so with this you can zoom in and out and run the models on individual parts of the image for higher fidelity, and incrementally build up your final image. There is a manual paint brush mode for touching up the image without using a model, and a image editor for common adjustments such as brightness, shadow, sharpness etc. \n\n\n\nI'm not sure how much use the program is for most people as it is tailored to my use case, and I'm certain someone else must have already made something similar/better. But I've spent a bit of time on it and I use it regularly, so I wanted to share instead of sitting on it. The code probably has a few bugs so let me know or feel free to submit a fix/feature. Has been tested on Linux, briefly on Windows, but not Mac.",
            "comments": []
        },
        {
            "id": "1grv53e",
            "title": "What are your must-have ComfyUI workflows?",
            "author": "Hunt3rseeker_Twitch",
            "score": 49,
            "upvotes": 49,
            "downvotes": 0,
            "num_comments": 37,
            "created_utc": 1731673332.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/",
            "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/",
            "selftext": "I'm pretty new to the whole AI community, discovered this new favorite interest of mine back in March, using A1111 Forge exclusively. \n\nVery recently, I felt brave enough to actually sink some time into learning ComfyUI. I have no previous coding or IT experience, and I am astonished; that stuff takes so long to learn!! I feel like everything is so incredibly specific when it comes to nodes; what do they even do? How do I connect it? What other thousand nodes are compatible with a specific node? What about all the COMBINATIONS?? 😩😩\n\nOk rant over... Anyway, to my point. I've noticed that I learn better (and obviously it's easier to generate) with good workflows! If you have any that you'd like to share that you feel are essential for your every day work, I'd greatly appreciate it!\n\n(PS I know about civitai and comfy workflows)",
            "comments": [
                {
                    "id": "lx95xr9",
                    "author": "coolfozzie",
                    "body": "My best tip for you is the get the rgthree nodes that has a group bypass and group muter. Then slowly build out a workflow that has a group for Lora and a group for control net. Then you can just turn those groups on or off when you need them. You can do the same for image to image and inpaintng. Eventually you can get a setup that is somewhat similar in function to a111. \n\nTake your time. Download other workflows to learn the process but then the way to really understand is to build the workflow from scratch.",
                    "score": 26,
                    "upvotes": 26,
                    "downvotes": 0,
                    "created_utc": 1731674214.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx95xr9/"
                },
                {
                    "id": "lxabuoj",
                    "author": "the_forbidden_won",
                    "body": "This guy has some good workflows for all the basics:\n\nhttps://civitai.com/models/912123/all-simple-workflow-flux-or-upscale-or-lora-or-gguf-or-civitai-metadata",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731688243.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxabuoj/"
                },
                {
                    "id": "lx96py1",
                    "author": "HellkerN",
                    "body": "I just start from scratch and add things I need, until it turns into an incomprehensible spaghetti mess, then start from scratch again.",
                    "score": 15,
                    "upvotes": 15,
                    "downvotes": 0,
                    "created_utc": 1731674544.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx96py1/"
                },
                {
                    "id": "lx963va",
                    "author": "Herr_Drosselmeyer",
                    "body": "Ultimate Flux Workflow from AItrepteneur. You can grab it for free from his patron (need to sign up and follow but don't need to pay) here: https://www.patreon.com/aitrepreneur.\n\nIt's a really good all in one solution for flux. \n\nEDIT: It's a bit hard to find so here's the direct link: [https://www.patreon.com/file?h=112499790&m=356163391](https://www.patreon.com/file?h=112499790&m=356163391)",
                    "score": 14,
                    "upvotes": 14,
                    "downvotes": 0,
                    "created_utc": 1731674287.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx963va/"
                },
                {
                    "id": "lxa58zk",
                    "author": "Whatseekeththee",
                    "body": "Not sure if anyone said it yet, but if you are uncertain about what node connects to what other node you can drag the connection to an empty space, you will get a search menu that includes all nodes that have the correct input type for the connection. Pretty useful. Good luck.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731686282.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxa58zk/"
                },
                {
                    "id": "lxcthm0",
                    "author": "danamir_",
                    "body": "Weeell, if you want to dissect some workflows, here are some of mine, go wild. 😅 Just mute/unmute image outputs to enable/disable features, and bypass some optional nodes. And I use groups of routers to build visual switches.\n\n\"Mid\" workflow, with txt2img, img2img, detailer, upscaler : [SDXL Danamir Mid v52a.json](https://pastebin.com/nfKKurEn)\n\n\"Regional prompting\" workflow with regions, detailer, upscaler : [Danamir Regional Prompting v21.json](https://pastebin.com/AQfQn6Dh)\n\n\"Flux\" with flux, upscaler, optional SDXL second pass, detailer : [Danamir Flux v18.json](https://pastebin.com/qQNCWmnY)\n\nI also had a more advanced workflow for ControlNet and inpainting, but now I find it much much easier to do in [krita-ai-diffusion](https://github.com/Acly/krita-ai-diffusion) since you can draw the masks directly and use layers.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731716432.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxcthm0/"
                },
                {
                    "id": "lxcg6n3",
                    "author": "Own_Proof",
                    "body": "Have been looking for a good caption workflow (Florence or Joycaption) that has the ability to bulk caption and have the subject’s name already in the caption",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711604.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxcg6n3/"
                },
                {
                    "id": "lxctbw9",
                    "author": "probello",
                    "body": "How would you do something like omnigen where you say I want this from image 1 on that from image 2 using plain English. Can’t wrap my head around a node based version of that",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716374.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxctbw9/"
                },
                {
                    "id": "lxdo8ah",
                    "author": "Most_Way_9754",
                    "body": "The workflow you use will depend on what you're trying to do right? There are some all in one workflows that do everything related to image generation for example. But I prefer the workflows that do one specific thing, e.g. in-painting.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728372.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxdo8ah/"
                },
                {
                    "id": "lxdqo06",
                    "author": "Botoni",
                    "body": "Best workflows are those that do one thing, do it well and efficiently, in the simplest way possible and the least custom nodes.\n\nThose are easy to use, understand, debug, maintain and update.\n\nFor little additions like add a Lora, caption or controlnet, there are node templates, (although is totally fine to save them in workflow files and use the \"add to actual workflow\" option).\n\nUse the copy and paste (clipspace) right clic option to move images between workflows. There's a \"send to workflow\" option too I think",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729363.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxdqo06/"
                },
                {
                    "id": "lx9akjk",
                    "author": "ParanoidMarvin42",
                    "body": "IMHO ConfyUI is a mess from a UX standpoint.\n\nI’m a developer, so i might be biased, but it seems to me that this visual approach may work only up to a certain level of complexity. Write code is far easier and coherent for almost all non basic workflow.\n\nSo yeah, It’s a complex subject and Comfy make it even harder to understand everything creating a layer over the real stuff that you also have to lean. \n\nTL;DR: it’s not you, it’s comfy.",
                    "score": -1,
                    "upvotes": -1,
                    "downvotes": 0,
                    "created_utc": 1731676081.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9akjk/"
                },
                {
                    "id": "lx9uyco",
                    "author": "i-hate-jurdn",
                    "body": "The best comfyUI workflow is understanding how it all works so you can build workflows on the fly for your use cases....",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731683154.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9uyco/"
                },
                {
                    "id": "lx95pih",
                    "author": "victorc25",
                    "body": "What do you want to do? ",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731674114.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx95pih/"
                },
                {
                    "id": "lx9c5pc",
                    "author": "imrsn",
                    "body": "Ive just made a few basic ones that I use all the time. Text to image that supports multi loras, inpainting, outpainting, and resize. I wanna try some controlnet next.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731676689.0,
                    "parent_id": "t3_1grv53e",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9c5pc/"
                },
                {
                    "id": "lx9gb5a",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "Ohh I didn't know groups worked like that! I was playing around with a workflow yesterday and I wanted to turn some nodes off, but couldn't find anything except the, I think is called \"mode->turn off\"? Which gave me errors so I just ended up deleting the nodes for now. I'll give groups a try!\n\nQuick question: I think I've seen groups in other workflows that are not directly connected to the other groups. Is that a thing? If yes; how does comfy know where to continue if there's a stop in the middle?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731678223.0,
                    "parent_id": "t1_lx95xr9",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9gb5a/"
                },
                {
                    "id": "lxb1p3p",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "Oh cool, I'm mostly looking for AI related stuff on civitai, but this slipped under the radar! Checking it out, thanks!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731695909.0,
                    "parent_id": "t1_lxabuoj",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxb1p3p/"
                },
                {
                    "id": "lx9owcl",
                    "author": "Aitrepreneur",
                    "body": "Thanks, I appreciate the shoutout. u/Hunt3rseeker_Twitch should definitely watch my videos on how to use the workflow and how to install all the files and models, there is a lot to dl for the V2.... I even made a troubleshooting video on patreon yesterday that shows the install from scratch and give tips and fixes for the most common issues I saw from my patreons like the pulid flux node error and the missing nodes.  \nSo if it's your first time ya got a lot to learn my man... but it's freaking worth it imo, I personally love Flux even if some people in the community find it overrated. To each their own I suppose.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731681198.0,
                    "parent_id": "t1_lx963va",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9owcl/"
                },
                {
                    "id": "lx9f0f4",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "That sounds definitely like something for me! I'll check it out, thanks:)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731677751.0,
                    "parent_id": "t1_lx963va",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9f0f4/"
                },
                {
                    "id": "lx9g9hi",
                    "author": "None",
                    "body": "[deleted]",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678206.0,
                    "parent_id": "t1_lx963va",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9g9hi/"
                },
                {
                    "id": "lx9h5l6",
                    "author": "surim0n",
                    "body": "is it the manual install version?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678527.0,
                    "parent_id": "t1_lx963va",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9h5l6/"
                },
                {
                    "id": "lxb2xqn",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "That is practical! I didn't find the suggestions (the ones in the same bar that pops up) very helpful, but this I'm definitively going to use. Thanks:)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696277.0,
                    "parent_id": "t1_lxa58zk",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxb2xqn/"
                },
                {
                    "id": "lxdno92",
                    "author": "Most_Way_9754",
                    "body": "You need text find and replace from WAS node suite to replace the name of your subject into Florence caption.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728151.0,
                    "parent_id": "t1_lxcg6n3",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxdno92/"
                },
                {
                    "id": "lxbxr0w",
                    "author": "RO4DHOG",
                    "body": "I second this, and I'm a gamer so I might have a low attention span.\n\nI generate 4K wallpapers, and srtip the clothes off celebrities.\n\nDoing this in Stable Diffusion, with ComfyUI, SwarmUI, AnapoeUX, or Auto1111, is easy... once you get Python and Git installed.\n\nBut that spaghetti interface is obnoxious, while fascinating to watch during image generations.\n\nSimply doing TXT2IMG/IMG2IMG with INIT images and CONTROLNET's like T2I-CANNY or T2I-DEPTH, provide complete control of the result.  Upscaling a 1280x720 resolution with 20-40 steps using DPM2++, EULER, or HUERAN sampling and SIMPLE, NORMAL, or KARRAS scheduling to 3x resolution of 3840x2160 with only 10 steps is perfect.\n\nDoing all that using any SDXL models (JuggernaughtXL, RealitiesEdgeXL, etc.) with another SDXL as the refiner (aka HiresFix) is fun to mix and match with DENOISING at .25ish (.35 starts to change the image, and anything higher pretty much mutilates the initial image and becomes random)\n\nAll from the comfort of a classic user interface with sliders an checkboxes.\n\nhttps://preview.redd.it/wkehkaezt41e1.png?width=1920&format=png&auto=webp&s=b1919927647d65bf891236cdf5620e2ff75c5236",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731705652.0,
                    "parent_id": "t1_lx9akjk",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxbxr0w/"
                },
                {
                    "id": "lx9za08",
                    "author": "moofunk",
                    "body": "If ComfyUI had Houdini style networks, you could make much larger and comprehensive nested networks and it would be a lot easier to follow them.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731684483.0,
                    "parent_id": "t1_lx9akjk",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9za08/"
                },
                {
                    "id": "lxb3jfs",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "I mean.. That is very obvious isn't it? The point of my post was to see if I could learn more about nodes and how they work. It's a very long way for me until I'd be a know-it-all comfyui user",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731696454.0,
                    "parent_id": "t1_lx9uyco",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxb3jfs/"
                },
                {
                    "id": "lx9etxx",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "That should have been obvious for me to write in the post, wops 😅\n\nI'm mainly into text2img and img2img (pony, sdxl, flux). I also like upscaling, img restoration, and prompt related stuff like wildcards and randomization! I recently upgraded my gpu to a 4070 ti super and I've been excited to try out some img2vid stuff, but those workflows are way too complicated for me atm.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731677687.0,
                    "parent_id": "t1_lx95pih",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9etxx/"
                },
                {
                    "id": "lx9qlg3",
                    "author": "Vaughn",
                    "body": "You want ctrl-b and ctrl-m most of the time.\n\nCtrl-b (bypass) skips that node, but passes data through by type. This can be used to bypass e.g. lora loading, where the input and output data are the same. (Trying it on VAE decode doesn't work, obviously.)\n\nCtrl-m (mute) disables that specific mode. Anything that depends on it will fail to run. If you mute an output node (preview/save), then everything that is *only* needed by that node will be skipped.\n\nRgthree has group bypass / group mute, which does the same thing for... groups of nodes, predictably. That's useful if e.g. you have a group that transforms something from an image, to a latent, and back to an image; bypassing just one of those steps will break the workflow after it, but bypassing all of them will make comfy pass the image through.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731681759.0,
                    "parent_id": "t1_lx9gb5a",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9qlg3/"
                },
                {
                    "id": "lx9z6mr",
                    "author": "Enshitification",
                    "body": "I forget the name of the node, but you can connect an output to it and give it a name. Then anywhere you want to use that output, you can connect another node and use that name. It makes for a much cleaner looking workflow, but it can also make it more confusing when you can't see the connections.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731684455.0,
                    "parent_id": "t1_lx9gb5a",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9z6mr/"
                },
                {
                    "id": "lx9u8m1",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "Haha yeah that must be an... Intense workflow if you have to make a whole additional video about how to solve errors 😁 I saved the link so I'll have it when I need it! I've seen many people say that it is very worth learning in the end, even though it can be a struggle. I'll keep on trying, I might just need to slow down a bit... I think I have the \"I wanna learn everything RIGHT NOW!\" phase 😄\n\nGreat content by the way, been watching ever since I installed Forge:) Keep it up",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731682928.0,
                    "parent_id": "t1_lx9owcl",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9u8m1/"
                },
                {
                    "id": "lxcpjty",
                    "author": "stuartullman",
                    "body": "you are doing the lords work.  thoroughly impressed",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731714969.0,
                    "parent_id": "t1_lx9owcl",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxcpjty/"
                },
                {
                    "id": "lx9gtuc",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "Hmm no I think you are mistaken, I found and downloaded a flux workflow just now.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678411.0,
                    "parent_id": "t1_lx9g9hi",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9gtuc/"
                },
                {
                    "id": "lx9jfok",
                    "author": "Herr_Drosselmeyer",
                    "body": "I've added a direct link.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731679333.0,
                    "parent_id": "t1_lx9h5l6",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9jfok/"
                },
                {
                    "id": "lxbyqji",
                    "author": "RO4DHOG",
                    "body": "plus, if you want to change yourself into a Muppet, use ControlNET CANNY.\n\nhttps://preview.redd.it/owubgxkvu41e1.png?width=1677&format=png&auto=webp&s=67d8e881a7324ed384cb636bfdd265a41fa05c5b",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731705955.0,
                    "parent_id": "t1_lxbxr0w",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxbyqji/"
                },
                {
                    "id": "lxbac2r",
                    "author": "i-hate-jurdn",
                    "body": "I think the \"how\" is often explained when a need arises for it.\n\nI would say don't force yourself to learn it, just figure things out as the need arises. It will take time to learn, but it is a fun exploration. At least it was for me.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698481.0,
                    "parent_id": "t1_lxb3jfs",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxbac2r/"
                },
                {
                    "id": "lxdn96t",
                    "author": "Most_Way_9754",
                    "body": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/tree/main/examples\n\nGrab the CogVideoX wrapper and the included I2V examples from Kijai's repository. The workflow is not complicated at all, thanks to Kijai.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731727984.0,
                    "parent_id": "t1_lx9etxx",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lxdn96t/"
                },
                {
                    "id": "lx9h4b5",
                    "author": "Hunt3rseeker_Twitch",
                    "body": "And he names his files without any spaces V2-ULTIMATE_FLUX_ALL-IN-ONE-WORKFLOW.json 😩 God bless that mans soul",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731678515.0,
                    "parent_id": "t1_lx9gtuc",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9h4b5/"
                },
                {
                    "id": "lx9ke08",
                    "author": "HellkerN",
                    "body": "Old-school, lol, hard to unlearn. I also try to keep paths short even though that limit hasn't been a thing for a long while.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731679668.0,
                    "parent_id": "t1_lx9h4b5",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9ke08/"
                },
                {
                    "id": "lx9ojhi",
                    "author": "vanonym_",
                    "body": "putting version first is weird too",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731681078.0,
                    "parent_id": "t1_lx9ke08",
                    "link_id": "t3_1grv53e",
                    "permalink": "/r/StableDiffusion/comments/1grv53e/what_are_your_musthave_comfyui_workflows/lx9ojhi/"
                }
            ]
        },
        {
            "id": "1grurp1",
            "title": "Problems with petals\\leaves in generations with PDXL and overall instability.",
            "author": "GiGiGus",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731672011.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grurp1/problems_with_petalsleaves_in_generations_with/",
            "permalink": "/r/StableDiffusion/comments/1grurp1/problems_with_petalsleaves_in_generations_with/",
            "selftext": "This problem was persistent in Forge as well and I dont know what causes it (as well as overdetailed background). If I to use stock Pony it gets messier and if I use something like IllustriousXL it will generate complete mess (first one is PDXL based model, second one is IllustriousXL with cleared score tags).\n\nhttps://preview.redd.it/zviv7dqpz11e1.png?width=3439&format=png&auto=webp&s=4791ad536b62eb2ed4bc60967b1c08343fa560db\n\nhttps://preview.redd.it/vhyjg2rhz11e1.png?width=1280&format=png&auto=webp&s=226b339547bf2b2940985b8694bb2a9dd7404ee1\n\nhttps://preview.redd.it/vb7pxv8c121e1.png?width=1280&format=png&auto=webp&s=fad530508bd0513f4712f5ba630b3726c46ed207\n\n",
            "comments": [
                {
                    "id": "lx9vcps",
                    "author": "ScavRU",
                    "body": "use sdxl vae",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731683278.0,
                    "parent_id": "t3_1grurp1",
                    "link_id": "t3_1grurp1",
                    "permalink": "/r/StableDiffusion/comments/1grurp1/problems_with_petalsleaves_in_generations_with/lx9vcps/"
                }
            ]
        },
        {
            "id": "1grurg3",
            "title": "ImageToImage how to make it more similar to the original image?",
            "author": "lordkamael",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731671987.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/",
            "permalink": "/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/",
            "selftext": "so i'm using webUI reforged, i friend of mine made an illustration of a plane, all i want is to create multiple renditions of it but using the powers of ai to add more detail to his art, since his drawing is super flat. but the ai changes too much, changes the shape of the plane, it basically creates a totally different plane, although in a similar \"pose\" i want to make it more similar to the original image, i tried using control net, i enabled \"reference\", \"canny\", \"depth\" but none seems to change that problem, the output just looks too different from the source image...what am i doing wrong? i'm sure it's related to some setting i'm missing, cfg maybe? i have no idea, help me please.",
            "comments": [
                {
                    "id": "lx91csn",
                    "author": "_kitmeng",
                    "body": "Lower the Denoise value to 0.2-0.4",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731672168.0,
                    "parent_id": "t3_1grurg3",
                    "link_id": "t3_1grurg3",
                    "permalink": "/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/lx91csn/"
                },
                {
                    "id": "lx92ina",
                    "author": "lordkamael",
                    "body": "thank you, i'll try that",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731672714.0,
                    "parent_id": "t1_lx91csn",
                    "link_id": "t3_1grurg3",
                    "permalink": "/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/lx92ina/"
                },
                {
                    "id": "lx978tk",
                    "author": "aerilyn235",
                    "body": "Or add some controlnet (lineart/scribble if its a simple drawing) to preserve the shape.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731674760.0,
                    "parent_id": "t1_lx92ina",
                    "link_id": "t3_1grurg3",
                    "permalink": "/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/lx978tk/"
                },
                {
                    "id": "lx9jq6w",
                    "author": "lordkamael",
                    "body": "yep it worked very well, thanks a lot!!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731679435.0,
                    "parent_id": "t1_lx978tk",
                    "link_id": "t3_1grurg3",
                    "permalink": "/r/StableDiffusion/comments/1grurg3/imagetoimage_how_to_make_it_more_similar_to_the/lx9jq6w/"
                }
            ]
        },
        {
            "id": "1grupz4",
            "title": "I think I have a workaround for the laggy inpaint sketching in some browsers for WebUI A1111/Forge/ReForge (Gradio 3 DPI scaling bug)",
            "author": "Number6UK",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731671837.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grupz4/i_think_i_have_a_workaround_for_the_laggy_inpaint/",
            "permalink": "/r/StableDiffusion/comments/1grupz4/i_think_i_have_a_workaround_for_the_laggy_inpaint/",
            "selftext": "My workaround at the moment (on Windows 11, but there'll be an equivalent for the other OSs), which I'm still testing but seems to work so far, is to:\n\n> 1)    Always use a particular browser for WebUI stuff; in my case, Firefox Developer Edition.\n> \n> 2)    Create a shortcut for the browser's .exe\n> \n> 3)    Right cilck the shortcut > Compatibility tab > Change high DPI settings button\n> \n> 4)    In Program DPI, tick the box Use this setting to fix scaling problems for this program instead of the ones in Settings\n> \n> 5)    In High DPI scaling override, tick the box Override high DPI scaling behaviour. In the Scaling performed by: dropdown, choose System (Enhanced) (this might not be available on older versions of Windows - if not, try one of the other options; I haven't tested them myself yet)\n> \n> 6)    Press OK to close the High DPI settings window,\n> \n> 7)    Press OK to close the shortcut properties window.\n> \n> 8)    Close any instance of the browser affected by the High DPI change - e.g. if you were setting the DPI settings on a shortcut to chrome.exe, close all instances of Chrome.\n> \n> 9)    Start the browser from the shortcut you set the properties on.\n> \n> 10)    Open the WebUI in that browser and see if the bug still occurs\n\nHopefully it will help you. The main drawbacks to this workaround are having to use a different browser just for WebUI, the fonts being a tiny bit less pretty, and some odd mouseover issues where tooltips sometimes show up a large distance from the mouse cursor. I've not found anything that's actually broken by this method however and have been using it for over a week now sucessfully.\n\nHope it works for you too.\n\n(PS, Mods - I had to pick a flair, but none of the flairs provided seemed to fit so had to put it as 'question - help' - it would be great if there was something that fit better maybe?)",
            "comments": [
                {
                    "id": "lxa9f3o",
                    "author": "red__dragon",
                    "body": ">  Always use a particular browser for WebUI stuff; in my case, Firefox Developer Edition.\n\nIf you use Firefox, you can create a separate profile and have a distinct shortcut to it!\n\nNavigating to `about:profiles` in Firefox helps create and manage them, and adding `-P \"profile-name\"` to the end of your shortcut path will launch that Firefox instance directly to the named profile.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731687522.0,
                    "parent_id": "t3_1grupz4",
                    "link_id": "t3_1grupz4",
                    "permalink": "/r/StableDiffusion/comments/1grupz4/i_think_i_have_a_workaround_for_the_laggy_inpaint/lxa9f3o/"
                },
                {
                    "id": "lxcmo96",
                    "author": "Number6UK",
                    "body": "Yep, I tried that however it seems to apply the shortcut's DPI settings to any instance of that Firefox.exe, even if it's in a different profile. (But not a Firefox.exe located somewhere else, like my normal non-Dev Firefox.exe)\n\ni.e. if the first Firefox.exe (regardless of any profile switches) that you open is not via the DPI altered shortcut, none of the subsequent ones will have DPI change even if you do use the DPI altered shortcut.\n\nLikewise, the opposite is true.\nIf no Firefox.exe's are running, and you use the DPI override shortcut, then open another Firefox.exe which has a different FF profile, it will also have the DPI override applied to it.\n\nFirefox's profile system is pretty janky when it comes down to it.\n\nWhat might work is copying the Firefox.exe (or Chrome.exe, etc.) and naming it something like FirefoxWithDPIOverride.exe then applying it to that - that might be enough to trick it into seeing it as a completely separate thing. I haven't tested that yet but it's worth a shot.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731713917.0,
                    "parent_id": "t1_lxa9f3o",
                    "link_id": "t3_1grupz4",
                    "permalink": "/r/StableDiffusion/comments/1grupz4/i_think_i_have_a_workaround_for_the_laggy_inpaint/lxcmo96/"
                }
            ]
        },
        {
            "id": "1grucre",
            "title": "Is it worth upgrading from 8GB vram to 12gb",
            "author": "Kiyushia",
            "score": 14,
            "upvotes": 14,
            "downvotes": 0,
            "num_comments": 55,
            "created_utc": 1731670422.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/",
            "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/",
            "selftext": "Thinking on upgrading from 2060 super 8gb to 3060 12gb, would it give any difference in speed?",
            "comments": [
                {
                    "id": "lx96bhm",
                    "author": "SideMurky8087",
                    "body": "8gb to 16gb 4060ti worth",
                    "score": 31,
                    "upvotes": 31,
                    "downvotes": 0,
                    "created_utc": 1731674376.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx96bhm/"
                },
                {
                    "id": "lx9zgmz",
                    "author": "nitinmukesh_79",
                    "body": "Not worth.\n\nGo for 16 or 24.",
                    "score": 12,
                    "upvotes": 12,
                    "downvotes": 0,
                    "created_utc": 1731684539.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9zgmz/"
                },
                {
                    "id": "lx9aeeg",
                    "author": "pumukidelfuturo",
                    "body": "I have 8gb and I'm constantly screwed, too. That's a good question. I'd aim for 16gb vram minimum. You can train SDXL loras with batch size 4 with 16gb (unlike 12gb). That means a difference of 25-27 minutes training agaisnt 120 minutes training. Training FLUX is a lot better too. Moreover, things like Mochi will need 16gb bare minimum. I don't think from 8 to 12 gb is really a big or substantial leap but depends on what you're paying for. If you find a super good deal with 12gb go for it, ofc.",
                    "score": 10,
                    "upvotes": 10,
                    "downvotes": 0,
                    "created_utc": 1731676014.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9aeeg/"
                },
                {
                    "id": "lx9gve0",
                    "author": "mk8933",
                    "body": "Yes it's worth it. 4gb extra Vram, more cuda cores. BUT...since we are almost in 2025 and you are in the market for something more. I'd say aim for 16gb. \n\nI have 12gb and its been great. I never felt left out. 1.5 and sdxl runs fast. Flux and SD 3.5 runs well and I can also play with a few LLMs.",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731678427.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9gve0/"
                },
                {
                    "id": "lx956q6",
                    "author": "Xylber",
                    "body": "go 24gb directly.",
                    "score": 13,
                    "upvotes": 13,
                    "downvotes": 0,
                    "created_utc": 1731673891.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx956q6/"
                },
                {
                    "id": "lx9gbl9",
                    "author": "m26x2",
                    "body": "In my opinion, the 4060ti is currently a good (maybe the best) compromise between price and performance. Even if 16GB of VRAM is quite scarce for some of the new models - the card is at least affordable",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731678228.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9gbl9/"
                },
                {
                    "id": "lx9uwss",
                    "author": "moofunk",
                    "body": "If you get a 12 GB card, then using both cards in the machine would allow using the big one entirely for Stable Diffusion, so you get a bit more than 8 to 12 GB as the main GPU needs some memory for the browser and other things.\n\nIt will also allow you to run other things on the main card without disturbing SD.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731683141.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9uwss/"
                },
                {
                    "id": "lx9k2t4",
                    "author": "gorpium",
                    "body": "I recently upgraded from 1070/8 to 3060/12. So much better, but I have to give the GPU some credit as well.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731679558.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9k2t4/"
                },
                {
                    "id": "lxb71v0",
                    "author": "fallingdowndizzyvr",
                    "body": "Worth it. It's not about speed, it's about being able to run models. Both because of the extra 4GB of VRAM and BF16 support. Case in point, you can't run CogVideox on a 2060, you can on a 3060. You can't run Mochi on the 2060, you can on a 3060 12GB.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731697495.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxb71v0/"
                },
                {
                    "id": "lx8zh6p",
                    "author": "yamfun",
                    "body": "Not worth it",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731671269.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx8zh6p/"
                },
                {
                    "id": "lxakjli",
                    "author": "Django_McFly",
                    "body": "We're already at a world where 16gb is starting to be the new minimum for next-gen models.  12 vs 8 will do something but unless that 3060 is dirt cheap vs a 16gb Nvidia card, I'd go with a 16gb Nvidia card.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731690808.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxakjli/"
                },
                {
                    "id": "lxbmsuw",
                    "author": "SweetLikeACandy",
                    "body": "I got a 3060 and I'd suggest to get at least a 4060Ti with 16GB.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731702319.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxbmsuw/"
                },
                {
                    "id": "lx92p4s",
                    "author": "supereatball",
                    "body": "Big difference in speed and you can run a better flux quant",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731672796.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx92p4s/"
                },
                {
                    "id": "lx949n3",
                    "author": "arewemartiansyet",
                    "body": "Unless you get it dirt cheap it doesn't seem worth it. I'd wait until the 5000 series releases and then try to find a used 4080/90 that's affordable for you.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731673493.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx949n3/"
                },
                {
                    "id": "lx905vf",
                    "author": "Mashic",
                    "body": "I did it, the only benefit is being able to use whisper large model.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731671603.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx905vf/"
                },
                {
                    "id": "lx976u9",
                    "author": "birazacele",
                    "body": "hmm i am not happy with the AI ​​speed of the RTX 3060. it will get better but don't expect a miracle.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731674738.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx976u9/"
                },
                {
                    "id": "lx9lx8q",
                    "author": "Apprehensive_Map64",
                    "body": "Not worth it, 16gb seems like a fair minimum going forward",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731680198.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9lx8q/"
                },
                {
                    "id": "lx9scgk",
                    "author": "Annual_Two7315",
                    "body": "Go to more, if not, it doesn't worth it, cause soon you'll have to upgrade again",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731682325.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9scgk/"
                },
                {
                    "id": "lx9xvwg",
                    "author": "YMIR_THE_FROSTY",
                    "body": "I would even upgrade to 2080 with 16gb probaby. :D\n\nIf you cant go higher, 12GB helps, if you can go higher, go.. there is nothing like too much VRAM these days when it comes to AI.\n\nYea and it does apply to system RAM too. My current plan is to have at least 128GB.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731684060.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9xvwg/"
                },
                {
                    "id": "lx9y4wy",
                    "author": "gpahul",
                    "body": "8 to 32 GB will make difference",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731684137.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9y4wy/"
                },
                {
                    "id": "lxaldfk",
                    "author": "sxosx",
                    "body": "Short answer: No\n\nLong answer, but shortened: Depends, but most likely no, you better aim for at least 16, or ideally 24(rumored 32) on next generation to be safe for next years to come",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731691057.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxaldfk/"
                },
                {
                    "id": "lxaxwwa",
                    "author": "s101c",
                    "body": "Depends on the cost of the upgrade. If you sell an existing card and get a new one, and spend only $60 max on top of that, yes, it is worth it.\n\nAnd yes, 3060 will be 20-25% faster.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731694795.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxaxwwa/"
                },
                {
                    "id": "lxbsqnr",
                    "author": "Bright-Consequence61",
                    "body": "These are soooo minor changes. At least 16GB, preferably 24GB. Save up some money and look to the future.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704130.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxbsqnr/"
                },
                {
                    "id": "lxcdv11",
                    "author": "ArmadstheDoom",
                    "body": "So like a year ago, I upgraded from a 1080 to a 3060 12gb. And it'll work. But at the time, I was only using 1.5 and XL, and it doesn't have a problem with either. Then flux came out. And it'll run flux. But it's pretty slow. \n\nSo what I would advise is, if you've got a slightly higher budget, either go for one of the higher end 3000 series of the 4000 series ones. \n\n12gb WILL run things. But looking ahead, you'll probably want 16gb.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731710804.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxcdv11/"
                },
                {
                    "id": "lxcooiq",
                    "author": "Sea-Resort730",
                    "body": "If very cheap and slotting in a second card to offload clip uf your workflows support it \n\nFor most people no, buy 16gb or bigger",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731714651.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxcooiq/"
                },
                {
                    "id": "lxctctz",
                    "author": "Lucaspittol",
                    "body": "For people telling it is a worthless upgrade, the 3060 is about half of the price of a 4060 where I live. The 4060 is US$5200-equivalent, while the 3060 12GB is US$1900-equivalent.   \nIt is definitely worth moving from 8GB to 12GB, but on my case, moving to 16GB is more than twice the price.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716383.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxctctz/"
                },
                {
                    "id": "lxdpmpx",
                    "author": "DrFlexit1",
                    "body": "I say go 24 gb.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731728941.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdpmpx/"
                },
                {
                    "id": "lxdsczb",
                    "author": "xantub",
                    "body": "If the question is to continue with 8 or go to 12, go to 12. If the question is what's the better upgrade, go 16 (unless you have a lot of money then go higher). For image and video generation, VRAM is king.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731730096.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdsczb/"
                },
                {
                    "id": "lx9etb1",
                    "author": "el_ramon",
                    "body": "Enough for SDXL, not enough for Flux or SD3.5",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731677681.0,
                    "parent_id": "t3_1grucre",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9etb1/"
                },
                {
                    "id": "lxb4wki",
                    "author": "NoSuggestion6629",
                    "body": "I think 16gb is the bare minimum these days for AI and even upper tier gaming to support 2K video framing and AI inference. Even 24gb VRAM is not enough to run the new FLUX DEV w/o some alterations.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731696858.0,
                    "parent_id": "t1_lx96bhm",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxb4wki/"
                },
                {
                    "id": "lxdpwox",
                    "author": "Kiyushia",
                    "body": "Im considering the 4060ti. But now I don't know if I take it or wait for 5060",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731729051.0,
                    "parent_id": "t1_lx96bhm",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdpwox/"
                },
                {
                    "id": "lxas9co",
                    "author": "Intention_Connect",
                    "body": "I'd vote for 32 g.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731693109.0,
                    "parent_id": "t1_lx956q6",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxas9co/"
                },
                {
                    "id": "lxbuf0o",
                    "author": "fallingdowndizzyvr",
                    "body": "Telling anyone to get a 4060 is telling them to go f* themselves. The 4060 is the nerfed generation.\n\n3060 - Bandwidth 360.0 GB/s \n\n4060ti - Bandwidth 288.0 GB/s",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731704639.0,
                    "parent_id": "t1_lxbmsuw",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxbuf0o/"
                },
                {
                    "id": "lx99od4",
                    "author": "pumukidelfuturo",
                    "body": "Maybe its just  me, but 4080 or 4009 never goes in the same sentence as \"affordable\"",
                    "score": 12,
                    "upvotes": 12,
                    "downvotes": 0,
                    "created_utc": 1731675729.0,
                    "parent_id": "t1_lx949n3",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx99od4/"
                },
                {
                    "id": "lx9ayyp",
                    "author": "Enshitification",
                    "body": "I doubt cards are ever going to go down in price in the US after Der Farter imposes trade tariffs next year.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731676234.0,
                    "parent_id": "t1_lx949n3",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9ayyp/"
                },
                {
                    "id": "lxctos1",
                    "author": "Lucaspittol",
                    "body": "The 3090 is still extremely expensive, even used. The 4090 is unlikely to go down in price too soon.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716508.0,
                    "parent_id": "t1_lx949n3",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxctos1/"
                },
                {
                    "id": "lxa388s",
                    "author": "tamal4444",
                    "body": "What speeds are you getting?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731685676.0,
                    "parent_id": "t1_lx976u9",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxa388s/"
                },
                {
                    "id": "lxcuact",
                    "author": "Lucaspittol",
                    "body": "Too steep of an upgrade for most countries. 4060 16GB here is more expensive than two 3060s 12GB.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716732.0,
                    "parent_id": "t1_lxcooiq",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxcuact/"
                },
                {
                    "id": "lx9wfzd",
                    "author": "stddealer",
                    "body": "Enough for 3.5 medium.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731683617.0,
                    "parent_id": "t1_lx9etb1",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9wfzd/"
                },
                {
                    "id": "lxa4yq4",
                    "author": "red__dragon",
                    "body": "Been running Flux on my 3060 12 GB since the nf4 and GGUF quants came out. It works slowly but works fine.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731686195.0,
                    "parent_id": "t1_lx9etb1",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxa4yq4/"
                },
                {
                    "id": "lxa51ky",
                    "author": "jib_reddit",
                    "body": "fp8 Flux is 11GB , so it fits on a 12GB card if you run the T5 clip on the CPU.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731686220.0,
                    "parent_id": "t1_lx9etb1",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxa51ky/"
                },
                {
                    "id": "lxcouls",
                    "author": "xyzzs",
                    "body": "Flux dev with fp8 runs great on my 3060ti and I can’t tell the difference between it and the full model on fai.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731714712.0,
                    "parent_id": "t1_lxb4wki",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxcouls/"
                },
                {
                    "id": "lxbwe6r",
                    "author": "batatahh",
                    "body": "64 is better",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731705240.0,
                    "parent_id": "t1_lxas9co",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxbwe6r/"
                },
                {
                    "id": "lxc86rq",
                    "author": "SweetLikeACandy",
                    "body": "You can go and do that if you want, I don't mind. Regardless the bandwidth, between 3060 and 4070Ti there isn't a better and cheaper 16GB option.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731708915.0,
                    "parent_id": "t1_lxbuf0o",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxc86rq/"
                },
                {
                    "id": "lx9eebk",
                    "author": "arewemartiansyet",
                    "body": "Well, I said a 'used' 4080 or 90. But you might still be correct, we'll see.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731677527.0,
                    "parent_id": "t1_lx99od4",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9eebk/"
                },
                {
                    "id": "lxctvjn",
                    "author": "Lucaspittol",
                    "body": "Trump is planning a 60% tariff, which means that GPUs will be twice as expensive in the US. Brazil imposes a 92% tariff for comparison, and a 3060 costs like US$2000 - equivalent.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731716578.0,
                    "parent_id": "t1_lx9ayyp",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxctvjn/"
                },
                {
                    "id": "lxe58rs",
                    "author": "Sea-Resort730",
                    "body": "The best option for them is an unlimited saas like [https://graydient.ai](https://graydient.ai) or some credits on [Civitai.com](https://Civitai.com) \n\nThat's like renting a 4090 for pennies a day",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731736227.0,
                    "parent_id": "t1_lxcuact",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxe58rs/"
                },
                {
                    "id": "lxbvvot",
                    "author": "BagOfFlies",
                    "body": "I'm running it on my 2080S 8GB so not sure why they'd say you can't run it with 12GB.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731705084.0,
                    "parent_id": "t1_lxa4yq4",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxbvvot/"
                },
                {
                    "id": "lxdi9jg",
                    "author": "mainichi",
                    "body": "About what kind of speed are you seeing with that? Looking to see if I should upgrade to something similar. Thanks.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731726027.0,
                    "parent_id": "t1_lxcouls",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdi9jg/"
                },
                {
                    "id": "lxdjhym",
                    "author": "JayRoss34",
                    "body": "Na 128 gb",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731726517.0,
                    "parent_id": "t1_lxbwe6r",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdjhym/"
                },
                {
                    "id": "lxdm6bo",
                    "author": "fallingdowndizzyvr",
                    "body": "You can buy nerfed if you want. I'll stick with non nerfed.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731727564.0,
                    "parent_id": "t1_lxc86rq",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxdm6bo/"
                },
                {
                    "id": "lx9rioo",
                    "author": "Rich_Consequence2633",
                    "body": "They are still going to be fairly expensive.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731682058.0,
                    "parent_id": "t1_lx9eebk",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lx9rioo/"
                },
                {
                    "id": "lxe3wyj",
                    "author": "Bazookasajizo",
                    "body": "What in the actual f*ck!?!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735606.0,
                    "parent_id": "t1_lxctvjn",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxe3wyj/"
                },
                {
                    "id": "lxe42z3",
                    "author": "Bazookasajizo",
                    "body": "Can confirm. 3060 ti (8gb). 1 minute for a flux dev generation seems fine to me. 12gb should allow faster gens",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731735687.0,
                    "parent_id": "t1_lxbvvot",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxe42z3/"
                },
                {
                    "id": "lxe3esc",
                    "author": "Bazookasajizo",
                    "body": "3060 ti, 1024X1024 image takes 1 minute and 10 seconds on NF4 V2 version of flux dev.\n\n\nNo additional things like loras, controlnet or highres fix etc",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731735365.0,
                    "parent_id": "t1_lxdi9jg",
                    "link_id": "t3_1grucre",
                    "permalink": "/r/StableDiffusion/comments/1grucre/is_it_worth_upgrading_from_8gb_vram_to_12gb/lxe3esc/"
                }
            ]
        },
        {
            "id": "1grtdmd",
            "title": "Testing out Shuttle 3 Diffusion",
            "author": "Tobaka",
            "score": 18,
            "upvotes": 18,
            "downvotes": 0,
            "num_comments": 18,
            "created_utc": 1731666311.0,
            "url": "https://www.reddit.com/gallery/1grtdmd",
            "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx96hvh",
                    "author": "Electronic-Metal2391",
                    "body": "Photo realistic images are terribly plastic with this model. This model is not for photo realistic images.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731674451.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx96hvh/"
                },
                {
                    "id": "lx8qgyl",
                    "author": "Tobaka",
                    "body": "Getting pretty cool results with the GGUF Q4 version of Shuttle 3 Diffusion: [https://huggingface.co/shuttleai/shuttle-3-diffusion](https://huggingface.co/shuttleai/shuttle-3-diffusion)\n\nFirst Prompt: In an intensely atmospheric oil painting rendered with dynamic brush strokes, a macro shot of an intricate android holding a delicate butterfly at the tip of its finger is captured. The scene takes place within the chaos of a battlefield, but it's as if time has momentarily paused to present this surreal and captivating moment. A dream-like quality pervades the image with cinematic lighting that casts an eerie dark glow over the landscape. Sharp contrast is achieved through soft focus on the android and butterfly while surrounding elements remain out of clear view, creating a sense of mystery. The battlefield appears chaotic with smoke and sparks filling the air\n\nHere's my super messy workflow with prompt builder and a bunch of other stuff: [https://civitai.com/models/908205/tobakaz-wild-n-messy-master-workflow](https://civitai.com/models/908205/tobakaz-wild-n-messy-master-workflow)",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731666332.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx8qgyl/"
                },
                {
                    "id": "lx8s6tv",
                    "author": "ResponsibleTruck4717",
                    "body": "How can it handle multi subject multi people?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731667369.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx8s6tv/"
                },
                {
                    "id": "lx9wjh0",
                    "author": "beti88",
                    "body": "![gif](giphy|LxPsfUhFxwRRC)",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731683647.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx9wjh0/"
                },
                {
                    "id": "lxaenyx",
                    "author": "ThenExtension9196",
                    "body": "Looks generic",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731689078.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxaenyx/"
                },
                {
                    "id": "lxc8sj3",
                    "author": "Fault23",
                    "body": "I mean, they look good but how long did it take to generate these pictures with your GPU?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731709116.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxc8sj3/"
                },
                {
                    "id": "lxd5bp1",
                    "author": "-becausereasons-",
                    "body": "I don't like images that scream \"AI\"",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731720915.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxd5bp1/"
                },
                {
                    "id": "lxdw3dt",
                    "author": "forlornhermit",
                    "body": "This thing works outside the box since it has schnell architecture so I can just run it in forge/comfyui with Flux loras?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731697.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxdw3dt/"
                },
                {
                    "id": "lxa0aaq",
                    "author": "Artforartsake99",
                    "body": "Looks like rubbish SD 1 l.5 to me",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731684795.0,
                    "parent_id": "t3_1grtdmd",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxa0aaq/"
                },
                {
                    "id": "lxcvhp9",
                    "author": "pumukidelfuturo",
                    "body": "schnell is bad at photorealism, anyways.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731717177.0,
                    "parent_id": "t1_lx96hvh",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxcvhp9/"
                },
                {
                    "id": "lx9i13f",
                    "author": "A_dot_Powell",
                    "body": "I'm curious what sampler and scheduler are you using? I am trying this out with 4 steps and a CFG of 1 with the fp8 version and getting nothing like your sampes. I also gave your workflow a look, and it is wow.  It would be great to build out from a basic workflow.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678840.0,
                    "parent_id": "t1_lx8qgyl",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx9i13f/"
                },
                {
                    "id": "lx8urug",
                    "author": "Tobaka",
                    "body": "https://preview.redd.it/9lqum9rkr11e1.png?width=1440&format=png&auto=webp&s=5e83979c578a1df5a399330d34adb8128e40c645\n\nI'm only using the GGUF Q4 version (with an SDXL refine/upscale), so not the best to judge by if you can use the bigger ones.\n\nPrompt: a group of survivors huddled in a dimly lit underground shelter, each person uniquely marked by the dystopia: a scarred rebel leader with cybernetic arms pointing at a glowing map, a mechanic adjusting a jury-rigged biomechanical weapon, a child clutching a glowing, salvaged robotic eye, and a medic with glowing implants tending to an injured fighter, their faces illuminated by flickering amber light",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731668827.0,
                    "parent_id": "t1_lx8s6tv",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx8urug/"
                },
                {
                    "id": "lxclvdu",
                    "author": "Tobaka",
                    "body": "2 minutes with turbo lora, 8 steps + 4 steps refine/upscale",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731713625.0,
                    "parent_id": "t1_lxc8sj3",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxclvdu/"
                },
                {
                    "id": "lxa6oyj",
                    "author": "Anonamoose_eh",
                    "body": "That’s because this sub is obsessed with tinkering with models instead of making art or cool pictures.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731686715.0,
                    "parent_id": "t1_lxa0aaq",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxa6oyj/"
                },
                {
                    "id": "lx9j3d7",
                    "author": "Tobaka",
                    "body": "Haha yeah, it's a monster. I use Euler and Simple with a guidance of 1.8. I also have a bunch of loras activated, but not sure how much they do with this model",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731679214.0,
                    "parent_id": "t1_lx9i13f",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lx9j3d7/"
                },
                {
                    "id": "lxcsy22",
                    "author": "Fault23",
                    "body": "That's quite a long time for a good GPU. What is your GPU model?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716231.0,
                    "parent_id": "t1_lxclvdu",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxcsy22/"
                },
                {
                    "id": "lxbr06k",
                    "author": "desktop3060",
                    "body": "I can't tell if you're agreeing that the model looks bad or if you're complimenting the style. Does it make more artistic/cooler pictures compared to other models?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731703600.0,
                    "parent_id": "t1_lxa6oyj",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxbr06k/"
                },
                {
                    "id": "lxct5ko",
                    "author": "Tobaka",
                    "body": "I have a 3080 12GB",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731716309.0,
                    "parent_id": "t1_lxcsy22",
                    "link_id": "t3_1grtdmd",
                    "permalink": "/r/StableDiffusion/comments/1grtdmd/testing_out_shuttle_3_diffusion/lxct5ko/"
                }
            ]
        },
        {
            "id": "1grtard",
            "title": "Clip vision L safetensors, FLUX  Shuttle 3",
            "author": "HeightSensitive1845",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731665946.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/",
            "permalink": "/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/",
            "selftext": "I am trying to get Shuttle 3 working on ForgeUI, i am having trouble finding the \"Clip Vision L safetensors\" on Google/Huggingface. BTW sorry to keep posting questions. I appreciate this community! Thanks",
            "comments": [
                {
                    "id": "lx8qaw6",
                    "author": "ikmalsaid",
                    "body": "Are you looking for this?\n\n[https://huggingface.co/comfyanonymous/flux\\_text\\_encoders/blob/main/clip\\_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731666229.0,
                    "parent_id": "t3_1grtard",
                    "link_id": "t3_1grtard",
                    "permalink": "/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/lx8qaw6/"
                },
                {
                    "id": "lx8rgf0",
                    "author": "HeightSensitive1845",
                    "body": "I think so is it the same as clip \"vision\"? also where i can find the ae.safetensors?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731666932.0,
                    "parent_id": "t1_lx8qaw6",
                    "link_id": "t3_1grtard",
                    "permalink": "/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/lx8rgf0/"
                },
                {
                    "id": "lx8wsu1",
                    "author": "ikmalsaid",
                    "body": "Here you go:\n\nhttps://huggingface.co/black-forest-labs/FLUX.1-schnell/blob/main/ae.safetensors",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731669918.0,
                    "parent_id": "t1_lx8rgf0",
                    "link_id": "t3_1grtard",
                    "permalink": "/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/lx8wsu1/"
                },
                {
                    "id": "lx8rjq0",
                    "author": "HeightSensitive1845",
                    "body": "Thanks for you guidance, all worked!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731666989.0,
                    "parent_id": "t1_lx8rgf0",
                    "link_id": "t3_1grtard",
                    "permalink": "/r/StableDiffusion/comments/1grtard/clip_vision_l_safetensors_flux_shuttle_3/lx8rjq0/"
                }
            ]
        },
        {
            "id": "1grsp91",
            "title": "Marilyn Sings a Christmas Song - another Animatediff plus Liveportrait demo",
            "author": "CQdesign",
            "score": 19,
            "upvotes": 19,
            "downvotes": 0,
            "num_comments": 5,
            "created_utc": 1731663161.0,
            "url": "https://www.youtube.com/watch?v=moL2aMrZpQw",
            "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx8lea1",
                    "author": "CQdesign",
                    "body": "Christmas is coming, I thought it will be fun to do a Xmas related video. The Marilyn Monroe footage was created with Animatediff a few months ago. I feed the footage into Liveportrait to create this video.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731663184.0,
                    "parent_id": "t3_1grsp91",
                    "link_id": "t3_1grsp91",
                    "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/lx8lea1/"
                },
                {
                    "id": "lx9ah7z",
                    "author": "DefiantTemperature41",
                    "body": "The disembodied head is a bit distracting, but a very cool video just the same.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731676044.0,
                    "parent_id": "t3_1grsp91",
                    "link_id": "t3_1grsp91",
                    "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/lx9ah7z/"
                },
                {
                    "id": "lx9tkha",
                    "author": "CQdesign",
                    "body": "Thanks. Disembodied head?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731682715.0,
                    "parent_id": "t1_lx9ah7z",
                    "link_id": "t3_1grsp91",
                    "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/lx9tkha/"
                },
                {
                    "id": "lxa0h2q",
                    "author": "Enshitification",
                    "body": "She's wearing a black turtleneck sweater. Commenter was probably viewing it on a phone screen and couldn't see it.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731684851.0,
                    "parent_id": "t1_lx9tkha",
                    "link_id": "t3_1grsp91",
                    "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/lxa0h2q/"
                },
                {
                    "id": "lxa3de1",
                    "author": "DefiantTemperature41",
                    "body": "Exactly.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731685720.0,
                    "parent_id": "t1_lxa0h2q",
                    "link_id": "t3_1grsp91",
                    "permalink": "/r/StableDiffusion/comments/1grsp91/marilyn_sings_a_christmas_song_another/lxa3de1/"
                }
            ]
        },
        {
            "id": "1grshlt",
            "title": "have there been any updates on regional prompter or other similar extensions?",
            "author": "Zombycow",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731662151.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grshlt/have_there_been_any_updates_on_regional_prompter/",
            "permalink": "/r/StableDiffusion/comments/1grshlt/have_there_been_any_updates_on_regional_prompter/",
            "selftext": "i heard a whole bunch about regional about a year ago, now i never hear anything about it ever again.\n\nis the project dead, or is there still stuff happening? (like, did they ever get \"latent\" working well?)",
            "comments": [
                {
                    "id": "lx8pk88",
                    "author": "mearyu_",
                    "body": "Flux regional prompting was announced on this subreddit not 2 weeks ago my dude [https://www.reddit.com/r/StableDiffusion/comments/1gk2p5n/regional\\_prompting\\_for\\_flux/](https://www.reddit.com/r/StableDiffusion/comments/1gk2p5n/regional_prompting_for_flux/)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731665779.0,
                    "parent_id": "t3_1grshlt",
                    "link_id": "t3_1grshlt",
                    "permalink": "/r/StableDiffusion/comments/1grshlt/have_there_been_any_updates_on_regional_prompter/lx8pk88/"
                },
                {
                    "id": "lx9hluv",
                    "author": "Zombycow",
                    "body": "i wasn't here 2 weeks ago, so i probably missed it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678691.0,
                    "parent_id": "t1_lx8pk88",
                    "link_id": "t3_1grshlt",
                    "permalink": "/r/StableDiffusion/comments/1grshlt/have_there_been_any_updates_on_regional_prompter/lx9hluv/"
                }
            ]
        },
        {
            "id": "1grsdxr",
            "title": "What can I run in an rtx 3060 12gb?",
            "author": "BlueeWaater",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 15,
            "created_utc": 1731661671.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/",
            "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/",
            "selftext": "Give any ideas. ",
            "comments": [
                {
                    "id": "lx8q5k3",
                    "author": "MassiveMeddlers",
                    "body": "You can run pretty much every sdxl models+ some flux models. Btw i have 3060 6gb.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731666139.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8q5k3/"
                },
                {
                    "id": "lx8kzk2",
                    "author": "kortax9889",
                    "body": "Any SDXL, SD3.5 medium, SD3.5 Large fp8, flux fp8 or gguf.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731662924.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8kzk2/"
                },
                {
                    "id": "lx8s8op",
                    "author": "cosmicr",
                    "body": "Pretty much everything. Even cogvideo etc. Just gotta get the right models and configs.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731667398.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8s8op/"
                },
                {
                    "id": "lx8khh5",
                    "author": "Early-Ad-1140",
                    "body": "All SDXL checkpoints will work, so will Flux, but with Flux you should stick to the checkpoints that do not use fp16 precision, since they normally exceed the 12 GB of the RTX 3060 by far. There are excellent Flux finetunes that are in the 12 GB range and require only about 8 steps for pleasant results.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731662609.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8khh5/"
                },
                {
                    "id": "lx8w4hs",
                    "author": "IntelligentAirport26",
                    "body": "Doom and probably Csgo",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731669560.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8w4hs/"
                },
                {
                    "id": "lx8sze7",
                    "author": "Relatively_happy",
                    "body": "Run Forge",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731667821.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8sze7/"
                },
                {
                    "id": "lx8j87d",
                    "author": "Haghiri75",
                    "body": "One year ago I used pretty similar gear for running SDXL turbo (which I believe was a newly released model at the moment).",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731661837.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8j87d/"
                },
                {
                    "id": "lx8l46d",
                    "author": "Plums_Raider",
                    "body": "flux,sd3.5l/m,sdxl,sd1.5,(sd2),llms to around 20b but  i prefer qwen2.5 14b and llama 3.2 11b at the moment, You can train Flux loras and finetunes if you have the time.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731663004.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8l46d/"
                },
                {
                    "id": "lx95ib8",
                    "author": "Ubuntu_20_04_LTS",
                    "body": "Flux and Mochi fp8/Q8 is pretty much the limit",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731674028.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx95ib8/"
                },
                {
                    "id": "lx98p4l",
                    "author": "schlammsuhler",
                    "body": "You can run flux in Q6 and sd3.5L in fp8 and everything else in fp16. Yay",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731675345.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx98p4l/"
                },
                {
                    "id": "lx9ahzi",
                    "author": "ArmadstheDoom",
                    "body": "This is the card I have, and you can basically run everything. Now, training can take a long time. But you won't have too much of a problem running the fp8 flux dev model.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731676052.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx9ahzi/"
                },
                {
                    "id": "lx9jly2",
                    "author": "Kyle_Dornez",
                    "body": "Most of things. I'm using it myself, it can handle WebUI interfaces, InvokeAI, and sometimes the interface, Photoshop and OBS recording at once. It starts lagging a bit with FLUX models, but if you get a lighter version of it - FP8 I think - it would crunch Flux as well. \n\nCan't say about video generation, I've never bothered with it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731679393.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx9jly2/"
                },
                {
                    "id": "lxclyxe",
                    "author": "Far_Insurance4191",
                    "body": "everything, even flux at fp16 with no slowdown if you have 32gb ram",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731713661.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lxclyxe/"
                },
                {
                    "id": "lx8jg47",
                    "author": "Mashic",
                    "body": "Stable Diffusion and Flux.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731661966.0,
                    "parent_id": "t3_1grsdxr",
                    "link_id": "t3_1grsdxr",
                    "permalink": "/r/StableDiffusion/comments/1grsdxr/what_can_i_run_in_an_rtx_3060_12gb/lx8jg47/"
                }
            ]
        },
        {
            "id": "1grs4tl",
            "title": "Is there a way to run the model Genmo AI Mochi 1 without comfy still with the same memory requirement?",
            "author": "Ok_Difference_4483",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731660561.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/",
            "permalink": "/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/",
            "selftext": "Is there a way to run the Genmo AI Mochi 1 model without comfy still with the same memory requirement? Without using the original repo, as it requires a lot of memory? Using the CLI?",
            "comments": [
                {
                    "id": "lxbbvst",
                    "author": "ShengrenR",
                    "body": "I mean.. the comfy nodes are all just python, right? so you'd need to dig them each out and connect them in a script, instead, or at least figure out what's different in the comfy implement and update the similar code in another inference version.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731698945.0,
                    "parent_id": "t3_1grs4tl",
                    "link_id": "t3_1grs4tl",
                    "permalink": "/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/lxbbvst/"
                },
                {
                    "id": "lxbq0qg",
                    "author": "Ok_Difference_4483",
                    "body": "That.. I have thought of, I’m more surprised no one has ever mentioned/encountered this situation? and yes running on windows is just easier for most. But there should be an option to do it through the CLI, no? I mean it should the simplest of its form, even for Comfy too?\n\nI assume the way they are connecting nodes would be the equivalent to passing outputs of such functions in Python, and they seem to have configs file for different parameters of the model used. Not a foreign concept. \n\nThe problem now is I have to implement all of this… I’ll probably ask the Comfy team first if they can just provide some help on this matter.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731703300.0,
                    "parent_id": "t1_lxbbvst",
                    "link_id": "t3_1grs4tl",
                    "permalink": "/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/lxbq0qg/"
                },
                {
                    "id": "lxbrm4p",
                    "author": "ShengrenR",
                    "body": "Quick google pulls up [https://github.com/pydn/ComfyUI-to-Python-Extension](https://github.com/pydn/ComfyUI-to-Python-Extension) \\- not mine and I can't vouch for it being great or awful - but it might be a starting point.\n\n\\*Edit\\*: I honestly might just start with their auto-convert as a first pass and wrap the whole sucker in a function call to make it easy to use",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731703787.0,
                    "parent_id": "t1_lxbq0qg",
                    "link_id": "t3_1grs4tl",
                    "permalink": "/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/lxbrm4p/"
                },
                {
                    "id": "lxcd5sx",
                    "author": "Ok_Difference_4483",
                    "body": "Oh nice! I haven’t seen that during my search! That will be a starting point for sure!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731710565.0,
                    "parent_id": "t1_lxbrm4p",
                    "link_id": "t3_1grs4tl",
                    "permalink": "/r/StableDiffusion/comments/1grs4tl/is_there_a_way_to_run_the_model_genmo_ai_mochi_1/lxcd5sx/"
                }
            ]
        },
        {
            "id": "1grrshh",
            "title": "Looking for a Lora that Can Create Images Like This! ",
            "author": "yachty66",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731658947.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/",
            "permalink": "/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/",
            "selftext": "Hey. I am looking for a Lora that can produce images like the one below. Does anyone know of one like that?\n\nhttps://preview.redd.it/ctock0rwy01e1.jpg?width=400&format=pjpg&auto=webp&s=a442d202066579281ae670612bbea3d03fb87090\n\n",
            "comments": [
                {
                    "id": "lx8g6yg",
                    "author": "weshouldhaveshotguns",
                    "body": "It looks like a dall-e/chatgpt image to me.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731660011.0,
                    "parent_id": "t3_1grrshh",
                    "link_id": "t3_1grrshh",
                    "permalink": "/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/lx8g6yg/"
                },
                {
                    "id": "lx8ez7n",
                    "author": "Designer-Pair5773",
                    "body": "https://preview.redd.it/m1nu9am3011e1.png?width=1024&format=pjpg&auto=webp&s=a1265df9d62904b34d0d6fd2ba63b3cd7ac8abad\n\nThis is a highly detailed CGI (computer-generated imagery) rendering of a futuristic, humanoid cyborg figure. The cyborg is depicted with a metallic, mechanized appearance, predominantly in shades of blue and silver. Its head is encased in a sleek, high-tech helmet, adorned with intricate circuitry and glowing blue lights, giving it an almost otherworldly, futuristic look. The cyborg's eyes are also glowing with a bright, electric blue hue, adding to its intense, almost menacing aura.\n\nThe cyborg's body is muscular and highly detailed, with visible wires, tubes, and circuits running along its skin and beneath its armor-like exterior. These wires and tubes are illuminated with a soft blue light, enhancing the futuristic, high-tech aesthetic. The background is a swirling, ethereal blue and white space with faint stars and electric blue lightning bolts, creating a sense of power and energy surrounding the cyborg.\n\nThe overall style of the image is highly realistic and photorealistic, with a focus on intricate details and textures that make the cyborg's metallic surface appear both sleek and rugged. The image is rich in contrast, with the glowing blue elements standing out against the darker metallic tones.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731659280.0,
                    "parent_id": "t3_1grrshh",
                    "link_id": "t3_1grrshh",
                    "permalink": "/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/lx8ez7n/"
                },
                {
                    "id": "lx8egzw",
                    "author": "yachty66",
                    "body": "(Or prompt)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731658983.0,
                    "parent_id": "t3_1grrshh",
                    "link_id": "t3_1grrshh",
                    "permalink": "/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/lx8egzw/"
                },
                {
                    "id": "lx8fs1g",
                    "author": "yachty66",
                    "body": "Nice! It still looks a little bit too realistic compared to the image I shared, but what model did you use?",
                    "score": -4,
                    "upvotes": -4,
                    "downvotes": 0,
                    "created_utc": 1731659760.0,
                    "parent_id": "t1_lx8ez7n",
                    "link_id": "t3_1grrshh",
                    "permalink": "/r/StableDiffusion/comments/1grrshh/looking_for_a_lora_that_can_create_images_like/lx8fs1g/"
                }
            ]
        },
        {
            "id": "1grqw8m",
            "title": "How would you make something like this short horror video?",
            "author": "SuspiciousPrune4",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731654977.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grqw8m/how_would_you_make_something_like_this_short/",
            "permalink": "/r/StableDiffusion/comments/1grqw8m/how_would_you_make_something_like_this_short/",
            "selftext": "https://www.reddit.com/r/vfx/s/peeOR1QBn1\n\nThis looks like it was made with Kling or something, but it’s pretty good. There are some inconsistencies but the room and everything look normal even after they turn the corner, and the blinds are swaying etc.\n\nDo you think the creator would have used a first and last frame in the prompt? Or do you think it was just a one-image prompt and the AI did the rest?",
            "comments": []
        },
        {
            "id": "1grqvu4",
            "title": "Mark Cuban AI Professional Headshots - Generated on Republiclabs.ai",
            "author": "Biz_problem_solver",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731654921.0,
            "url": "https://www.reddit.com/gallery/1grqvu4",
            "permalink": "/r/StableDiffusion/comments/1grqvu4/mark_cuban_ai_professional_headshots_generated_on/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx87wpj",
                    "author": "Biz_problem_solver",
                    "body": "This is a multi-stage process. Gather Mark Cuban's face image, anything with his face will work.\n\nFirst stage is utilizing Tencent's Photo Maker [https://github.com/datakami-models/PhotoMaker](https://github.com/datakami-models/PhotoMaker) to generate the baseline foundational image. The prompt is 'business headshot photo in a business setting wearing a suit with blurred office background' and 'business headshot photo in a business setting wearing an arabic robe with blurred forest background'\n\nNext stage is to take the outputs and run it through a simple face-swap with the original Mark Cuban image. You can choose your favorite, I simply used [https://replicate.com/xiankgx/face-swap](https://replicate.com/xiankgx/face-swap) \n\nThat should be it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731655223.0,
                    "parent_id": "t3_1grqvu4",
                    "link_id": "t3_1grqvu4",
                    "permalink": "/r/StableDiffusion/comments/1grqvu4/mark_cuban_ai_professional_headshots_generated_on/lx87wpj/"
                }
            ]
        },
        {
            "id": "1grqm8b",
            "title": "Guardian of the Amethyst Flame",
            "author": "angelinshan",
            "score": 8,
            "upvotes": 8,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731653781.0,
            "url": "https://v.redd.it/0bh3v1m0c01e1",
            "permalink": "/r/StableDiffusion/comments/1grqm8b/guardian_of_the_amethyst_flame/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx9968f",
                    "author": "Icy-Ad3030",
                    "body": "How do you do that",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731675531.0,
                    "parent_id": "t3_1grqm8b",
                    "link_id": "t3_1grqm8b",
                    "permalink": "/r/StableDiffusion/comments/1grqm8b/guardian_of_the_amethyst_flame/lx9968f/"
                }
            ]
        },
        {
            "id": "1grq15y",
            "title": " Flux LoRA: Johannes Frederik Engelbert ten Klooster style ",
            "author": "Embarrassed_War_6363",
            "score": 55,
            "upvotes": 55,
            "downvotes": 0,
            "num_comments": 4,
            "created_utc": 1731651337.0,
            "url": "https://www.reddit.com/gallery/1grq15y",
            "permalink": "/r/StableDiffusion/comments/1grq15y/flux_lora_johannes_frederik_engelbert_ten/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx80nis",
                    "author": "Embarrassed_War_6363",
                    "body": "[Johannes Frederik Engelbert ten Klooster style Flux LoRA](https://civitai.com/models/949095/johannes-frederik-engelbert-ten-klooster-style)\n\nThis model was made after I saw [https://civitai.com/models/943256/johannes-frederik-engelbert-ten-klooster-style](https://civitai.com/models/943256/johannes-frederik-engelbert-ten-klooster-style), which looks great but is quite large so I cannot use it. So I decided to train one myself, and this is the result.\n\nIt is not as good as the other one, but it has its own distinct style, and is smaller.\n\nMost of the gallery prompt are stolen from the other Klooster model so that one can compare the output from the two models 😅🙏\n\nMore information about the artist: [https://nl.wikipedia.org/wiki/Johan\\_ten\\_Klooster](https://nl.wikipedia.org/wiki/Johan_ten_Klooster)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731651371.0,
                    "parent_id": "t3_1grq15y",
                    "link_id": "t3_1grq15y",
                    "permalink": "/r/StableDiffusion/comments/1grq15y/flux_lora_johannes_frederik_engelbert_ten/lx80nis/"
                },
                {
                    "id": "lxap4nh",
                    "author": "Winter_unmuted",
                    "body": "Would you mind sharing your training settings?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731692175.0,
                    "parent_id": "t3_1grq15y",
                    "link_id": "t3_1grq15y",
                    "permalink": "/r/StableDiffusion/comments/1grq15y/flux_lora_johannes_frederik_engelbert_ten/lxap4nh/"
                },
                {
                    "id": "lxebbob",
                    "author": "Embarrassed_War_6363",
                    "body": "These are the settings I used for training:\n\nFor the one with border (13 public domain images): [https://civitai.com/images/40389929](https://civitai.com/images/40389929)\n\nFLUX.1 - dev-fp8\n\nTrigger: k1ooster\n\nRepeat: 15 Epoch: 10 total Steps = (\\* 15 10 13)=1950\n\nUnet LR: 0.0005 Scheduler: cosine Optimizer: AdamW\n\nNetwork Dim: 8 Alpha: 4\n\nWithout border (11 public domain images): [https://civitai.com/images/40389951](https://civitai.com/images/40389951)\n\nFLUX.1 - dev-fp8\n\nTrigger: k1ooster\n\nRepeat: 20 Epoch: 10 Total steps: (\\* 20 10 11)=2200\n\nUnet LR: 0.0005\n\nLR Scheduler: cosine Optimizer: AdamW\n\nNetwork Dim: 8 Alpha: 4",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731739359.0,
                    "parent_id": "t3_1grq15y",
                    "link_id": "t3_1grq15y",
                    "permalink": "/r/StableDiffusion/comments/1grq15y/flux_lora_johannes_frederik_engelbert_ten/lxebbob/"
                },
                {
                    "id": "lxb7a3v",
                    "author": "Embarrassed_War_6363",
                    "body": "These are the settings I used for training:\n\nFor the one with border (13 public domain images): [https://civitai.com/images/40389929](https://civitai.com/images/40389929)\n\nFLUX.1 - dev-fp8\n\nTrigger: k1ooster\n\nRepeat: 15 Epoch: 10 total Steps = (\\* 15 10 13)=1950\n\nUnet LR: 0.0005 Scheduler: cosine Optimizer: AdamW\n\nNetwork Dim: 8 Alpha: 4\n\nWithout border (11 public domain images): [https://civitai.com/images/40389951](https://civitai.com/images/40389951)\n\nFLUX.1 - dev-fp8\n\nTrigger: k1ooster\n\nRepeat: 20 Epoch: 10 Total steps: (\\* 20 10 11)=2200\n\nUnet LR: 0.0005\n\nLR Scheduler: cosine Optimizer: AdamW\n\nNetwork Dim: 8 Alpha: 4",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731697563.0,
                    "parent_id": "t1_lxap4nh",
                    "link_id": "t3_1grq15y",
                    "permalink": "/r/StableDiffusion/comments/1grq15y/flux_lora_johannes_frederik_engelbert_ten/lxb7a3v/"
                }
            ]
        },
        {
            "id": "1grptlq",
            "title": "mochi inference on 4090 with comfyui",
            "author": "https-gpu-ai",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731650549.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grptlq/mochi_inference_on_4090_with_comfyui/",
            "permalink": "/r/StableDiffusion/comments/1grptlq/mochi_inference_on_4090_with_comfyui/",
            "selftext": "it look good for me\n\n[https://github.com/kijai/ComfyUI-MochiWrapper](https://github.com/kijai/ComfyUI-MochiWrapper)\n\nhttps://reddit.com/link/1grptlq/video/swk1a6b3a01e1/player\n\n",
            "comments": []
        },
        {
            "id": "1grppkm",
            "title": "Game assets",
            "author": "Responsible_Ad1062",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 5,
            "created_utc": 1731650127.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grppkm/game_assets/",
            "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/",
            "selftext": "I'm trying to make mobile game assets and faced with such a problem - objects have different drawing styles and different lighting. What can I do about it?",
            "comments": [
                {
                    "id": "lx7z6oy",
                    "author": "weshouldhaveshotguns",
                    "body": "Its a broad question. What model are you using? you may want to use a lora or IPA to keep styles consistent.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731650634.0,
                    "parent_id": "t3_1grppkm",
                    "link_id": "t3_1grppkm",
                    "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/lx7z6oy/"
                },
                {
                    "id": "lx9dsno",
                    "author": "shapic",
                    "body": "Lora, stylealign, ipadapter, maybe even all combined.\nIn case of flux you can try to create multiple icons in one generation. Like 9x9 grid in prompt etc",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731677306.0,
                    "parent_id": "t3_1grppkm",
                    "link_id": "t3_1grppkm",
                    "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/lx9dsno/"
                },
                {
                    "id": "lxag3uv",
                    "author": "Monsieur-Velstadt",
                    "body": "The solution I found was the combo Photoshop (or any similar tool) + inpainting with a LoRA. It takes time.\nI created my LoRA gradually, and now I have more and more images with the style I wanted, so my LoRA keeps improving.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731689502.0,
                    "parent_id": "t3_1grppkm",
                    "link_id": "t3_1grppkm",
                    "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/lxag3uv/"
                },
                {
                    "id": "lx80bcq",
                    "author": "Responsible_Ad1062",
                    "body": "I understand that my question is too general, but I have already tried a lot of things. I usually work with XL models and FLUX, so far the best thing I've come to is using ControlNet - it gives me the opportunity to set the composition of the item, but I still face a constant change of style, despite the stylistically defined prompt. The same problem with lighting - as far as I understand, it is quite problematic to set it via prompt. The style I chose is similar to the illustration, but more like hand-drawn (since I use sketches in ControlNet). I didn't find a suitable lora (maybe I didn't do enough research) and I'm still suffering with the IPA, because it gives a terrible result and I don't understand what I'm doing wrong with it (I set it up according to Mateo's video \"[IPAdapter v2: all the new features!](https://www.youtube.com/watch?v=_JzDcgKgghY&t=812s)\")",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731651198.0,
                    "parent_id": "t1_lx7z6oy",
                    "link_id": "t3_1grppkm",
                    "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/lx80bcq/"
                },
                {
                    "id": "lx86tgv",
                    "author": "Pretend_Potential",
                    "body": "game assets are normally lit by the game engine during play. you don't want to create items that are shaded as if light was falling on them from somewhere.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731654625.0,
                    "parent_id": "t1_lx80bcq",
                    "link_id": "t3_1grppkm",
                    "permalink": "/r/StableDiffusion/comments/1grppkm/game_assets/lx86tgv/"
                }
            ]
        },
        {
            "id": "1grpbnp",
            "title": "Anyone suggestion with Flux LORA Training Params for Realistic Faces / headshot generation?",
            "author": "Equivalent_Name7608",
            "score": 3,
            "upvotes": 3,
            "downvotes": 0,
            "num_comments": 18,
            "created_utc": 1731648647.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/",
            "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/",
            "selftext": "I have tried below params already but result has somewhat similarity of face but it doesnt look close to realistic face, any suggestion what i can do will be great help for me , Thanks in adavanced.\n\n**rank - 16,32**\n\n**lr - 0.001,0.002**\n\n**steps - 1500**\n\n",
            "comments": [
                {
                    "id": "lx8c1if",
                    "author": "ArtificialMediocrity",
                    "body": "I'm getting good results with these settings:\n\nRank: 16,16  \nBatch size: 1  \nLearning Rate: 1  \nOptimizer:  Prodigy  \nScheduler: Cosine  \nEMA: on\n\nSteps:  depends on the size of the dataset.  If it's only a few pictures, 1500-2000 is about right.  For a larger set with 50-100 images, I would go up to 3000.  For a really huge dataset, you can take it even higher because there's less risk of overtraining.  For example I recently did one with 2000 images and trained for 6000 steps with the above settings.  It's on CivitAI if you want to check out the result (Karl Pilkington).",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731657551.0,
                    "parent_id": "t3_1grpbnp",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8c1if/"
                },
                {
                    "id": "lx9tmxr",
                    "author": "faffingunderthetree",
                    "body": "I've been doing a few people loras, some come out brilliant and some quite meh. I've tried lots of different settings, I usually do batch size 4 though, is 1 better? \n\nAnd I've heard u can do 512res to save time and resources but the 1024res loras I done turned out better I feel.\n\nMy main issue with a good facial lora is the dataset, should I just crop face images, or do I do full body or cowboy pose images? Or should they be mixed and some face pics, and some full body etc..  \nI never know.\n\nFlux does seem to not need that many images thankfully, 30 to 40 seems to be the sweet spot, any lora I've done where I dont have that many high res pics has not been great. I'm not sure what to do when say I've like 20 low res images only as a dataset, seems doomed :(",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731682736.0,
                    "parent_id": "t3_1grpbnp",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx9tmxr/"
                },
                {
                    "id": "lxbzxc3",
                    "author": "artificial_genius",
                    "body": "Raise the rank to at least 64/64 better to do 128/128, add another decimal to the learning rate (reduce it) like 0.0005 and increase steps to around 4000.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731706318.0,
                    "parent_id": "t3_1grpbnp",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxbzxc3/"
                },
                {
                    "id": "lx8fth7",
                    "author": "Equivalent_Name7608",
                    "body": "thanks for the reply, mostly i would be having 10-15 images for training",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731659783.0,
                    "parent_id": "t1_lx8c1if",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8fth7/"
                },
                {
                    "id": "lx8fv5g",
                    "author": "Equivalent_Name7608",
                    "body": "will definetly try with your parameters!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731659812.0,
                    "parent_id": "t1_lx8c1if",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8fv5g/"
                },
                {
                    "id": "lx8ie6y",
                    "author": "Equivalent_Name7608",
                    "body": "Cosine scheduler you said , i have to change here?\n\n noise\\_scheduler: \"flowmatch\" ?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731661335.0,
                    "parent_id": "t1_lx8c1if",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8ie6y/"
                },
                {
                    "id": "lx8q5mr",
                    "author": "Ok-Umpire3364",
                    "body": "Do you have any configs for fine tuning?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731666140.0,
                    "parent_id": "t1_lx8c1if",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8q5mr/"
                },
                {
                    "id": "lxbq44c",
                    "author": "Apprehensive_Sky892",
                    "body": "Mixture of faces and full body and portrait works the best.\n\nI found that if the majority of images are faces then LoRA will tend to produce headshots that take up most of the space, and you then have to \"fight it\" via prompting.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731703328.0,
                    "parent_id": "t1_lx9tmxr",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxbq44c/"
                },
                {
                    "id": "lxdvuv8",
                    "author": "Equivalent_Name7608",
                    "body": "thanks , sure will try it  \ni have like limited 10-15 img dataset, !!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731596.0,
                    "parent_id": "t1_lxbzxc3",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxdvuv8/"
                },
                {
                    "id": "lx8pixt",
                    "author": "ArtificialMediocrity",
                    "body": "Sorry, I should have been more specific. I meant \"Learning Rate Scheduler = Cosine\".\n\nThe noise scheduler is the sampler.  No need to change that.\n\nIn my experience, the Prodigy optimizer and Cosine scheduler work all sorts of magic together.  Prodigy adjusts the learning rate to what it thinks is optimal, and Cosine keeps pushing it down to get it more refined by the end.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731665755.0,
                    "parent_id": "t1_lx8ie6y",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx8pixt/"
                },
                {
                    "id": "lx953vs",
                    "author": "Equivalent_Name7608",
                    "body": "nope!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731673857.0,
                    "parent_id": "t1_lx8q5mr",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx953vs/"
                },
                {
                    "id": "lx951ct",
                    "author": "Equivalent_Name7608",
                    "body": "optimizer: prodigy , lr\\_scheduler: cosine, lr - 0.001,  steps - 2000  \nI used this parameters , and the result for me was worst , face was also not matching properly, for both 16 and 32 rank ,  \nlet me know if i am doing anything wrong here please.\n\nInstead simple config with lr - 0.002 , steps - 1500 , rank - 16/32 works betteer than above params for me",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731673827.0,
                    "parent_id": "t1_lx8pixt",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx951ct/"
                },
                {
                    "id": "lx9f90n",
                    "author": "ArtificialMediocrity",
                    "body": "With Prodigy, the learning rate should be 1 (integer one, 1.0, this is not a typo).   It has its own method of adjusting the learning rate.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731677837.0,
                    "parent_id": "t1_lx951ct",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lx9f90n/"
                },
                {
                    "id": "lxdvjwl",
                    "author": "Equivalent_Name7608",
                    "body": "Thanks  for clarification, ! will definetly try this!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731465.0,
                    "parent_id": "t1_lx9f90n",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxdvjwl/"
                },
                {
                    "id": "lxdvzwd",
                    "author": "Equivalent_Name7608",
                    "body": "apology for misunderstanding about the lr",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731731656.0,
                    "parent_id": "t1_lx9f90n",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxdvzwd/"
                },
                {
                    "id": "lxdzpzv",
                    "author": "Equivalent_Name7608",
                    "body": "Also can you suggest is caption is neccassary in dataset?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733354.0,
                    "parent_id": "t1_lx9f90n",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxdzpzv/"
                },
                {
                    "id": "lxe9nva",
                    "author": "ArtificialMediocrity",
                    "body": "I don't use captions at all for Flux characters.  As long as the images are clear, it picks up the main subject.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731738435.0,
                    "parent_id": "t1_lxdzpzv",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxe9nva/"
                },
                {
                    "id": "lxec2hy",
                    "author": "Equivalent_Name7608",
                    "body": "Thank you",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731739779.0,
                    "parent_id": "t1_lxe9nva",
                    "link_id": "t3_1grpbnp",
                    "permalink": "/r/StableDiffusion/comments/1grpbnp/anyone_suggestion_with_flux_lora_training_params/lxec2hy/"
                }
            ]
        },
        {
            "id": "1grp66i",
            "title": "PC Seems to Crash/Stutter at The End of Generations Now",
            "author": "Lagahol",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731648066.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/",
            "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/",
            "selftext": "This may be a general PC issue but I am specifically noticing it only when running SD (Pony XL) on A1111 in the last few days. Every time I get to the end of image generation, even on simple prompts, my GPU usage falls to zero and my entire system seems slow to a near freeze. The Command Prompt will tell me generation is 100% complete, the webui will show something around 97-98%. This is on a \\~4 year old system with a 1070 which was working great with this exact SD setup up until a few days ago. No Windows updates/new components/changes to my A111 setup.\n\n* I've got the standard --xformers --medvram --sdxl optimizations.\n* I've tested my system RAM and all of my HDDs and SSD with the default Windows tools.\n* I've attempted a few generations with MSI Afterburner open to make sure it's not a GPU cooling problem, it seems to get up to about 76 F and the fans are working fine.\n* I've since updated my NVIDIA drivers to the latest workstation drivers, didn't fix the problem.\n* I have noticed that my system RAM demand and read/write on a HDD that doesn't have anything for A111 on it seem to spike to 100% when the GPU falls off. The GPU also seems to sporadically spike while my system is stuttering along.\n* I have attempted underclocking my GPU and even using improper sizes for Pony (512x512) and I was able to get an image out without stuttering. When I raised the size back up to 1024x1024 with a one word prompt it still did seize up, but only for a minute or two instead of forcing me to restart my desktop.",
            "comments": [
                {
                    "id": "lx8092d",
                    "author": "acbonymous",
                    "body": "You probably don't have enough vram to apply the vae and defaults to system ram, which you may also get full and causes your pc to freeze.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731651165.0,
                    "parent_id": "t3_1grp66i",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx8092d/"
                },
                {
                    "id": "lx8a2y3",
                    "author": "orangpelupa",
                    "body": "Sounds like vram deficit.\n\n\nOH and try updating to the latest studio driver. It fixed my vram deficiency in fooocus when generating sdxl with some models. ",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731656438.0,
                    "parent_id": "t3_1grp66i",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx8a2y3/"
                },
                {
                    "id": "lxaf9uw",
                    "author": "bridge1999",
                    "body": "Are you using the video card to display the gui for the OS?  If so the OS will hold 4GB of VRAM for the OS.  If your CPU has a GPU built in switch over to the onboard video outputs and this issue goes away.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731689257.0,
                    "parent_id": "t3_1grp66i",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lxaf9uw/"
                },
                {
                    "id": "lx8d952",
                    "author": "TheGhostOfPrufrock",
                    "body": "That would be my guess, also.  You can determine if that's the cause by monitoring GPU memory use in the Task Manager. If it is the problem, you may be able to fix it by disabling the System Memory Fallback -- provided it doesn't then result in OOM errors. Also, as orangpelupa suggests, you might make sure you've got the latest driver.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731658256.0,
                    "parent_id": "t1_lx8092d",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx8d952/"
                },
                {
                    "id": "lxatq21",
                    "author": "Lagahol",
                    "body": "Hmm, yes I am using the video card for display. My CPU is a Ryzen so I have to use the GPU for the OS.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731693544.0,
                    "parent_id": "t1_lxaf9uw",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lxatq21/"
                },
                {
                    "id": "lx9djy4",
                    "author": "Lagahol",
                    "body": "I've updated to the latest studio drivers and was still experiencing the same problems. Rolled back to the second to latest version and it seems to be better than before but still not solved. What I don't understand is why it's suddenly so much worse? I'm trying to generate the same images it would whip out in 1.5 mins without issue and now it's stuttering seemingly without anything changing. Also at the times when it's using all my system ram the GPU only sporadically kicks in, it's usually down to 0 load.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731677217.0,
                    "parent_id": "t1_lx8d952",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx9djy4/"
                },
                {
                    "id": "lx9larj",
                    "author": "Lagahol",
                    "body": "I did disable System Memory Fallback through the NVIDA panel and GPU acceleration for Windows. It allowed me to generate a more complicated image I had made before without crashing. It did still stutter at the end, but only for a minute this time. It did still use a most of my system RAM on top of 7 GB of VRAM? I did not get any OOM errors.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731679983.0,
                    "parent_id": "t1_lx8d952",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx9larj/"
                },
                {
                    "id": "lxb959d",
                    "author": "bridge1999",
                    "body": "Plug your monitor into the video port on the motherboard and Windows will no longer allocate vram on your video card.  I had this same issue and changed my monitor to use the video output on the motherboard and the issue disappeared.  My whole gui would be locked up at the end of a render when I was using the video card for my monitors.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698122.0,
                    "parent_id": "t1_lxatq21",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lxb959d/"
                },
                {
                    "id": "lx9hx1o",
                    "author": "Lagahol",
                    "body": "https://preview.redd.it/ehtk4cjsl21e1.png?width=1211&format=png&auto=webp&s=38253479c27ac60ef24e2a6998dbb8f9690150b4\n\nThis is what my system looked like during the crash. Couldn't screenshot as it happened cause the system was barely responsive. VRAM peaked at like 7 GB prior to the crash, and then the CUDA usage fell off a cliff. Right before this, Chrome crashed and I was able to end task and not restart my desktop. My A111 instillation is on my E:// drive and Windows is on the C://",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678800.0,
                    "parent_id": "t1_lx9djy4",
                    "link_id": "t3_1grp66i",
                    "permalink": "/r/StableDiffusion/comments/1grp66i/pc_seems_to_crashstutter_at_the_end_of/lx9hx1o/"
                }
            ]
        },
        {
            "id": "1grox3n",
            "title": "Face Model?",
            "author": "NotReallyMe47",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731647163.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grox3n/face_model/",
            "permalink": "/r/StableDiffusion/comments/1grox3n/face_model/",
            "selftext": "I'm looking for different tools for face models like ReActor but have no idea where to look. Are there any that you all would recommend? I use SDXL and Pony mostly but willing to experiment with other models",
            "comments": [
                {
                    "id": "lx7tfex",
                    "author": "Pretend_Potential",
                    "body": "ReActor is the current open source solution just about everyone is using",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731647899.0,
                    "parent_id": "t3_1grox3n",
                    "link_id": "t3_1grox3n",
                    "permalink": "/r/StableDiffusion/comments/1grox3n/face_model/lx7tfex/"
                },
                {
                    "id": "lx8spne",
                    "author": "Dry-Resist-4426",
                    "body": "Instant ID, ip adapter faceid plus. These are controlnet models. Instant ID is the best to my opinion, outperforms reactor in quality but it is much slower. If you want to work with one or two specific characters it is also recommended to train a Lora for it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731667666.0,
                    "parent_id": "t3_1grox3n",
                    "link_id": "t3_1grox3n",
                    "permalink": "/r/StableDiffusion/comments/1grox3n/face_model/lx8spne/"
                }
            ]
        },
        {
            "id": "1gro819",
            "title": "Can anybody help me , i want to download the stable diffusion but I am noob ",
            "author": "ballfond",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 28,
            "created_utc": 1731644724.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/",
            "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/",
            "selftext": "https://youtu.be/6MeJKnbv1ts?si=CIkpv3771XvtppSL I saw this video but you am getting torch 2.1.2 \n\nI will be really greatful",
            "comments": [
                {
                    "id": "lx7sz2g",
                    "author": "Superb-Ad-4661",
                    "body": "man, first you must install python 3.10, put it in your environment variables PATH, if you dont know this you'll need to learn anyway, install git for windows, create a empty folder for your stable diffusion copy, git bash or run cmd and git clone [https://github.com/lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge), after that in cmd you'll need setup a venv, still in cmd, python -m venv venv. it will create a folder venv, navigate till scripts folder and type activate, now your cmd will be in a virtual environment, still in cmd, return to your root folder where is the file requirements.txt, and type: pip install -r requirements.txt, wait till the process finishes, so assuming you have a nvidia card, you will need uninstall torch if it dont come with cuda, still in cmd in the virtual environment (called using activate in scripts) pip uninstall torch torchaudio torchvision. and go to the site [pytorch.org](http://pytorch.org) and copy the link more suitable for your instalation of Forge. so in the cmd with the venv activated pip install (torch+cuda0, the link will be something like this: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124.\n\nyou'll problaby will make some mistakes in the process, but it's all pay attention in the steps, or you 'll be days trying and pulling the hair out of your head, but it's the way, because early or later, the system will crash and you will need to make all again. there are maybe some one click installers, but it's better not rely on them, maybe in forge github page can be one.\n\nthis cover the basics, maybe I forgot something. good luck.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731647697.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7sz2g/"
                },
                {
                    "id": "lx7rgql",
                    "author": "Hearcharted",
                    "body": "Step 1: Google \"Fooocus\"\nStep 2: Profit 😎",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731647029.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7rgql/"
                },
                {
                    "id": "lx7ogm2",
                    "author": "Pretend_Potential",
                    "body": "just go get base SDXL from civitAI",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731645755.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7ogm2/"
                },
                {
                    "id": "lx7r2lx",
                    "author": "Won3wan32",
                    "body": "don't bother bro , play [https://getimg.ai/models/flux](https://getimg.ai/models/flux) until you get bored \n\nyou don't seem to be able to follow a simple tutorial",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731646859.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7r2lx/"
                },
                {
                    "id": "lx84mx5",
                    "author": "arentol",
                    "body": "Please don't follow that 2-year-old video on a dying system (Automatic111). You are working way too hard doing it that way. Setting up newer and better systems for using SD is trivially easy these days.\n\nIf you want the same basic interface as in that video, but a newer and more supported tool, install Forge following this video from 2 months, instead of 2 years, ago. You may need to change some things if you want to use a model other than Flux, but most other ones will work with Forge just fine:\n\n[https://www.youtube.com/watch?v=BFSDsMz\\_uE0](https://www.youtube.com/watch?v=BFSDsMz_uE0)\n\nAlso, once you have Forge installed using that video, you can follow this series that is older to learn more about using it, and working with older models:\n\n[https://www.youtube.com/watch?v=zqgKj9yexMY&list=PL-pohOSaL8P\\_VxpGxcay1EJFtqX4m8WqZ](https://www.youtube.com/watch?v=zqgKj9yexMY&list=PL-pohOSaL8P_VxpGxcay1EJFtqX4m8WqZ)\n\nAnd if you want a more versatile software, follow the same persons entire video series on Comfyui, starting here:\n\n[https://www.youtube.com/watch?v=Zko\\_s2LO9Wo&list=PL-pohOSaL8P9kLZP8tQ1K1QWdZEgwiBM0](https://www.youtube.com/watch?v=Zko_s2LO9Wo&list=PL-pohOSaL8P9kLZP8tQ1K1QWdZEgwiBM0)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731653446.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx84mx5/"
                },
                {
                    "id": "lx8fbgg",
                    "author": "Herr_Drosselmeyer",
                    "body": "That video is two years old and mostly outdated.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731659482.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx8fbgg/"
                },
                {
                    "id": "lx98y15",
                    "author": "No-Sleep-4069",
                    "body": "For a noob and keeping things simple. Just get fooocus UI, that video you are referring is 2 years old  \nTry this simple fooocus installation: [https://youtu.be/3tAaL57rhoU?si=YazVeGzuZedSuVC6](https://youtu.be/3tAaL57rhoU?si=YazVeGzuZedSuVC6)\n\nThis playlist is for beginners: [https://youtube.com/playlist?list=PLPFN04WspxqsslRSpiLmwGR8QTpDYNv7z&si=KY5FARfX5GSTS4aV](https://youtube.com/playlist?list=PLPFN04WspxqsslRSpiLmwGR8QTpDYNv7z&si=KY5FARfX5GSTS4aV)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731675442.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx98y15/"
                },
                {
                    "id": "lx7msmw",
                    "author": "emprezario",
                    "body": "Try with Ollama instead. https://youtu.be/4FzNqZsB_7Q",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731645077.0,
                    "parent_id": "t3_1gro819",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7msmw/"
                },
                {
                    "id": "lx7t285",
                    "author": "ballfond",
                    "body": "Thanks man",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731647733.0,
                    "parent_id": "t1_lx7sz2g",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7t285/"
                },
                {
                    "id": "lx7t3zw",
                    "author": "Superb-Ad-4661",
                    "body": "the models you download in the [civitai.com](http://civitai.com) and put them in their respective folders",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731647756.0,
                    "parent_id": "t1_lx7sz2g",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7t3zw/"
                },
                {
                    "id": "lx7ov1s",
                    "author": "ballfond",
                    "body": "Maybe I'm using python 3.16 can that be the problem?\n\nOr is the sdxl from civil ai latest version \n\nJust explain what you want bro I'm new to this so any knowledge will be appreciated",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731645921.0,
                    "parent_id": "t1_lx7ogm2",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7ov1s/"
                },
                {
                    "id": "lx7r7wh",
                    "author": "ballfond",
                    "body": "Please bro maybe I have downloaded python 3.16 and that is the problem",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731646923.0,
                    "parent_id": "t1_lx7r2lx",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7r7wh/"
                },
                {
                    "id": "lx8fp4n",
                    "author": "ballfond",
                    "body": "Thanks bro you are a god",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731659710.0,
                    "parent_id": "t1_lx84mx5",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx8fp4n/"
                },
                {
                    "id": "lx9b8qs",
                    "author": "ballfond",
                    "body": "Thanks bro",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731676338.0,
                    "parent_id": "t1_lx98y15",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx9b8qs/"
                },
                {
                    "id": "lx7nucp",
                    "author": "ballfond",
                    "body": "Hey bro i also want to know if I should download stable diffusion 1.4 or some latest version but the hugging face demands a lot of things like organization name etc.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731645501.0,
                    "parent_id": "t1_lx7msmw",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7nucp/"
                },
                {
                    "id": "lx7nz65",
                    "author": "ballfond",
                    "body": "Or i have python 3.16 for latest version if that is causing any problem as I think latest is the best usually but that may not be the case",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731645555.0,
                    "parent_id": "t1_lx7msmw",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7nz65/"
                },
                {
                    "id": "lx7xcm6",
                    "author": "Superb-Ad-4661",
                    "body": "you're welcome, use python 3.10.11 not other or will break lot of stuffs and will not run most of the cool stuff, keep up with the Forge.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731649735.0,
                    "parent_id": "t1_lx7t285",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7xcm6/"
                },
                {
                    "id": "lx7tar6",
                    "author": "Pretend_Potential",
                    "body": "yeah, 3.16 is too high for just about everything. if you will get, and install SwarmUI - it'll take care of all the technical stuff for you. The developer is one of the mods here if you get stuck, and he also has a discord if you want",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731647841.0,
                    "parent_id": "t1_lx7ov1s",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7tar6/"
                },
                {
                    "id": "lx7t431",
                    "author": "Won3wan32",
                    "body": "haha, then you must be a time-traveling agent because the latest version is 3.14 \n\n[https://www.python.org/downloads/](https://www.python.org/downloads/)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731647757.0,
                    "parent_id": "t1_lx7r7wh",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7t431/"
                },
                {
                    "id": "lx9wsl5",
                    "author": "arentol",
                    "body": "The real credit goes to [pixaroma](https://www.youtube.com/@pixaroma). He is the god. I am more like an itinerant rabbi of his, traveling the internet spreading his word. \n\nThat said, his videos will be outdated in a few more months and I will need to find someone new to share about, unless he does updates.... Always do that. Information goes stale super fast in an area like this which is new and subject to rapid change. If you are going to help others you need to keep up so they don't have to go through the pain you went through just because you never bothered to learn the newer methods.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731683725.0,
                    "parent_id": "t1_lx8fp4n",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx9wsl5/"
                },
                {
                    "id": "lx7pdyq",
                    "author": "emprezario",
                    "body": "Use local.ai and pull the image directly from huggingface.",
                    "score": -1,
                    "upvotes": -1,
                    "downvotes": 0,
                    "created_utc": 1731646140.0,
                    "parent_id": "t1_lx7nucp",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7pdyq/"
                },
                {
                    "id": "lx7zj7o",
                    "author": "ballfond",
                    "body": "You are great man I'm not knowledgeable about coding so i had this problem you are the man bro",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731650805.0,
                    "parent_id": "t1_lx7xcm6",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7zj7o/"
                },
                {
                    "id": "lx7tef6",
                    "author": "ballfond",
                    "body": "Can you give me the discord bro",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731647887.0,
                    "parent_id": "t1_lx7tar6",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7tef6/"
                },
                {
                    "id": "lx7t6kl",
                    "author": "ballfond",
                    "body": "Sorry bro i am quite dumb",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731647788.0,
                    "parent_id": "t1_lx7t431",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7t6kl/"
                },
                {
                    "id": "lx7pyu6",
                    "author": "ballfond",
                    "body": "Where to pull",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731646386.0,
                    "parent_id": "t1_lx7pdyq",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7pyu6/"
                },
                {
                    "id": "lx7pvia",
                    "author": "ballfond",
                    "body": "Where to pull",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731646347.0,
                    "parent_id": "t1_lx7pdyq",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx7pvia/"
                },
                {
                    "id": "lx82wrd",
                    "author": "Pretend_Potential",
                    "body": "**The swarm discord invite link is:** [https://discord.gg/q2y38cqjNw](https://discord.gg/q2y38cqjNw)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731652542.0,
                    "parent_id": "t1_lx7tef6",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx82wrd/"
                },
                {
                    "id": "lx8493w",
                    "author": "ballfond",
                    "body": "Thanks man i appreciate it",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731653244.0,
                    "parent_id": "t1_lx82wrd",
                    "link_id": "t3_1gro819",
                    "permalink": "/r/StableDiffusion/comments/1gro819/can_anybody_help_me_i_want_to_download_the_stable/lx8493w/"
                }
            ]
        },
        {
            "id": "1grntn5",
            "title": "Forge flux controlnet update?",
            "author": "blank0007",
            "score": 4,
            "upvotes": 4,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731643378.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grntn5/forge_flux_controlnet_update/",
            "permalink": "/r/StableDiffusion/comments/1grntn5/forge_flux_controlnet_update/",
            "selftext": "Is it implemented yet or even coming at all",
            "comments": [
                {
                    "id": "lx7sz3p",
                    "author": "BillyGrier",
                    "body": "Yes, lllyasviel (dev) has it scheduled in the readme somewhere (it's in one of the discussions on the repo forum itself). Think it got moved back to Nov 20. He prob has lots of IRL studies or work going on. Hopefully coming up though as listed.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731647697.0,
                    "parent_id": "t3_1grntn5",
                    "link_id": "t3_1grntn5",
                    "permalink": "/r/StableDiffusion/comments/1grntn5/forge_flux_controlnet_update/lx7sz3p/"
                }
            ]
        },
        {
            "id": "1grmwut",
            "title": "How to make a video like in the Civitai top?",
            "author": "AdAgitated6993",
            "score": 6,
            "upvotes": 6,
            "downvotes": 0,
            "num_comments": 13,
            "created_utc": 1731640322.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/",
            "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/",
            "selftext": "I mean what techniques/tools are used for this? Almost 2 years ago I abandoned stable diffusion, and at that time Animatediff and Deforum were gaining popularity. What are the most popular tools at the moment for generating high-quality videos with a minimum of flickering?",
            "comments": [
                {
                    "id": "lx7so6p",
                    "author": "SuspiciousPrune4",
                    "body": "The best quality is Hailuo/Minimax, followed by Runway. Kling seemed great from the demos but every time I’ve tried it each video takes several days to generate, and then it’ll either say it failed, or the resulting video loses a ton of quality from the source image.\n\nThere are a few local ones but they’re not anywhere even close to the quality of Hailuo or Runway.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731647560.0,
                    "parent_id": "t3_1grmwut",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7so6p/"
                },
                {
                    "id": "lx8rdiv",
                    "author": "Occsan",
                    "body": "animatediff arguably offers the most flexibility.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731666882.0,
                    "parent_id": "t3_1grmwut",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx8rdiv/"
                },
                {
                    "id": "lx7aqoe",
                    "author": "Netsuko",
                    "body": "Kling, LUMA, Runway just do name a few. There’s so many to chose from. They all pretty much do the same especially with people/anime portraits.  Pretty much none of the animated images on Civitai were made locally.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731640678.0,
                    "parent_id": "t3_1grmwut",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7aqoe/"
                },
                {
                    "id": "lx7ur6t",
                    "author": "AdAgitated6993",
                    "body": "What passable quality options do you think there are for use locally? I need very fine tuning of the generation process, such as in auto1111 and comfyui",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731648509.0,
                    "parent_id": "t1_lx7so6p",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7ur6t/"
                },
                {
                    "id": "lx8f4m0",
                    "author": "idleWizard",
                    "body": "Glad someone said it. I got SO disappointment with Kling. Maybe it's my fault for being so hyped with demos, but my results were comically bad and it took forever to generate if it generated at all.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731659369.0,
                    "parent_id": "t1_lx7so6p",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx8f4m0/"
                },
                {
                    "id": "lxa1tg9",
                    "author": "vs3a",
                    "body": "that because Kling want you to pay",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731685252.0,
                    "parent_id": "t1_lx7so6p",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lxa1tg9/"
                },
                {
                    "id": "lx946oc",
                    "author": "msbeaute00000001",
                    "body": "can you point me to some resource that use animatediff that could be stable, no flickery? It seems to me that it is hard to control it to have stable outputs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731673459.0,
                    "parent_id": "t1_lx8rdiv",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx946oc/"
                },
                {
                    "id": "lx7b74r",
                    "author": "AdAgitated6993",
                    "body": "Is it possible to run them locally in comfyui?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731640843.0,
                    "parent_id": "t1_lx7aqoe",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7b74r/"
                },
                {
                    "id": "lx9uzo9",
                    "author": "Occsan",
                    "body": "Ok, I'm just going to explain you part of my workflow, because... well... it's a big one. But you can get this kind of result with it: [https://imgur.com/3v5YbQn](https://imgur.com/3v5YbQn)\n\nprompt was : \"a cute bird chirping on a tree in winter, it's wearing a tiny christmas hat\"\n\nand here's a pic of the workflow. explanations coming in the next comment.\n\nhttps://preview.redd.it/396evts3z21e1.png?width=1390&format=png&auto=webp&s=c32a7b4fee209a8261bf1d375670475e53d37438\n\nThat workflow allows me to do txt2img, txt2vid, img2img, img2vid, vid2img, vid2vid, controlnets, ipadapter, faceid, rgb sparse control, but also gracefully shifting accross a set of input images used either in controlnet or ipadapter, or both, auto captioning of images and prompt generation based on a input prompt.\n\nIn addition it also has various detectors for face, head and hair, person, etc (yolov detectors basically) that I can use to either keep or cut part of the input images.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731683166.0,
                    "parent_id": "t1_lx946oc",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx9uzo9/"
                },
                {
                    "id": "lx7buvd",
                    "author": "weshouldhaveshotguns",
                    "body": "closest thing we have locally is cogvideo, and mochi",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731641078.0,
                    "parent_id": "t1_lx7b74r",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7buvd/"
                },
                {
                    "id": "lx7csji",
                    "author": "Netsuko",
                    "body": "No. Those specific services are kind of like (tho not exactly) ChatGPT but for video creation, meaning they are so big and require so much compute power that they would not fit on consumer hardware with current tech.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731641405.0,
                    "parent_id": "t1_lx7b74r",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lx7csji/"
                },
                {
                    "id": "lxa0dbr",
                    "author": "Occsan",
                    "body": "Here's the part of the huge workflow that does most of the job regarding animatediff (there's a bit more to the right, but it's only used when there are faces detected in the image).\n\nhttps://preview.redd.it/0x2eo442031e1.png?width=1825&format=png&auto=webp&s=68c4e042cbd6ad62689757c42bbc253158e49097\n\nIt's a 2 pass workflow, with the low resolution pass broke down in 3 parts and a single pass in hires consisting of 1 step.\n\nNow, I break down all the numbered nodes/group of nodes:\n\n1. controls the amount of motion.\n2. Loads the animatelcm motion module (used in the first 2 passes)\n3. Loads the animatediff v3 motion module (used in the 2 latest passes)\n4. uncond zero helps with my SD15 checkpoint getting better colors, you can skip that.\n5. ... There's no 5. lol... When I numbered the image above, there was a 5, I merged it with 6, so just ignore 5.\n6. It's also helping getting better colors, but also helps a lot in avoiding blowing up the image. Basically, you start with whatever CFG scale you like, and over the 4 steps of the first pass, it will decrease to more or less quickly based on the value in the SRL Eval node (here it's 4: `w**4`)\n7. It's the first pass, 4 steps only, using a regular sampler and scheduler, only difference with normal image sampling (I mean: non animatediff) is that: animatediff is enabled with animatelcm and there's this decreasing CFG scale. You can totally play with the CFG scale, number of steps, start and end, etc...\n8. 2nd pass, still using animatelcm as the motion module, but this time we're using the typical lcm/sgm\\_uniform used with animatediff animatelcm motion module and we're activating 3 loras: v3 motion lora adapter, animatelcm lora and hyper-sd 8 steps lora. The result of 7+8 is that you get much sharper and detailed animations, at least in my experiences with my SD15 checkpoint.\n9. same as previous, but euler, to get rid of the ugly lcm artifacts you usually get on the last steps. This helps getting better detail.\n\nanimatelcm lora and hyper-sd 8 steps lora in the last 2 passes are also what helps you get an image super quickly. Basically, if you want to use animatediff and produce an image quickly, you definitively want to use CFG scale = 1. But if you do, no negative prompt for you.\n\nSo the idea is to sample very few steps with a higher CFG scale, so you get the effects of the negative prompt, and sample the rest at CFG scale = 1. But since you're sampling the rest with CFG scale = 1, then you need these loras (and you can definitively tweak their ratios), otherwise you're get a blurry image.\n\nI also found that v3\\_sd15\\_mm (animatediff v3 adapter lora) is helping quite a bit in maintaining a more stable image with less flickering.\n\nLastly, it's possible to go really crazy with the amount of motion in 1. You can go way higher than 2 for example. But if you do, you should also change the model used in 8 by the model you use in 9. So that the 2nd sampling pass (8) uses the v3 animatediff motion module with a scale\\_multival = 1 (this is the amount of motion). The result will be: for 4 steps tons of motion, then not a lot of motion. But the early steps determine the low-frequency features of the image (basically general subject, placement of objects, colors...) and the rest of the steps (at scale\\_multival = 1 = low amount of motion) determine the high-frequency features of the image (fine details, and this is also where the typical flickering happens).",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731684819.0,
                    "parent_id": "t1_lx9uzo9",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lxa0dbr/"
                },
                {
                    "id": "lxdxtax",
                    "author": "beachandbyte",
                    "body": "Thanks for sharing this, obviously took a lot of work, and always fun to explore workflows.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731732463.0,
                    "parent_id": "t1_lx9uzo9",
                    "link_id": "t3_1grmwut",
                    "permalink": "/r/StableDiffusion/comments/1grmwut/how_to_make_a_video_like_in_the_civitai_top/lxdxtax/"
                }
            ]
        },
        {
            "id": "1grlq8f",
            "title": "Question about multiple prompts emphasis in A1111 webui",
            "author": "staryoun1",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 3,
            "created_utc": 1731636584.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grlq8f/question_about_multiple_prompts_emphasis_in_a1111/",
            "permalink": "/r/StableDiffusion/comments/1grlq8f/question_about_multiple_prompts_emphasis_in_a1111/",
            "selftext": "(1girl, green dress, holding weapon, drill hair:0.5)\n\n\n\nDoes it means (1girl), (green dress), (holding weapon), (drill hair:0.5)?\n\n\n\nor (1girl:0.5), (green dress:0.5), (holding weapon:0.5), (drill hair:0.5) ?\n\n\n\nHow about (1girl, green dress:1.2, holding weapon:0.8, drill hair:0.5)? Does it work?\n\n\n\nI read [https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis) but i cound not find what i want to know.",
            "comments": [
                {
                    "id": "lx743ax",
                    "author": "Dwedit",
                    "body": "You get something similar to (1girl:0.5), (green dress:0.5), (holding weapon:0.5), (drill hair:0.5)\n\nBut it's not the same vector.  You can see this yourself by comparing two gens with the same seed, they don't match exactly.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731638367.0,
                    "parent_id": "t3_1grlq8f",
                    "link_id": "t3_1grlq8f",
                    "permalink": "/r/StableDiffusion/comments/1grlq8f/question_about_multiple_prompts_emphasis_in_a1111/lx743ax/"
                },
                {
                    "id": "lx81bf6",
                    "author": "acbonymous",
                    "body": "Everything gets the emphasis, even the commas. The last example is invalid and will only process the last emphasis, considering :1.2 and :0.8 as part of the prompt.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731651709.0,
                    "parent_id": "t3_1grlq8f",
                    "link_id": "t3_1grlq8f",
                    "permalink": "/r/StableDiffusion/comments/1grlq8f/question_about_multiple_prompts_emphasis_in_a1111/lx81bf6/"
                },
                {
                    "id": "lx91mn3",
                    "author": "thebaker66",
                    "body": "Yeah, first 2 are right, 3rd ineffective for what you are trying to do.\n\nI will add that the first 2 are corrective and that prompting is very sensitive to not only the bracketing and the weights but even quotation marks.\n\nOne thing I'll add is experiment with quotation marks around your phrases, this is something I used to see when I first got into SD and studied prompts but I stopped it. I rediscovered it yesterday on some old generations and it seriously changes things, generally cleans things up. Sometimes you want some times not but also take note of commas, commas between words and phrases can also alter things.. I'd say this is more something to look into if you're not getting what you want or notice conflicts/clashes where a word is overriding another word then it can help clean things up.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731672297.0,
                    "parent_id": "t1_lx81bf6",
                    "link_id": "t3_1grlq8f",
                    "permalink": "/r/StableDiffusion/comments/1grlq8f/question_about_multiple_prompts_emphasis_in_a1111/lx91mn3/"
                }
            ]
        },
        {
            "id": "1grky52",
            "title": "Is there a good local Model for very small images meant for deployment inside of a game?",
            "author": "Feisty-Pay-5361",
            "score": 29,
            "upvotes": 29,
            "downvotes": 0,
            "num_comments": 22,
            "created_utc": 1731634172.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/",
            "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/",
            "selftext": "I don't really know where to start my research so I thought I'd come here first. I need a very lightweight diffusion model for tiny images (think 256x256 or somewhere around that, detail is really not super important). It's only purpose would be to add some Flavor to a Tycoon game about making various films/tv shows and make small \"procedural\" cover art based on what the \"product\" the player is making (different genres, mood etc.). Something that can run on almost any PC and generate the image in a couple of seconds at most, but is also fine-tuneable by me (so that I can make it generate the content in the style that I want).\n\nAnyways I am not even sure if this is viable yet it is just an Idea that I had I could implement in to the project. I can go with actual procedural generation too if I really want to go all in, but diffusion seems like it'd be a natural fit for low detail non-descript iconis/posters.",
            "comments": [
                {
                    "id": "lx6vo4b",
                    "author": "Dismal-Rich-7469",
                    "body": "I see your idea , and it may work , but a far cheaper method is to use CLIP:https://codeandlife.com/2023/01/26/mastering-the-huggingface-clip-model-how-to-extract-embeddings-and-calculate-similarity-for-text-and-images/\n\nThe CLIP_L model can encode an image to a 768 vector.\n\nThe CLIP_L model can also encode text to a 768 vector\n\nAnd both of these vectors point in the same direction!   (It's Machine learning magic) \n\nHere is a practical example , where I use CLIP_L to search prompts: https://huggingface.co/datasets/codeShare/fusion-t2i-generator-data/blob/main/Google%20Colab%20Jupyter%20Notebooks/fusion_t2i_CLIP_interrogator.ipynb\n\nSo for your project , just make a bunch of images ahead of time and encode them with CLIP_L\n\nThen encode whatever the user writes with CLIP_L (it does not require  any  GPU at all) \n\nThen print the image with the 768 vector which most closely matches the 768 vector of the text  the user wrote.",
                    "score": 38,
                    "upvotes": 38,
                    "downvotes": 0,
                    "created_utc": 1731635501.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx6vo4b/"
                },
                {
                    "id": "lx6vwg6",
                    "author": "weshouldhaveshotguns",
                    "body": "You have a cool use case.  I think DALL·E Mini/Craiyon has the lowest system requirement of any ai image generation tool, but its outputs can be pretty bad.  It might be good enough, as long as you dont require text in the image.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731635577.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx6vwg6/"
                },
                {
                    "id": "lx7nbsa",
                    "author": "RealAstropulse",
                    "body": "This might be a good solution, it seems to run fine on cpu. [https://github.com/apple/ml-mdm](https://github.com/apple/ml-mdm)  \nI'd use the 64x64 model and an upscaler.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731645288.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx7nbsa/"
                },
                {
                    "id": "lx6v5r9",
                    "author": "Argamanthys",
                    "body": "There's [this](https://huggingface.co/justinpinkney/miniSD) SD 1.4 finetune, designed for 256x256 images. The model itself is just Stable Diffusion though, so I'm not sure it's vastly better than generating a 512 image and resizing it.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731635335.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx6v5r9/"
                },
                {
                    "id": "lx73up8",
                    "author": "eskimopie910",
                    "body": "Cool idea! I don’t have any info on it unfortunately but was curious if when you release it if you plan to mention that your game uses AI? Do you anticipate any backlash from using it? \n\nI’m making a game now and am tempted to use assets generated by AI but haven’t pulled the trigger due to the overwhelming negative perception of it",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731638286.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx73up8/"
                },
                {
                    "id": "lx84qh9",
                    "author": "IrisColt",
                    "body": "Interesting question! Could an SD 1.5 2GB model, optimized for 512x512, be downsized to generate 16x16 textures with a file just 62MB?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731653498.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx84qh9/"
                },
                {
                    "id": "lx8fpwx",
                    "author": "Emotional_Echidna293",
                    "body": "why limit yourself to 256x256? AI Roguelite allows players to select whatever resolution they're happy with and even load up their own Comfy server or plug in an API from somewhere applicable, no need to reinvent the wheel just do something similar to that.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731659723.0,
                    "parent_id": "t3_1grky52",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8fpwx/"
                },
                {
                    "id": "lx774gs",
                    "author": "Feisty-Pay-5361",
                    "body": "I see! Very interesting, I was not aware of such a technique. Thank you, I'll look in to it, seems very promising, especially performance wise (also a lot of control over the content it can produce which is important).",
                    "score": 12,
                    "upvotes": 12,
                    "downvotes": 0,
                    "created_utc": 1731639410.0,
                    "parent_id": "t1_lx6vo4b",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx774gs/"
                },
                {
                    "id": "lx6xm4e",
                    "author": "weshouldhaveshotguns",
                    "body": "Damn yo, this is brilliant. Bravo.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731636141.0,
                    "parent_id": "t1_lx6vo4b",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx6xm4e/"
                },
                {
                    "id": "lx7m11k",
                    "author": "RealAstropulse",
                    "body": "Actually genius suggestion. This guy develops.",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731644772.0,
                    "parent_id": "t1_lx6vo4b",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx7m11k/"
                },
                {
                    "id": "lx83yhp",
                    "author": "IrisColt",
                    "body": ">just make a bunch of images ahead of time\n\n  \nGot it—interesting idea. Guessing it's up to you to cover all possible film/TV genres to fit any idea, right?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731653087.0,
                    "parent_id": "t1_lx6vo4b",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx83yhp/"
                },
                {
                    "id": "lx77mdm",
                    "author": "Feisty-Pay-5361",
                    "body": "I am not too concerned with that aspect really; I am more concerned over actual Legal stuff (like the Steam Terms of Service for one); which is why I am looking for it to be strictly controlled output.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731639581.0,
                    "parent_id": "t1_lx73up8",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx77mdm/"
                },
                {
                    "id": "lx8pi5p",
                    "author": "Feisty-Pay-5361",
                    "body": "There is no practical use for that in my game. It'd just be some background flavor/visual icon, not a key mechanic the player has any actual control over. I also do not want to ship SD or similar, too heavy+too risky.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731665741.0,
                    "parent_id": "t1_lx8fpwx",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8pi5p/"
                },
                {
                    "id": "lx8alex",
                    "author": "NarrativeNode",
                    "body": "Honestly? 1000 thumbnails should cover it.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731656728.0,
                    "parent_id": "t1_lx83yhp",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8alex/"
                },
                {
                    "id": "lx8qtsw",
                    "author": "ver0cious",
                    "body": "If a cover is not well representative, just place a renew/replace button to queue/generate a better one.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731666548.0,
                    "parent_id": "t1_lx83yhp",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8qtsw/"
                },
                {
                    "id": "lx8q95m",
                    "author": "Thomas-Lore",
                    "body": "Pregenerate thousands and come up with a way of selecting a matching one, that way you don't need to ship the ai with the game (and risk users getting nsfw images) .",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731666199.0,
                    "parent_id": "t1_lx77mdm",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8q95m/"
                },
                {
                    "id": "lxb7nl3",
                    "author": "Emotional_Echidna293",
                    "body": "i understand the \"heavy\" concern, but \"risky\"? it really isn't. + using SD to gen 512x512 images on lower-end models doesn't even use that much compute anymore as long as you're using an optimized backend like comfy, you don't start pushing big numbers til you're using like sd3/sdcascade 1024x1024 gens.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731697675.0,
                    "parent_id": "t1_lx8pi5p",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lxb7nl3/"
                },
                {
                    "id": "lx8jcx9",
                    "author": "Green-Rule-1292",
                    "body": "You could also make separate and reusable layers, \"space style background\", \"alchemy style foreground\" etc and then combine a few of the closest matches from each layer category to produce some ridiculous number of image variations.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731661915.0,
                    "parent_id": "t1_lx8alex",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8jcx9/"
                },
                {
                    "id": "lxbgsiy",
                    "author": "Feisty-Pay-5361",
                    "body": "It is risky because I do not want to let users create ToS content on accident (or purpose). Also I think you are underestimating what \"light\" means here; I am not talking about some guy with a 1060; it'd be a 2D game that's supposed to run on a 400 dollar Intel HD laptop (it's a SPrite based game after all). And shipping filesize has to be way bellow 1gb.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700488.0,
                    "parent_id": "t1_lxb7nl3",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lxbgsiy/"
                },
                {
                    "id": "lx8uvxc",
                    "author": "NarrativeNode",
                    "body": "Yes!! Characters, Costumes and Backgrounds maybe?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731668890.0,
                    "parent_id": "t1_lx8jcx9",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx8uvxc/"
                },
                {
                    "id": "lxbqjmt",
                    "author": "Emotional_Echidna293",
                    "body": "any \"tos breaking content\" is on THEM not you. If you're uploading your game to Steam that's why you put the AI generated tag, you aren't responsible for what an AI generates in your game... the AI in ai roguelite has no limits and can even go full nsfw yet has no mature content descriptor and has been around for ages.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731703460.0,
                    "parent_id": "t1_lxbgsiy",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lxbqjmt/"
                },
                {
                    "id": "lx913uf",
                    "author": "Green-Rule-1292",
                    "body": "Exactly! Could even do character\\_left and character\\_right for example. Or costume\\_top and costume\\_bottom. Numbers of possible variations explode really fast too so probably wouldn't even have to produce too many images.\n\nFor example, just having three layers with 20 variants each would still produce 20\\*20\\*20=8000 possible variations(!) while only having to draw 20+20+20=60 drawings. (and spend some time up front planning it all out).",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731672048.0,
                    "parent_id": "t1_lx8uvxc",
                    "link_id": "t3_1grky52",
                    "permalink": "/r/StableDiffusion/comments/1grky52/is_there_a_good_local_model_for_very_small_images/lx913uf/"
                }
            ]
        },
        {
            "id": "1grjfh6",
            "title": "Is civitai site down or is under maintenance?! Couldn't generate pics?",
            "author": "Ecstatic_Ad_1144",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731629645.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grjfh6/is_civitai_site_down_or_is_under_maintenance/",
            "permalink": "/r/StableDiffusion/comments/1grjfh6/is_civitai_site_down_or_is_under_maintenance/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx6gnrg",
                    "author": "Enshitification",
                    "body": "I just logged in. They have a notice that image gen is currently down due to overload.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731630436.0,
                    "parent_id": "t3_1grjfh6",
                    "link_id": "t3_1grjfh6",
                    "permalink": "/r/StableDiffusion/comments/1grjfh6/is_civitai_site_down_or_is_under_maintenance/lx6gnrg/"
                }
            ]
        },
        {
            "id": "1grihbh",
            "title": "Two men on the move.",
            "author": "Unit2209",
            "score": 465,
            "upvotes": 465,
            "downvotes": 0,
            "num_comments": 30,
            "created_utc": 1731626959.0,
            "url": "https://www.reddit.com/gallery/1grihbh",
            "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/",
            "selftext": "",
            "comments": [
                {
                    "id": "lx66ljn",
                    "author": "Unit2209",
                    "body": "This piece gave me quite a lot of trouble, but was definitely fun. When it comes to my workflow you should know the drill by now. This time I included a link to the original base image. :)\n\nWorkflow:\n\n1. Generate base image.\n2. Dirty upscale 2x in img2img with Ultimate SD Upscaler. Play with denoise, 0.35-0.4. CFG 10-15.\n3. Inpaint major changes to scene.\n4. Clean upscale 2x with SUPIR (or your favorite clean upscaler).\n5. Inpaint minor changes and details to scene, if changing major details then inpaint in chunks. (Repeat 50x)\n6. To make the file size manageable, use your favorite image editor. Export the PNG as JPEG with desired quality settings. Usually 90-95%.\n\nOrignal Generation Parameters: Does not include upscale or inpainting information;\n\n* ((In the style of Pixel art)), 4 massive epic artillery pieces in background looming over a concrete city, distant landscape, dark night sky\n* Negative prompt: lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artists name\n* Steps: 40, Sampler: DPM++ 2M, Schedule type: Karras, CFG scale: 5, Seed: 2373356170, Size: 1216x832, Model hash: 0724518c6b, Model: juggernautXL\\_v7Rundiffusion, Version: v1.9.4\n\nLink to full final image: [https://drive.google.com/file/d/1EY2X3rg-1hgoeYHTNz1-aJ7w6ZTXZiYJ/view?usp=drive\\_link](https://drive.google.com/file/d/1EY2X3rg-1hgoeYHTNz1-aJ7w6ZTXZiYJ/view?usp=drive_link)\n\nLink to initial base image: [https://drive.google.com/file/d/192fmDATaLdukUQkwMAAdVHTi4E2kxEal/view?usp=drive\\_link](https://drive.google.com/file/d/192fmDATaLdukUQkwMAAdVHTi4E2kxEal/view?usp=drive_link)",
                    "score": 48,
                    "upvotes": 48,
                    "downvotes": 0,
                    "created_utc": 1731627091.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx66ljn/"
                },
                {
                    "id": "lx67663",
                    "author": "Jimmm90",
                    "body": "Ok this is my favorite series",
                    "score": 11,
                    "upvotes": 11,
                    "downvotes": 0,
                    "created_utc": 1731627280.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx67663/"
                },
                {
                    "id": "lx6bua1",
                    "author": "zkgkilla",
                    "body": "I love these keep it up",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731628827.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6bua1/"
                },
                {
                    "id": "lx6p2ru",
                    "author": "pwillia7",
                    "body": "These are great! Keep going!",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731633279.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6p2ru/"
                },
                {
                    "id": "lx6ua3g",
                    "author": "Patient-Librarian-33",
                    "body": "What is the final res?",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731635043.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6ua3g/"
                },
                {
                    "id": "lxaklu9",
                    "author": "FourOranges",
                    "body": "This reminds me of an Alan Watts lecture on how paintings in the West differ from Asian ones, with Chinese paintings having more of a focus on the grand composition. A painting might be titled \"man drinking wine\" similar to your title and it'd be depicted exactly as yours: if you zoom in on a particular portion of the painting you might find that man drinking wine but the goal of the artist was to incorporate that man drinking wine into the whole vast composition that makes up the painting. There was another point to be made of Western art using empty white space and focusing instead on the topic but Chinese art utilizing the entire scroll/parchment in order to demonstrate the theme of harmoniously coexisting with nature. Pretty cool stuff.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731690827.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lxaklu9/"
                },
                {
                    "id": "lx6elb0",
                    "author": "dontpushbutpull",
                    "body": "Can i haz: planetary invasion!?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731629748.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6elb0/"
                },
                {
                    "id": "lx6p27u",
                    "author": "LocoMod",
                    "body": "This is outstanding. Great job!",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731633274.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6p27u/"
                },
                {
                    "id": "lx7v8lc",
                    "author": "imainheavy",
                    "body": "When it says workflow included, where/how exactly do I access this info ?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731648736.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx7v8lc/"
                },
                {
                    "id": "lx7vkzq",
                    "author": "Key-Rest-9764",
                    "body": "I like these and hope they can continue to be updated.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731648895.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx7vkzq/"
                },
                {
                    "id": "lx6jz4m",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/dl4i54d0py0e1.png?width=3840&format=png&auto=webp&s=6a68c76e2441ee81db2eec156b9a60f6bbfdede6\n\nIt started with tiled cubes from Excel 1.0 logo in 1991.  I drew stick figures then, pixel by pixel, using MSpaint.  and my coworkers wanted to print it at Kinkos, but the guy at the store said it was too small of resolution at 640x480.\n\nSo I put it into Stable Diffusion XL, using INIT image, with various prompting when I found this incredible tool in 2023.",
                    "score": -3,
                    "upvotes": -3,
                    "downvotes": 0,
                    "created_utc": 1731631548.0,
                    "parent_id": "t3_1grihbh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6jz4m/"
                },
                {
                    "id": "lx69onh",
                    "author": "remghoost7",
                    "body": "Kudos on including your entire workflow.  \nMore people should follow suit on this sort of thing.\n\nAlso love seeing an SDXL model pushed to this quality, especially around all of the recent SD3.5/flux releases. It really just goes to show you how powerful of a tool Stable Diffusion really is once you understand how to use it and how to dance around it's limitations.\n\n>!DPM++ 2m / karras is best girl.!<\n\n\\---\n\nWhich frontend are you using for inpainting...?  \nOr are you using the Kira / Photoshop plugin?",
                    "score": 16,
                    "upvotes": 16,
                    "downvotes": 0,
                    "created_utc": 1731628118.0,
                    "parent_id": "t1_lx66ljn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx69onh/"
                },
                {
                    "id": "lx6rc6x",
                    "author": "MidSolo",
                    "body": ">bad anatomy, bad hands, [...] missing fingers, extra digit, fewer digits\n\nIf you're going to make a scene this zoomed out, why include that in the negative prompt?",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731634055.0,
                    "parent_id": "t1_lx66ljn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6rc6x/"
                },
                {
                    "id": "lx7f2ok",
                    "author": "comfyui_user_999",
                    "body": "This continues to be a great series of images, very nicely done.  I don't know whether you would ever consider recording or streaming your process, but I'd watch something like that.  Along the lines of sketchinginblender.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731642208.0,
                    "parent_id": "t1_lx66ljn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx7f2ok/"
                },
                {
                    "id": "lx6qac3",
                    "author": "None",
                    "body": "[deleted]",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731633697.0,
                    "parent_id": "t1_lx66ljn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6qac3/"
                },
                {
                    "id": "lx8ozhp",
                    "author": "SafeSurprise3001",
                    "body": "> (Repeat 50x)\n\nYeah I'm not surprised, first thing I thought when I looked at it was \"how much inpainting did this guy do\"\n\nTurns out the answer is \"a lot\"",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731665425.0,
                    "parent_id": "t1_lx66ljn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx8ozhp/"
                },
                {
                    "id": "lx6rc4b",
                    "author": "Unit2209",
                    "body": "Thanks! I definitely enjoy it too.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731634054.0,
                    "parent_id": "t1_lx67663",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6rc4b/"
                },
                {
                    "id": "lx6x0f8",
                    "author": "Unit2209",
                    "body": "Final res is 4480x2704",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731635945.0,
                    "parent_id": "t1_lx6ua3g",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6x0f8/"
                },
                {
                    "id": "lxan5bp",
                    "author": "Unit2209",
                    "body": "Wow, that's very interesting",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731691586.0,
                    "parent_id": "t1_lxaklu9",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lxan5bp/"
                },
                {
                    "id": "lx81w12",
                    "author": "Unit2209",
                    "body": "I left general instructions on a comment on this post. Feel free to ask questions if anything doesn't make sense!",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731652006.0,
                    "parent_id": "t1_lx7v8lc",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx81w12/"
                },
                {
                    "id": "lx6k2h3",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/u5d0mlwopy0e1.jpeg?width=639&format=pjpg&auto=webp&s=e4e08f6576d0a6a4a638b09a256cecf60affe85a\n\nThe original from 1991.",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731631578.0,
                    "parent_id": "t1_lx6jz4m",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6k2h3/"
                },
                {
                    "id": "lx6fh6p",
                    "author": "Unit2209",
                    "body": "Thank you! And I just use base ForgeUI inpainting. I really need to try to expand my tool set, lol",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731630044.0,
                    "parent_id": "t1_lx69onh",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6fh6p/"
                },
                {
                    "id": "lx6t4j9",
                    "author": "Unit2209",
                    "body": "A very good point! Not having that could only improve the image. However, I usually am lazy and leave old details in my negative.\n\n\nChanging the incorrect negative after I've seen the image would have altered it in ways I didn't want.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731634662.0,
                    "parent_id": "t1_lx6rc6x",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6t4j9/"
                },
                {
                    "id": "lx6ra8c",
                    "author": "Unit2209",
                    "body": "I can see animation helping many areas of this piece.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731634037.0,
                    "parent_id": "t1_lx6qac3",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6ra8c/"
                },
                {
                    "id": "lx6ykby",
                    "author": "Patient-Librarian-33",
                    "body": "Pretty tame, I like the details.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731636464.0,
                    "parent_id": "t1_lx6x0f8",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6ykby/"
                },
                {
                    "id": "lx874e2",
                    "author": "imainheavy",
                    "body": "Aha, so it's not acctualy a button i press to see the meta data etc. i see",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731654791.0,
                    "parent_id": "t1_lx81w12",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx874e2/"
                },
                {
                    "id": "lx6kd8y",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/0d69z0pwpy0e1.jpeg?width=3840&format=pjpg&auto=webp&s=d30c9d587f6e85b2d2fc1f2eef0a3c70507f43d9\n\nThe computer only does what I ask it to.  \n\nHow about a nice game of Chess?",
                    "score": -1,
                    "upvotes": -1,
                    "downvotes": 0,
                    "created_utc": 1731631679.0,
                    "parent_id": "t1_lx6k2h3",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6kd8y/"
                },
                {
                    "id": "lx6qogn",
                    "author": "Unit2209",
                    "body": "Of what you posted, I do enjoy this one the most.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731633833.0,
                    "parent_id": "t1_lx6kd8y",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6qogn/"
                },
                {
                    "id": "lx6l83q",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/vhdc40xnqy0e1.jpeg?width=1280&format=pjpg&auto=webp&s=df5e130a47b38bc8ef5782660276385e4383854d\n\nIt's called a Battle Cruiser.   I drew a poorly illustration of a cannon and asked Stable Diffusion to enhhance it.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731631964.0,
                    "parent_id": "t1_lx6kd8y",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6l83q/"
                },
                {
                    "id": "lxaptws",
                    "author": "Godd2",
                    "body": "Q-bert Chess",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731692387.0,
                    "parent_id": "t1_lx6qogn",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lxaptws/"
                },
                {
                    "id": "lx6ooif",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/fpy5wrycuy0e1.png?width=3840&format=png&auto=webp&s=f68c926c6ae0c6b115919e97d23ef1a0b220a4bf\n\nIts never ending.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731633145.0,
                    "parent_id": "t1_lx6l83q",
                    "link_id": "t3_1grihbh",
                    "permalink": "/r/StableDiffusion/comments/1grihbh/two_men_on_the_move/lx6ooif/"
                }
            ]
        },
        {
            "id": "1grhsjo",
            "title": "Dark Fantasy Book Covers",
            "author": "Vegetable_Writer_443",
            "score": 42,
            "upvotes": 42,
            "downvotes": 0,
            "num_comments": 8,
            "created_utc": 1731625048.0,
            "url": "https://www.reddit.com/gallery/1grhsjo",
            "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/",
            "selftext": "I've been experimenting with book cover designs that focus on character composition, title placement, and author name with the fitting fonts. The goal is to create eye-catching covers that showcase characters as the main focus, with consistent detailing and balanced layout.\n\nI've developed a set of prompts that you can use for your own designs.\n\n**A decrepit village with crooked houses and a blood-red moon hanging above, casting ominous shadows. In the center, a hooded figure with glowing eyes points a finger, conjuring dark magic that swirls around them. The title \"Cursed Heritage\" and the author’s name can be displayed in the clear space above the figure, adding intrigue.**\n\n**A desolate castle perched atop a cliff is silhouetted against a blood-red sky. Bats fly in formation around the towering spires, while a lone raven perches on a crumbling ledge. Below, dark waves crash against the rocks. The title “Crown of Shadows” can be displayed in bold, gothic lettering at the bottom, leaving space for author text above.**\n\n**A dark forest shrouded in mist, with twisted trees and glowing eyes peering from the shadows. In the foreground, a cloaked figure holds a flickering lantern, casting eerie light on ancient runes carved into the ground. The title text, \"Whispers of the Forgotten\", is prominently displayed at the top, while the author’s name is positioned at the bottom against the dark background.**\n\n\n**A dark forest shrouded in mist, with twisted trees and glowing eyes peering from the shadows. In the foreground, a cloaked figure holds a flickering lantern, casting eerie light on ancient runes carved into the ground. The title text, \"Whispers of the Forgotten\", is prominently displayed at the top, while the author’s name is positioned at the bottom against the dark background.**",
            "comments": [
                {
                    "id": "lx7vufr",
                    "author": "Key-Rest-9764",
                    "body": "I like these. I like the first one the most. It seems that you are waiting for me, and the next one is you.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731649018.0,
                    "parent_id": "t3_1grhsjo",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx7vufr/"
                },
                {
                    "id": "lx87xa6",
                    "author": "umarmnaq",
                    "body": "Awesome! Now, use LLMs to write the books.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731655231.0,
                    "parent_id": "t3_1grhsjo",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx87xa6/"
                },
                {
                    "id": "lx6g7u5",
                    "author": "Vegetable_Writer_443",
                    "body": "I've added this and many other prompt templates to my browser extension for free, you can check it out if you are interested.\nhttps://chromewebstore.google.com/detail/prompt-catalyst/hehieakgdbakdajfpekgmfckplcjmgcf",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731630292.0,
                    "parent_id": "t3_1grhsjo",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx6g7u5/"
                },
                {
                    "id": "lx6kst6",
                    "author": "MisterBlackStar",
                    "body": "Flux Dev?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731631822.0,
                    "parent_id": "t3_1grhsjo",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx6kst6/"
                },
                {
                    "id": "lx6ls6o",
                    "author": "Vegetable_Writer_443",
                    "body": "Accidentally added the same prompt twice. The prompt for the last image is **A lone warrior in ornate armor stands at the edge of a cliff, overlooking a vast, stormy ocean. Lightning splits the sky as a ship approaches in the distance, its sails tattered. The title \"Stormbringer's Fate\" is strikingly placed at the top, with the author’s name at the bottom.**",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731632151.0,
                    "parent_id": "t3_1grhsjo",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx6ls6o/"
                },
                {
                    "id": "lxaadga",
                    "author": "LeKhang98",
                    "body": "Did Flux accurately write all the titles in the image or did you fixed them later? ",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731687807.0,
                    "parent_id": "t1_lx6g7u5",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lxaadga/"
                },
                {
                    "id": "lx6l00s",
                    "author": "Vegetable_Writer_443",
                    "body": "Yes. The last image is Flux Pro 1.1",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731631888.0,
                    "parent_id": "t1_lx6kst6",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lx6l00s/"
                },
                {
                    "id": "lxac1n1",
                    "author": "Vegetable_Writer_443",
                    "body": "These are unedited Flux outputs. It handles text exceptionally well, with no spelling errors. Although sometimes it doesn't add the text mentioned in the prompt at all.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731688302.0,
                    "parent_id": "t1_lxaadga",
                    "link_id": "t3_1grhsjo",
                    "permalink": "/r/StableDiffusion/comments/1grhsjo/dark_fantasy_book_covers/lxac1n1/"
                }
            ]
        },
        {
            "id": "1grhopx",
            "title": "Possible to train a Flux lora with 12gb of VRAM and 16gb of system RAM?",
            "author": "omg_can_you_not",
            "score": 14,
            "upvotes": 14,
            "downvotes": 0,
            "num_comments": 24,
            "created_utc": 1731624757.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/",
            "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/",
            "selftext": "I have a 3060 12gb but only 16gb of system ram. I don't mind waiting longer for training to finish, but is it possible to do? I'd prefer to do it in ComfyUI if such a workflow exists. Thanks to anyone who can point me in the right direction!",
            "comments": [
                {
                    "id": "lx6j9sw",
                    "author": "faffingunderthetree",
                    "body": "Doable I've seen others say they have, but itll be insanely slow i feel. \nI know it's an answer to a question you didn't ask, but for the time it takes the like $2/€2 it costs to train a lora on the usual sites is probably cheaper then your electrical bill from your 3060 going 100% for 20hours",
                    "score": 14,
                    "upvotes": 14,
                    "downvotes": 0,
                    "created_utc": 1731631312.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx6j9sw/"
                },
                {
                    "id": "lx687pp",
                    "author": "tom83_be",
                    "body": "See [https://www.reddit.com/r/StableDiffusion/comments/1f5onyx/tutorial\\_setup\\_train\\_flux1\\_dev\\_loras\\_using/](https://www.reddit.com/r/StableDiffusion/comments/1f5onyx/tutorial_setup_train_flux1_dev_loras_using/)",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731627627.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx687pp/"
                },
                {
                    "id": "lx76der",
                    "author": "Appropriate-Duck-678",
                    "body": "I have the same system configuration as yours and For me I renamed flux dev fp8 model as flux dev and kept it in the model path and ran the flux gym with roughly 17 images and at around 1300 itr you will get the desired results and the training time will be roughly 2:30 hrs...you can get a consistent lora",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731639149.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx76der/"
                },
                {
                    "id": "lx6znx3",
                    "author": "rymdimperiet",
                    "body": "Works fine using Fluxgym with a reasonable amount of images (around 50). \n\nIs veeeeeeeeeeeery slow, though.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731636836.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx6znx3/"
                },
                {
                    "id": "lx716q3",
                    "author": "SiyoSan",
                    "body": "Yes it is. Depending on how much images you use for training, it can take some time. I use a 3080ti 12gb vram and it takes me about 3 hours for 30 training images and 5000 regularization images and 5 epochs . Way less without the regularization images. And the results are pretty good.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731637362.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx716q3/"
                },
                {
                    "id": "lx7n8iv",
                    "author": "GateOPssss",
                    "body": "Doable, and very slow. Same config on my side, i had to increase my pagefile to 50GB to make it work, otherwise it crashes. But it works.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731645253.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx7n8iv/"
                },
                {
                    "id": "lx7yl5x",
                    "author": "Ok-Perception8269",
                    "body": "I have your card and 64 GB RAM and did it last night using Fluxgym. I used 24 images which was probably too many, took about 10 hours. IIRC I saw a workflow for training using comfy on civitai, just don’t have it in front of me. I think you’re ok, just start it before you go to bed.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731650338.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx7yl5x/"
                },
                {
                    "id": "lx8c86m",
                    "author": "Party-Try-1084",
                    "body": "OneTrainer, 768px, 9,1~vram and 11ram usage, \nSpeed is 9it/s(i think it's broken because i had 6s/it before) but it works) Also 3060 and 16gb memory\nConfig is in this subreddit, + cpu offloaded gradient checkpointing and lora alpha 16 and 16.0(128 will give 1gb lora files)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731657656.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8c86m/"
                },
                {
                    "id": "lx8j358",
                    "author": "No-Sleep-4069",
                    "body": "Yes, try flux gym in pinokio",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731661752.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8j358/"
                },
                {
                    "id": "lx8jwmv",
                    "author": "Kadaj22",
                    "body": "Yep but it will take a while",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731662249.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8jwmv/"
                },
                {
                    "id": "lx9ohgs",
                    "author": "Ok-Perception8269",
                    "body": "Here is a workflow in ComfyUI:\n\nhttps://civitai.com/articles/7131/flux-lora-trainer-on-comfyui-v10",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731681059.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx9ohgs/"
                },
                {
                    "id": "lx6b6jh",
                    "author": "Scolder",
                    "body": "Secourses has a setting that might work for your pc.",
                    "score": -15,
                    "upvotes": -15,
                    "downvotes": 0,
                    "created_utc": 1731628610.0,
                    "parent_id": "t3_1grhopx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx6b6jh/"
                },
                {
                    "id": "lx746va",
                    "author": "omg_can_you_not",
                    "body": "Lol this is a very good point. I see it's about $5 to train it on CivitAI so I'll probably just go this route.",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731638402.0,
                    "parent_id": "t1_lx6j9sw",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx746va/"
                },
                {
                    "id": "lx7zc25",
                    "author": "krzysiekde",
                    "body": "Yeah, but just in my case: I pay for renting a gpu, but the result is crap and have to try all over again... It's not always that easy unfortunately. But on the other hand the cost of electricity you mentioned and time spent would be bigger in home option",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731650708.0,
                    "parent_id": "t1_lx6j9sw",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx7zc25/"
                },
                {
                    "id": "lx8ljwk",
                    "author": "Nattya_",
                    "body": "Better to rent a GPU like on runpod, then you can have a lora for 0.5 usd and you can view progress images there too",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731663283.0,
                    "parent_id": "t1_lx6j9sw",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8ljwk/"
                },
                {
                    "id": "lx740cx",
                    "author": "omg_can_you_not",
                    "body": "I did try with Fluxgym a few days ago but kept getting OOM errors, do you know if there is a way to add command arguments to it?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731638340.0,
                    "parent_id": "t1_lx6znx3",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx740cx/"
                },
                {
                    "id": "lx8jk90",
                    "author": "No_Afternoon_4260",
                    "body": "Like how slow?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731662039.0,
                    "parent_id": "t1_lx6znx3",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8jk90/"
                },
                {
                    "id": "lx6ix6r",
                    "author": "faffingunderthetree",
                    "body": "Can you stop pushing his paid patreon stuff? You're obviously an alt account of his",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731631195.0,
                    "parent_id": "t1_lx6b6jh",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx6ix6r/"
                },
                {
                    "id": "lx7af90",
                    "author": "Nenotriple",
                    "body": "Send me a PM with your Civitai username and I'll send you the buzz you need for training a lora.",
                    "score": 12,
                    "upvotes": 12,
                    "downvotes": 0,
                    "created_utc": 1731640566.0,
                    "parent_id": "t1_lx746va",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx7af90/"
                },
                {
                    "id": "lx9q6ft",
                    "author": "faffingunderthetree",
                    "body": "No it's like $2.20 or there abouts on civatai, and you can get buzz each day for doing like daily mmo quest like stuff, takes about 5mins to them all each day and you get around 250 buzz or something like that, bit tedious but pretty easy if u do each day, free lora every 10 days or so then? \n\nI'd probably rather just pay the $2 since I'm lazy, but I see no reason not to do the daily stuff",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731681623.0,
                    "parent_id": "t1_lx746va",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx9q6ft/"
                },
                {
                    "id": "lx8cdvr",
                    "author": "Party-Try-1084",
                    "body": "don't use fluxgym, it's so broken and never worked for me on 16gb ram/12vram",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731657746.0,
                    "parent_id": "t1_lx740cx",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8cdvr/"
                },
                {
                    "id": "lx8uga0",
                    "author": "rymdimperiet",
                    "body": "About a day for 8 epochs on standard settings with 50 1024x1024 images. On a 3080ti. \nMaybe there are ways to optimize that, but I'm a noob when it comes to lora training.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731668647.0,
                    "parent_id": "t1_lx8jk90",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx8uga0/"
                },
                {
                    "id": "lxaajms",
                    "author": "Pretend_Potential",
                    "body": "It's not furkan, he doesn't use alt accounts. and i don't see that he posted a link to the patreon?",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731687857.0,
                    "parent_id": "t1_lx6ix6r",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lxaajms/"
                },
                {
                    "id": "lx6kxx5",
                    "author": "Scolder",
                    "body": "I’m not an alt account.  I happen to use his configs.\n\n\n\nYou sound like a conspiracy theorist.",
                    "score": -13,
                    "upvotes": -13,
                    "downvotes": 0,
                    "created_utc": 1731631869.0,
                    "parent_id": "t1_lx6ix6r",
                    "link_id": "t3_1grhopx",
                    "permalink": "/r/StableDiffusion/comments/1grhopx/possible_to_train_a_flux_lora_with_12gb_of_vram/lx6kxx5/"
                }
            ]
        },
        {
            "id": "1grhmb2",
            "title": "I'm getting a little lost in learning this and I want to continue adding more knowledge, how do I do it?",
            "author": "Dave-C",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 13,
            "created_utc": 1731624579.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/",
            "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/",
            "selftext": "I'm learning but it seems to be slow. When there is something new I'm wanting to learn how to do I usually look at a workflow but then the workflow has 10 things in it that I don't know how to do so I don't know where to start to learn what I need to know.\n\nSo I started off on Forge, it was good but I switched to Comfy and I've been much happier with it because it forces me to learn what is happening. I started off with generating basic images. I then wanted to learn how to add in loras to what I generate, that was easy. Then I wanted to learn how to get more detail since I'm using FLUX and it is limited to 2MP so I had to learn how to do upscaling. Then I figured out how to pause the generation so I can do a batch of smaller images, pick the ones I like then upscale them using Ultimate SD.\n\nAt this point I'm stuck because I don't know how to get from what I'm doing now to creating images with multiple people so I need to learn how to divide an image so loras are applied to different sections of the image. I need to learn more about IP adapters because, supposedly from what I've read, it is a better technique than loras. Is there a way to divide a generate image by layers? Like using loras for background, middle and foreground?\n\nI know I'm likely asking a lot but I guess what I'm asking is if you had to relearn this stuff, how would you do it?",
            "comments": [
                {
                    "id": "lx68szt",
                    "author": "Celestial_Creator",
                    "body": "just to add\n\nif you want more creative control\n\n[https://github.com/Acly/krita-ai-diffusion](https://github.com/Acly/krita-ai-diffusion)\n\nwhich will use your comfy install",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731627824.0,
                    "parent_id": "t3_1grhmb2",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx68szt/"
                },
                {
                    "id": "lx7xgce",
                    "author": "LeKhang98",
                    "body": "If you want to learn more about IPAdapter then Latent Vision YT channel is a pretty good source since the owner is also the creator of IPAdapter Plus node in ComfyUI so he usually explain everything in detail. Also what you want to do can be achieved by Regional Prompting or you may use Attention Masking (Latent Vision has a detail video about that.)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731649786.0,
                    "parent_id": "t3_1grhmb2",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx7xgce/"
                },
                {
                    "id": "lxcqkjv",
                    "author": "artificial_genius",
                    "body": "I don't think that the ipadapters are better than lora. They take less time for sure but quality is lacking for most models. I learned most of what I know like you, trolling around YouTube, here, and github so you are on the right path. Maybe go for making loras next? You'll figure most of it out eventually and soon there will be something new to learn anyway.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731715349.0,
                    "parent_id": "t3_1grhmb2",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lxcqkjv/"
                },
                {
                    "id": "lx659w4",
                    "author": "Same-Pizza-6724",
                    "body": "\"regional prompter\" is what you're looking for.\n\nI've no idea on using it in comfy though, (you'd have to pry forge from my cold dead hands), but I would be beyond shocked if it didn't exist.\n\nSo that's your first port of call.\n\nThat should allow you to say \"x lora on the right, y lora on the left\" or whatever.\n\nNext is controlnet, there's lots of different controlnet, and they all work a bit different, and are better for some concepts, worse for others.\n\nI swear by controlnet canny, but you can do depth masks, just poses, just background, basically whatever.\n\nI don't use IP adapter because controlnet canny and reactor work fine for my eyes, but as far as I'm aware, it's a similar thing for producing similar things.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731626660.0,
                    "parent_id": "t3_1grhmb2",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx659w4/"
                },
                {
                    "id": "lx7fe57",
                    "author": "Superb-Ad-4661",
                    "body": "Hello, some people here have been in this business for almost 2 years and haven't managed to learn everything, and if you don't practice everything cyclically you will forget some things along the way. Each branch of AI opens new doors and more learning needs. About your rig, the vram still makes a difference, I have a 3090 and I think it's not enough for some complex tasks, when you need to load and do inference for large models and high parameters.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731642314.0,
                    "parent_id": "t3_1grhmb2",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx7fe57/"
                },
                {
                    "id": "lx6f1w3",
                    "author": "Dave-C",
                    "body": "Oh my, that looks amazing.\n\nYou know when I built this PC earlier this year I thought \"this will be powerful enough for years.\" Now I'm sitting here on a 4070 wondering if my PC needs an upgrade.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731629903.0,
                    "parent_id": "t1_lx68szt",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx6f1w3/"
                },
                {
                    "id": "lx7xx3c",
                    "author": "Dave-C",
                    "body": "Thank you, I've got a lot to look into now but I'll try to get to it within the next few days or at least this weekend. Thank you for the advice.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731650011.0,
                    "parent_id": "t1_lx7xgce",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx7xx3c/"
                },
                {
                    "id": "lx6kmgz",
                    "author": "solomania9",
                    "body": "I hear you. I’d suggest practicing prompting with fewer words, learning the subtle differences between them with the same seed. It’s really fascinating to see what concepts are baked into the models.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731631764.0,
                    "parent_id": "t1_lx659w4",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx6kmgz/"
                },
                {
                    "id": "lx86mhs",
                    "author": "victorc25",
                    "body": "“Business”",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731654517.0,
                    "parent_id": "t1_lx7fe57",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx86mhs/"
                },
                {
                    "id": "lx6tspc",
                    "author": "Celestial_Creator",
                    "body": "using a 3060 however i did upgrade my system ram i had 16gigs and kept hitting the ceiling",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731634885.0,
                    "parent_id": "t1_lx6f1w3",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx6tspc/"
                },
                {
                    "id": "lxa9u9k",
                    "author": "LeKhang98",
                    "body": "I just discovered another simple node CONDITION (SET MASK) that can help applying different prompts to different regions, may not help with different Loras though. You can see it at 18:10 in this vid https://youtu.be/oBKcjY-JO3Y?si=vT43qaSpSQQh-MyO",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731687647.0,
                    "parent_id": "t1_lx7xx3c",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lxa9u9k/"
                },
                {
                    "id": "lx6wjy5",
                    "author": "Dave-C",
                    "body": "I have 32 in this system and I still max it but I mostly use the full version of Flux and the fp8 clip. I've been meaning to switch to an fp8 version of Flux but if I remember right the last time I tried it Comfy crashed and I stropped trying. I should go back and see if I can get that sorted out so I have faster gen times. Either that or go buy another 32gb of ram and for that I have not kept up with it but this cpu had issues with anything higher than two slots of memory used when I purchased it, hopefully that has been resolved.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731635792.0,
                    "parent_id": "t1_lx6tspc",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx6wjy5/"
                },
                {
                    "id": "lx7dypi",
                    "author": "Celestial_Creator",
                    "body": "i added 64 and i see flux take up more then 32 so yea if you can add another",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731641813.0,
                    "parent_id": "t1_lx6wjy5",
                    "link_id": "t3_1grhmb2",
                    "permalink": "/r/StableDiffusion/comments/1grhmb2/im_getting_a_little_lost_in_learning_this_and_i/lx7dypi/"
                }
            ]
        },
        {
            "id": "1grh841",
            "title": "Just wanted to let the AMD community know that I have achieved 20its/sec on a 6900xt.",
            "author": "plansoftheuniverse",
            "score": 58,
            "upvotes": 58,
            "downvotes": 0,
            "num_comments": 49,
            "created_utc": 1731623518.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/",
            "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/",
            "selftext": "So I for the longest time have been fiddling around with this damn thing, I can google things but everything takes me a while to sort out. Followed many different guides incl AMD's official Olive guide which did net 15-16it/s actually but was such a pain trying to figure out how to optimise models for Olive yada yada.\n\nToday, I got ZLUDA working in WEBUI. \n\n[https://forums.guru3d.com/threads/how-to-optimized-automatic1111-zluda-stable-diffusion-webui-on-amd-gpus.451861/](https://forums.guru3d.com/threads/how-to-optimized-automatic1111-zluda-stable-diffusion-webui-on-amd-gpus.451861/)\n\nThis is the guide I followed. For ZLUDA, there is no GFX1030 for my GPU. After much trawling through forums, I discovered that there's little to no difference between the platforms. So I used a GFX1031 or something and guys....\n\n20 it/s.   \n\n\nUpscaling is still slow though, multiple channels run some say 3it/s and others 10 and others 20. No idea what's going on there. ",
            "comments": [
                {
                    "id": "lx69lm4",
                    "author": "lostinspaz",
                    "body": "\" I have achieved 20its/sec \"\n\nDoing what, specifically?\n\ndepending on model and settings, that may be impressive, or that may be trivial",
                    "score": 35,
                    "upvotes": 35,
                    "downvotes": 0,
                    "created_utc": 1731628089.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx69lm4/"
                },
                {
                    "id": "lx5wnlb",
                    "author": "pointermess",
                    "body": "Nice but...\n\n\n20it/s doing what? Which model? What resolution? How many steps? Would be nice if you could specify the settings... ",
                    "score": 72,
                    "upvotes": 72,
                    "downvotes": 0,
                    "created_utc": 1731623906.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx5wnlb/"
                },
                {
                    "id": "lx6zzhi",
                    "author": "criticalt3",
                    "body": "OP or anyone else wanting to generate on AMD hassle free, there are some [great guides here](https://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides) for pretty much every UI I believe. \n\nEnjoy",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731636947.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6zzhi/"
                },
                {
                    "id": "lx62eu6",
                    "author": "iDeNoh",
                    "body": "SDNext has supported (and has been the primary platform for development on) zluda since right after zluda 3.0 dropped.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731625732.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx62eu6/"
                },
                {
                    "id": "lx6mg85",
                    "author": "hiper2d",
                    "body": "Thank you for the guide. I was using Flux on Runpod GPU but then I realized that my 6850 xt is not completelly useless for AI",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731632374.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6mg85/"
                },
                {
                    "id": "lx9holv",
                    "author": "The-Reaver",
                    "body": "I have Zluda 6800xt Comfy ui, bemyPONY checkpoint 30 steps 7 cfg scale, no upscale, 1024x1280, takes about 20 sec to generate.\n\nHighest I've seen it gi was maybe 5it/sec but it's still fast af lol",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731678718.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx9holv/"
                },
                {
                    "id": "lx6yvzt",
                    "author": "yamfun",
                    "body": "Wait that is slower than a cheaper 4070ti?",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731636574.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6yvzt/"
                },
                {
                    "id": "lx7j9np",
                    "author": "charmander_cha",
                    "body": "I have no problems with my AMD card.\n\nI just don't rely on time, I do things calmly, there's no need to rush.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731643708.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7j9np/"
                },
                {
                    "id": "lx8vcc3",
                    "author": "Samurai_zero",
                    "body": "Can you try Flux fp8 and check how many it/s you get on a 1024x1024 image on average?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731669140.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx8vcc3/"
                },
                {
                    "id": "lxbqwj0",
                    "author": "MayorWolf",
                    "body": "Zluda has an expiry date.  It will no longer work past major driver and library updates.  It works right now, while it is still compatible with current tools.  \n\nAMD's legal team killed ZLUDA and the AMD layers that exist now are all that will ever exist.  \n\nConsider this when buying your next GPU for ML reasons. AMD doesn't care about how their customers use their cards and actively limit options.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731703570.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxbqwj0/"
                },
                {
                    "id": "lx6ytmt",
                    "author": "criticalt3",
                    "body": "Yeah ZLUDA is great. Leather jacket babies will come in here and say image generation sucks on AMD or call you a liar or doubt you but it is what it is. They can't handle not being special and the only ones that can generate images.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731636552.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6ytmt/"
                },
                {
                    "id": "lx6kxbd",
                    "author": "daHaus",
                    "body": ">So I for the longest time have been fiddling around with this damn thing,\n\nThis is why I can't recommend AMD GPUs, they're the only OEM I've ever seen help their competitors by nerfing their own products. It's better to just buy from a company that respects your time instead.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731631863.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6kxbd/"
                },
                {
                    "id": "lx6wdn9",
                    "author": "Kmaroz",
                    "body": "Thats faster than my 2070s. I think.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731635734.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6wdn9/"
                },
                {
                    "id": "lx6c7hy",
                    "author": "yamfun",
                    "body": "AMD bro still tinkering for SD1.5?  That is just sad, and why don't buy AMD",
                    "score": -11,
                    "upvotes": -11,
                    "downvotes": 0,
                    "created_utc": 1731628948.0,
                    "parent_id": "t3_1grh841",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6c7hy/"
                },
                {
                    "id": "lx8m055",
                    "author": "EdgeLordwhy",
                    "body": "Sd 1.5, webui\n\n1girl, huge breasts\n\nPeak prompting",
                    "score": 17,
                    "upvotes": 17,
                    "downvotes": 0,
                    "created_utc": 1731663568.0,
                    "parent_id": "t1_lx69lm4",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx8m055/"
                },
                {
                    "id": "lx61gud",
                    "author": "SeymourBits",
                    "body": "Looks like SD1.5 on Automatic1111, based on the link.",
                    "score": 20,
                    "upvotes": 20,
                    "downvotes": 0,
                    "created_utc": 1731625425.0,
                    "parent_id": "t1_lx5wnlb",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx61gud/"
                },
                {
                    "id": "lx6zd1w",
                    "author": "plansoftheuniverse",
                    "body": "I shalt be checking that out shortly! Cheers bud",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731636731.0,
                    "parent_id": "t1_lx62eu6",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6zd1w/"
                },
                {
                    "id": "lxbqenk",
                    "author": "NanoSputnik",
                    "body": "This is very slow. Slower than 3060. ",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731703417.0,
                    "parent_id": "t1_lx9holv",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxbqenk/"
                },
                {
                    "id": "lxbrspa",
                    "author": "NanoSputnik",
                    "body": "Slower than same price nVidia GPUs, basically untrainable, consumes more VRAM and pain in the ass to install. But if it helps you to feel the rebel why not?",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731703843.0,
                    "parent_id": "t1_lx6ytmt",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxbrspa/"
                },
                {
                    "id": "lx6zg18",
                    "author": "criticalt3",
                    "body": "Just because OP didn't do research doesn't mean it takes everyone hours to set stuff up. Took me about 15 minutes to get ComfyUI going and generating 2560x1440 images in less than a minute.",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731636759.0,
                    "parent_id": "t1_lx6kxbd",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6zg18/"
                },
                {
                    "id": "lx702hm",
                    "author": "plansoftheuniverse",
                    "body": "AMD has made some questionable decisions over the years, however as I said in another comment, I love supporting the underdog.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731636975.0,
                    "parent_id": "t1_lx6kxbd",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx702hm/"
                },
                {
                    "id": "lx71hdj",
                    "author": "Slippedhal0",
                    "body": "AMD has Amuse. its not as flexible as other software in terms of models and options but its plug and play for supported cards, 1 click installer and works super well.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731637466.0,
                    "parent_id": "t1_lx6kxbd",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx71hdj/"
                },
                {
                    "id": "lx6l86l",
                    "author": "seraphinth",
                    "body": "Nah let amd bros cook. Ngreedia needs competition otherwise we'll only have slower apple m4's to turn to when a model needs more than 24gb of vram.",
                    "score": 27,
                    "upvotes": 27,
                    "downvotes": 0,
                    "created_utc": 1731631965.0,
                    "parent_id": "t1_lx6c7hy",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6l86l/"
                },
                {
                    "id": "lx6z1qn",
                    "author": "criticalt3",
                    "body": "Generating SDXL and stuff just fine here, don't know what crack you're smoking to come up with this.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731636627.0,
                    "parent_id": "t1_lx6c7hy",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6z1qn/"
                },
                {
                    "id": "lx6wxla",
                    "author": "zzulus",
                    "body": "What is currently the most popular base model?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731635919.0,
                    "parent_id": "t1_lx6c7hy",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6wxla/"
                },
                {
                    "id": "lx6zmsa",
                    "author": "plansoftheuniverse",
                    "body": "I don't think I would ever buy Nvidia for the same reasons I wouldn't buy an iPhone and why I am put off of Samsung phones even though they might be great. \n\nI love rooting for the underdog.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731636825.0,
                    "parent_id": "t1_lx6c7hy",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx6zmsa/"
                },
                {
                    "id": "lx975jq",
                    "author": "StrangeAlchomist",
                    "body": "That’s still pretty decent. I was struggling to get more than five on a 7900xtx a few months back",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731674724.0,
                    "parent_id": "t1_lx61gud",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx975jq/"
                },
                {
                    "id": "lxc45nv",
                    "author": "The-Reaver",
                    "body": "Yes, that is what's \"funny\". I don't get it how I'm loading in like 10 different loras, very long detailed prompt and SDXL but it is still \"fast\".\n\n\nAs a reference to \"fast\", I was previously running xformer confyui, it would even run SDXL, for SD 1.5 it took minutes per generation 512x768 res. \n\nAny ideas what or why this might be? The slow generations I mean, help is appreciated!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731707622.0,
                    "parent_id": "t1_lxbqenk",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxc45nv/"
                },
                {
                    "id": "lxbscic",
                    "author": "criticalt3",
                    "body": "Just shows how uneducated you are.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704010.0,
                    "parent_id": "t1_lxbrspa",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxbscic/"
                },
                {
                    "id": "lx7ywtq",
                    "author": "r-daddy",
                    "body": "I don't believe you.. how??",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731650498.0,
                    "parent_id": "t1_lx6zg18",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7ywtq/"
                },
                {
                    "id": "lx7aqsg",
                    "author": "yamfun",
                    "body": "I smoke the \"I switched from AMD Rx6xxx series to NV and the image gen life became so much better\" crack",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731640679.0,
                    "parent_id": "t1_lx6z1qn",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7aqsg/"
                },
                {
                    "id": "lx79zwd",
                    "author": "yamfun",
                    "body": "In this area, AMD is the worse price-performance-ratio product (like, the reverse of the gaming gpu purchase mindset), so the iPhone Android analogy is not too correct.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731640416.0,
                    "parent_id": "t1_lx6zmsa",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx79zwd/"
                },
                {
                    "id": "lxcdm5y",
                    "author": "NanoSputnik",
                    "body": "Prompt length does not affect SDXL generation speed, and comfy is very effective with loras. It will patch the model on the fly and subsequent generations will use cached patched model. I also think that latest comfy doesn't use xformers at all. It uses torch's cross attention. As for the AMD I afraid I can't give any advice aside from following exactly installation steps from comfy's github readme. Basically all you need is specific command to install torch with rocm support. At least on Linux.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731710719.0,
                    "parent_id": "t1_lxc45nv",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxcdm5y/"
                },
                {
                    "id": "lx80qpg",
                    "author": "ang_mo_uncle",
                    "body": "Idk how complex a windows setup is, but Linux is literally just installing Rocm (which is simple), installing comfy/forge and potentially installing Pytorch.\n\n\nI'd say you spend about 90% just waiting for the downloads of Rocm and Pytorch.",
                    "score": 8,
                    "upvotes": 8,
                    "downvotes": 0,
                    "created_utc": 1731651416.0,
                    "parent_id": "t1_lx7ywtq",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx80qpg/"
                },
                {
                    "id": "lx8bl3q",
                    "author": "newbie80",
                    "body": "Super easy if the distribution has rocm in it's repos. On fedora you'd be up and running in like 10 minutes. install rocm, create python virtual env, git clone whatever interface you want, install the requirements, install rocm versions of pytorch, then just run it.\n\nNot sure how fast compared to nvidia equivalent. I'm getting about 3it/s on sdxl models at 1024\\*1024. About 7 seconds per generation. 45 seconds for flux dev, 8 seconds for schnell.\n\nDon't have the latest and greatest, just settled for something stable. python 3.10, pytorch 2.3, pytorch rocm6.0. rocm 6.2.1 on the system. Should get a boost on newer software, but my setup is stable, no crashes.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731657290.0,
                    "parent_id": "t1_lx7ywtq",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx8bl3q/"
                },
                {
                    "id": "lx9bbkq",
                    "author": "criticalt3",
                    "body": "With ZLUDA. Works under windows as well. \n\nhttps://github.com/CS1o/Stable-Diffusion-Info/wiki/Webui-Installation-Guides",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731676369.0,
                    "parent_id": "t1_lx7ywtq",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx9bbkq/"
                },
                {
                    "id": "lx7c4pg",
                    "author": "criticalt3",
                    "body": "User error",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731641173.0,
                    "parent_id": "t1_lx7aqsg",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7c4pg/"
                },
                {
                    "id": "lxebdrq",
                    "author": "The-Reaver",
                    "body": "Yeah, problem is, I'm on windows and this is the fastest speed I can get. If I was to use Linux I would get majestic It/s but it's just a pain in the ass to dual boot windoes and Linux plus idk anything abut using Linux so there's that lol  \n\nI guess I'll have to wait for windoes rocm support...",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731739390.0,
                    "parent_id": "t1_lxcdm5y",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxebdrq/"
                },
                {
                    "id": "lxb9ejb",
                    "author": "omgitzgb",
                    "body": "its a simple install on windows lol… like a minute ._.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698201.0,
                    "parent_id": "t1_lx80qpg",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxb9ejb/"
                },
                {
                    "id": "lx9pyfu",
                    "author": "r-daddy",
                    "body": "That's what I have currently but even a 512x512 takes like two minutes using a 7900 XT. Might have to install everything from scratch or just adjust my workflow.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731681550.0,
                    "parent_id": "t1_lx9bbkq",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx9pyfu/"
                },
                {
                    "id": "lx7dc20",
                    "author": "yamfun",
                    "body": "For example, does bitsandbytes-rocm work nowadays?",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731641599.0,
                    "parent_id": "t1_lx7c4pg",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7dc20/"
                },
                {
                    "id": "lxb9u52",
                    "author": "omgitzgb",
                    "body": "Thats brutal",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731698332.0,
                    "parent_id": "t1_lx9pyfu",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxb9u52/"
                },
                {
                    "id": "lxbg5rq",
                    "author": "paypahsquares",
                    "body": "Should absolutely be getting way way better speeds even at 1024x1024 with that. I would [give SD.Next a try following this](https://github.com/vladmandic/automatic/wiki/ZLUDA).\n\n//e: don't bother with Deepcache at the bottom tho",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731700292.0,
                    "parent_id": "t1_lx9pyfu",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lxbg5rq/"
                },
                {
                    "id": "lx7e4dt",
                    "author": "criticalt3",
                    "body": "I've got no clue what that even is. I just generate images easily and quickly on an AMD GPU.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731641869.0,
                    "parent_id": "t1_lx7dc20",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7e4dt/"
                },
                {
                    "id": "lx7r78i",
                    "author": "yamfun",
                    "body": "yeah so you are just a light user who don't realize what amd is missing",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731646914.0,
                    "parent_id": "t1_lx7e4dt",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7r78i/"
                },
                {
                    "id": "lx7ry4k",
                    "author": "criticalt3",
                    "body": "Or you probably tried to setup something janky, and when it didn't work, blamed your hardware instead of your lack of intelligence, then bent your knee to ngreedia like every other knuckle dragger with more money than sense. \n\nRocm is an AMD thing btw. And it works fine for me in every model from sd1.5 to flux.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731647239.0,
                    "parent_id": "t1_lx7r78i",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7ry4k/"
                },
                {
                    "id": "lx7t097",
                    "author": "yamfun",
                    "body": "Young grasshopper you don't even know what bitsandbytes is and it is just one of the example. When you need to do more advance stuff and realize the lack of amd support everywhere from the amd itself and in the community, you will understand one day instead of insulting me and your future self.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731647711.0,
                    "parent_id": "t1_lx7ry4k",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7t097/"
                },
                {
                    "id": "lx7t2fx",
                    "author": "criticalt3",
                    "body": "Lmao",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731647736.0,
                    "parent_id": "t1_lx7t097",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7t2fx/"
                },
                {
                    "id": "lx7tpco",
                    "author": "criticalt3",
                    "body": "Looks like it's related to LLMs and not image generation so are you trying to strawman your way into something that no one was speaking of that is unrelated? \nI have a LLM running on my machine btw and it was an effortless setup. \nIf it is used for image generation then it seems I was right, you were trying to setup something janky. ZLUDA is right there if you're trying to emulate CUDA functions. \n\nSeems like you are a person with no troubleshooting experience. Hope things go better for you though.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731648029.0,
                    "parent_id": "t1_lx7t097",
                    "link_id": "t3_1grh841",
                    "permalink": "/r/StableDiffusion/comments/1grh841/just_wanted_to_let_the_amd_community_know_that_i/lx7tpco/"
                }
            ]
        },
        {
            "id": "1greequ",
            "title": "Help to run the restoration node in ComfyUI for bringing old photos back to life",
            "author": "PreferenceRich537",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731616158.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1greequ/help_to_run_the_restoration_node_in_comfyui_for/",
            "permalink": "/r/StableDiffusion/comments/1greequ/help_to_run_the_restoration_node_in_comfyui_for/",
            "selftext": "Hello all,\n\nI am new to using ComfyUI. I am trying to run this workflow [https://github.com/cdb-boop/ComfyUI-Bringing-Old-Photos-Back-to-Life](https://github.com/cdb-boop/ComfyUI-Bringing-Old-Photos-Back-to-Life)? to restore some old photos.\n\nHere, I am trying to install all requirements with requirements.txt, cmake, dlib, and all checkpoints. It has been 10 days of attempts to install, but I have failed repeatedly. I have searched multiple videos on YouTube, but none provide a step-by-step installation guide.\n\nCould anyone please help me?\n\nI am using the portable version of Comfyui on Windows 11. My python version is 3.10.15.\n\nhttps://preview.redd.it/8f4sl7mpfx0e1.png?width=1405&format=png&auto=webp&s=b4bebc8136a5a2a1b617219a10f2bae1689b21cb\n\nhttps://preview.redd.it/hi7b2m4qfx0e1.png?width=1917&format=png&auto=webp&s=340fbab973b1e27f98c959fd601b53354b6173d8\n\nhttps://preview.redd.it/eflx17kqfx0e1.png?width=876&format=png&auto=webp&s=9ce99bccfd53ae543c4615e64226490b552722bf\n\nhttps://preview.redd.it/yr67sdbrfx0e1.png?width=1891&format=png&auto=webp&s=1423001c01e412d9d071810f66182e85ca833594\n\n",
            "comments": [
                {
                    "id": "lx8axiw",
                    "author": "lothariusdark",
                    "body": "Did you install dlib into comfyuis python environment or simply into your system python?\n\n\nBecause comfyui won't find it if its in your system python, that's on purpose though and good to prevent problems.\n\n\nYou need to start the virtual environment in the terminal first, not sure how to do it with comfyui portable though, haven't used windows in years.\n\n\nAlso, post errors as Text, ideally as a code block. Reddit has a setting for it when writing.\nTrying to diagnose from screenshots sucks. No one wants to type out package versions if they could just be copied..",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731656918.0,
                    "parent_id": "t3_1greequ",
                    "link_id": "t3_1greequ",
                    "permalink": "/r/StableDiffusion/comments/1greequ/help_to_run_the_restoration_node_in_comfyui_for/lx8axiw/"
                }
            ]
        },
        {
            "id": "1greme7",
            "title": "M4 Pro 48GB Benchmarks for Stable Diffusion?",
            "author": "Ocabrah",
            "score": 12,
            "upvotes": 12,
            "downvotes": 0,
            "num_comments": 49,
            "created_utc": 1731616706.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/",
            "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/",
            "selftext": "I've been playing around with SD on my Macbook Pro with an M1 Pro chip and 16GB of RAM and an image takes about 5mins to generate when using A1111 with HighRes fix and ADetailer and I'm wondering how long this would take on an M4 Pro chip.\n\n\nI know, I know, build a PC and get a NVIDIA card with as much VRAM as possible but I could upgrade my laptop to an M4 Pro with 48GB of unified RAM for about $2000, not sure if I could build a PC with a 3090 for that much unless I risk buying used on Facebook Marketplace.\n\n Also, I would rather just have a single computer for everything as I also do music production.",
            "comments": [
                {
                    "id": "lx5cbbb",
                    "author": "Hot_Principle_7648",
                    "body": "flux dev fp16, 1024x1024, euler, 28 steps at 6 mins 20 secs on a m4 pro 64GB on comfy",
                    "score": 37,
                    "upvotes": 37,
                    "downvotes": 0,
                    "created_utc": 1731617654.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5cbbb/"
                },
                {
                    "id": "lx5y3fu",
                    "author": "Whispering-Depths",
                    "body": "I picked up an RMA'ed 3090ti from a retailer for 700 usd, so uh...\n\n(it works flawlessly, 4it/s/image 1024x1024 using SDXL in a batch of 8), 2.4~ it/s for single-image 1mp",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731624357.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5y3fu/"
                },
                {
                    "id": "lx5fev0",
                    "author": "Mutaclone",
                    "body": "If you're planning on sticking with a Mac I'd definitely recommend downloading [DrawThings](https://apps.apple.com/us/app/draw-things-ai-generation/id6444050820).  I don't know how well the built-in face restorer compares to ADetailer, but the render speed should be much faster at least.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731618600.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5fev0/"
                },
                {
                    "id": "lx72suc",
                    "author": "One-Turk",
                    "body": "I bought the M3 Max 48GB to be mobile and do some Stable diffusion stuff, I wanted to retire my desktop. Long story short I ended up buying a 4080 Super :D",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731637922.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx72suc/"
                },
                {
                    "id": "lx7qjkm",
                    "author": "Kmaroz",
                    "body": "48GB RAM not gonna help. The key is Nvidia GPU that fully optimised for Stable Diffusion. You dont need 3090, even lower PC with 2070S can generate image in less than 20 seconds.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731646630.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx7qjkm/"
                },
                {
                    "id": "lx5c46r",
                    "author": "BUF11",
                    "body": "Picking up a 2nd hand 3090 is the best decision I ever made. Going forwards I want to find a website where you can make virtual windows PCs with 4090 or better though, but can't work out any website to do it.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731617593.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5c46r/"
                },
                {
                    "id": "lx5og86",
                    "author": "A_dot_Powell",
                    "body": "Yeah, I was seeing the same results and just bought a computer from eBay(I needed to update a server anyway).",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731621367.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5og86/"
                },
                {
                    "id": "lx8gbdl",
                    "author": "korutech-ai",
                    "body": "With same spec M1 SDXL no detailer images take about 1min. \nSDXL on 7900XTX with control net, stacked LoRAs and upscale takes about 20-30s. \n\nI’ll try to do a better side by side with the same workflow. I’m curious how much better the M4 pro or max performs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731660087.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx8gbdl/"
                },
                {
                    "id": "lx5nayu",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/qzprsne4ux0e1.png?width=1920&format=png&auto=webp&s=32c6ca886d3b2f0f7cd20928fa3cb3b2bbc1621d\n\nMaking 3840x2160 wallpapers from a simple prompt 'Bikini Car Wash' takes a few minutes, but always worth the wait.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731621017.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5nayu/"
                },
                {
                    "id": "lx90iq2",
                    "author": "jtufff",
                    "body": "Don't burn me for suggesting this, but is eGPU an option for a Mac? Not sure how they perform for SD...",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731671773.0,
                    "parent_id": "t3_1greme7",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx90iq2/"
                },
                {
                    "id": "lx5kii4",
                    "author": "MMAgeezer",
                    "body": "Big oof. Thanks for testing.",
                    "score": 13,
                    "upvotes": 13,
                    "downvotes": 0,
                    "created_utc": 1731620161.0,
                    "parent_id": "t1_lx5cbbb",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5kii4/"
                },
                {
                    "id": "lx5e94t",
                    "author": "Designer-Pair5773",
                    "body": "Thats so sad to read 😮‍💨",
                    "score": 28,
                    "upvotes": 28,
                    "downvotes": 0,
                    "created_utc": 1731618246.0,
                    "parent_id": "t1_lx5cbbb",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5e94t/"
                },
                {
                    "id": "lx5fvax",
                    "author": "Ocabrah",
                    "body": "So not that much better huh. Well, I might have to go all in on a new build... Thanks.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731618738.0,
                    "parent_id": "t1_lx5cbbb",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5fvax/"
                },
                {
                    "id": "lx6yjqt",
                    "author": "Steven_Strange_1998",
                    "body": "What about of draw things?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731636458.0,
                    "parent_id": "t1_lx5cbbb",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx6yjqt/"
                },
                {
                    "id": "lxdr0ce",
                    "author": "don1138",
                    "body": "Ouch! 🥵",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731729506.0,
                    "parent_id": "t1_lx5cbbb",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxdr0ce/"
                },
                {
                    "id": "lx61t5v",
                    "author": "darth_chewbacca",
                    "body": "For reference on a 7900xtx\n\n> 4it/s/image 1024x1024 using SDXL\n\n3.22it/s/image on my rig.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731625535.0,
                    "parent_id": "t1_lx5y3fu",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx61t5v/"
                },
                {
                    "id": "lx71cac",
                    "author": "donjulioanejo",
                    "body": "I mean, you still need a PC to put it into, with enough power and CPU not to bottleneck anything.\n\nEven if you get barebones everything, that's still like $800 minimum.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731637418.0,
                    "parent_id": "t1_lx5y3fu",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx71cac/"
                },
                {
                    "id": "lx5sm6z",
                    "author": "Aberracus",
                    "body": "Krita Ai !!!",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731622648.0,
                    "parent_id": "t1_lx5fev0",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5sm6z/"
                },
                {
                    "id": "lx6cn05",
                    "author": "TwistedBrother",
                    "body": "The face restorer is rubbish and busted. There’s scripts on the GitHub for adetailer though.\n\nAnd Draw Things has really good performance on my m2 16gb. Probably at least 1/2 the time of Comfy if not more. I just gave up on Comfy. \n\nIt has 8-bit and bits and bytes flux dev and schnell models out of the box.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731629093.0,
                    "parent_id": "t1_lx5fev0",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx6cn05/"
                },
                {
                    "id": "lx5ggkv",
                    "author": "Ocabrah",
                    "body": "What are your times for 512x512, 30 steps,euler or Kerras on the 3090 if you don't mind me asking?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731618917.0,
                    "parent_id": "t1_lx5c46r",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5ggkv/"
                },
                {
                    "id": "lx7bluy",
                    "author": "None",
                    "body": "[deleted]",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731640987.0,
                    "parent_id": "t1_lx5c46r",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx7bluy/"
                },
                {
                    "id": "lxahgw8",
                    "author": "thefi3nd",
                    "body": "You should be able to do this with Paperspace. For the more powerful GPUs you'll need to request access the first time.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731689898.0,
                    "parent_id": "t1_lx5c46r",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxahgw8/"
                },
                {
                    "id": "lx5pjqe",
                    "author": "Ocabrah",
                    "body": "Yeah sounds like that's the best way to go about it. I was looking for mini PCs to use as a Jellyfin server and backups, might as well just roll everything into a single build.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731621703.0,
                    "parent_id": "t1_lx5og86",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5pjqe/"
                },
                {
                    "id": "lx5nlwg",
                    "author": "RO4DHOG",
                    "body": "https://preview.redd.it/5bdsxtmiux0e1.png?width=1920&format=png&auto=webp&s=cdd830e8b6a3bcbf77dce158c757993bf99f0b21\n\nI like 'Monster Trucks Sunset Desert' too.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731621111.0,
                    "parent_id": "t1_lx5nayu",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5nlwg/"
                },
                {
                    "id": "lx5oga0",
                    "author": "Ocabrah",
                    "body": "Nice. Have you tried any of the video generators?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731621368.0,
                    "parent_id": "t1_lx5nayu",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5oga0/"
                },
                {
                    "id": "lx9xrg0",
                    "author": "moofunk",
                    "body": "eGPUs are not supported for ARM based Macs.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731684023.0,
                    "parent_id": "t1_lx90iq2",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx9xrg0/"
                },
                {
                    "id": "lxbe3sz",
                    "author": "luchobe",
                    "body": "Its a mac what you expected",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731699638.0,
                    "parent_id": "t1_lx5e94t",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxbe3sz/"
                },
                {
                    "id": "lx87v3l",
                    "author": "Valerian_",
                    "body": "even an RTX 4060 ti 16GB VRAM would go many times faster than that, you don't have to spend more than 2k to build a decent enough PC",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731655199.0,
                    "parent_id": "t1_lx5fvax",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx87v3l/"
                },
                {
                    "id": "lxbvazt",
                    "author": "garg",
                    "body": "https://www.reddit.com/r/LocalLLaMA/comments/1gqkyvp/m4_max_128gb_sounds_great_for_llms_but_wont_that/lx1k3kt/\n\nThis person is reporting 2 minutes on an m4 max. But still slower than his nvidia gpu",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731704909.0,
                    "parent_id": "t1_lx5fvax",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxbvazt/"
                },
                {
                    "id": "lx7335h",
                    "author": "Whispering-Depths",
                    "body": "I have a $250 AMD cpu and $120 1000 watt power supply with no issues, sometimes running 24/7, doesn't go over 65c on the card or 55c on the cpu ($80 dual-fan closed loop cpu cooler, 64 gig ddr4 ram was 200-something",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731638021.0,
                    "parent_id": "t1_lx71cac",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx7335h/"
                },
                {
                    "id": "lx5jga6",
                    "author": "chAzR89",
                    "body": "512x512 is peanuts for a 3090. Not using one myself but I would guess about 2 seconds\n\nEdit: my 4070 at 512x512 is between 10 and 12 it/s for comparison",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731619831.0,
                    "parent_id": "t1_lx5ggkv",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5jga6/"
                },
                {
                    "id": "lx71ja5",
                    "author": "donjulioanejo",
                    "body": "Not OP but I get about 2-3 seconds for that on a 3080 Ti",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731637485.0,
                    "parent_id": "t1_lx5ggkv",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx71ja5/"
                },
                {
                    "id": "lx68i0o",
                    "author": "Dekes1",
                    "body": "Using the full Flux Dev model, in batches of 4 images at a time,  euler-beta-30 steps at 1280x1024,  it takes 200-225 seconds on an overclocked 3090.  It's the way to go unless you can spring for a 4090. Sorry I don't have times for SD but it would definitely be even faster. ",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731627720.0,
                    "parent_id": "t1_lx5ggkv",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx68i0o/"
                },
                {
                    "id": "lx8y5s1",
                    "author": "BUF11",
                    "body": "Using what model? Using SDXL Turbo which is 512x512 you can do 60 images per minute (less than a second). Using SD 1.5 512x512 is probably 15-20 images per minute (3-4 seconds per image) but it has been a long time since I did that.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731670617.0,
                    "parent_id": "t1_lx5ggkv",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx8y5s1/"
                },
                {
                    "id": "lx87yfk",
                    "author": "BUF11",
                    "body": "\nNeither seem to be windows",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731655249.0,
                    "parent_id": "t1_lx7bluy",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx87yfk/"
                },
                {
                    "id": "lx8z6ep",
                    "author": "A_dot_Powell",
                    "body": "This is the one I bought. Running Ubuntu server, Plex,  an array of *arr applications, and ComfyUI. I bought the 3060 with 32GB of ram, because image generation is occasionally for blog posts although I have an account with Replicate for the JIC times (maxing myself out at $10.00 a month but I haven't reached that yet).\n\nFlux runs pretty well with the setup, but I find myself using Juggernaut more than anything and occasionally Dreamshaper. For me the newness of generations has worn off and I am spending more time fitting it into my workflow.\n\nhttps://www.ebay.com/itm/235392576248?mkcid=16&mkevt=1&mkrid=711-127632-2357-0&ssspo=S0916h1VQhe&sssrc=4429486&ssuid=z8zytvt-qpk&var=&widget_ver=artemis&media=COPY",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731671121.0,
                    "parent_id": "t1_lx5pjqe",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx8z6ep/"
                },
                {
                    "id": "lx6f08s",
                    "author": "zabique",
                    "body": "What is this gui called?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731629888.0,
                    "parent_id": "t1_lx5nlwg",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx6f08s/"
                },
                {
                    "id": "lx5sa0l",
                    "author": "RO4DHOG",
                    "body": "InfiniteZoom is quick and easy, but makes me dizzy.\n\nAnimatedDiff is also good, easy to use, and widely supported.\n\nDeforum was wonderful, especially with Batching, but It's always breaking somehow and takes more time to setup and get the results I expected.   Because starting over after seeing weirdness, could also be my early experience with INIT and CONTROLNET parameters.\n\nOnce I found Controlnet t2i-canny, t2i-depth adapters... I get clean, stable results as expected.\n\nhttps://preview.redd.it/bz7fmvvuyx0e1.png?width=3840&format=png&auto=webp&s=36ede04f619df44d5364faa8e8cdc9d17eba0f0a",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731622544.0,
                    "parent_id": "t1_lx5oga0",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx5sa0l/"
                },
                {
                    "id": "lx74e3v",
                    "author": "donjulioanejo",
                    "body": "Sure, but all in all, you need:\n\n* CPU - $250\n* Computer case - $100 cheapest options\n* RAM - $200 for 64 GB, can probably get this down to $100 for 32 GB\n* SSD - $100\n* At least some basic case fans - $50\n* PSU - $100\n* Monitor - $100\n* Mouse/keyboard - $50\n\nAgain this is like the barebones options for everything, and I still got like $850.\n\nWith a laptop, don't need any of this.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731638470.0,
                    "parent_id": "t1_lx7335h",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx74e3v/"
                },
                {
                    "id": "lx8y8a6",
                    "author": "BUF11",
                    "body": "1216x832 only for me!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731670653.0,
                    "parent_id": "t1_lx68i0o",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx8y8a6/"
                },
                {
                    "id": "lx6pqio",
                    "author": "RO4DHOG",
                    "body": "[GitHub - anapnoe/stable-diffusion-webui-ux: Stable Diffusion web UI UX](https://github.com/anapnoe/stable-diffusion-webui-ux)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731633506.0,
                    "parent_id": "t1_lx6f08s",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx6pqio/"
                },
                {
                    "id": "lx75gwv",
                    "author": "Whispering-Depths",
                    "body": "with a laptop, you cant do anything and it costs $2000 for remotely similar specs lol?",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731638837.0,
                    "parent_id": "t1_lx74e3v",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx75gwv/"
                },
                {
                    "id": "lx9ijbz",
                    "author": "Whispering-Depths",
                    "body": "the cool part about a cpu is you already have all that shite from years ago. \n\nwith an apple product, good luck lmfao",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731679019.0,
                    "parent_id": "t1_lx74e3v",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx9ijbz/"
                },
                {
                    "id": "lx75znz",
                    "author": "donjulioanejo",
                    "body": "Except it weighs 3.5 pounds, you can take it anywhere, work from anywhere (like your bed, your couch, the airplane, or a beach vacation), and don't need a ton of peripherals just to get to the login screen?\n\nSure, running AI is probably not the best case scenario for a laptop, since nVidia cards blow everything out of the water.\n\nBut for literally anything else, IMO a pimped out M4 Macbook Pro beats everything on the market if games/tools you need are compatible with Mac OS.\n\nMost people usually have a laptop for travel, couch, and basic computing.  Most people who need high performance usually also have a workstation desktop.  New Macs are honestly insane.  If some benchmarks are to be believed, the 40-core M4 Max has performance approaching an RTX 3080, except in a laptop form factor.  Yes, it costs $4k USD, but compare that to a $2000 desktop and a $2000 base model MBP, and you get the exact same price with the convenience of only having one system.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731639017.0,
                    "parent_id": "t1_lx75gwv",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx75znz/"
                },
                {
                    "id": "lx9aw5n",
                    "author": "UnhappyTreacle9013",
                    "body": "Individual Benchmarks of float calculations have literally no predictive information on AI performance.\n\nNo cuda cores means no cuda cores and a lot of models are simply optimized for cuda.\n\nNot hating on macs here (pricing especially for storage aside) but for AI stuff, a desktop keeps being the way to go.\n\nBut economically speaking, renting out gpus remotely or running models remotely is probably the best option - I mean you can at times get a A100 for <2 USD per min now... And with that you are at a power level that beats an hypothetical M4 max with dual 5090ti.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731676204.0,
                    "parent_id": "t1_lx75znz",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx9aw5n/"
                },
                {
                    "id": "lx9i93y",
                    "author": "Whispering-Depths",
                    "body": "yeah, except apple is trash, their hardware is trash, their design is trash, and it's all 10x the price of anything else with equivalent specs.\n\nYou spend $4k USD for an equivalent to a $900 usd desktop PC. They can claim whatever bullshit they want about their processor being as good as a 3080 - it's not, it costs 4x as much and is still useless sh!t, because it's apple.\n\na 3080 goes realistically for $500 usd tops, $430 really.\n\nSo, what you mean is \"go with apple, deal with ALL of their dumb stuff, horrible design, spend 4x the money, and get 1/4th the performance. Not even getting into how you can't really cool the damn thing or overclock reasonably.\n\n> Physics dictates that any GPU in a compact form factor without much cooling abilities, will never ever get anywhere close to a GPU that isn't constrained that way. That is never going to change. When a laptop catches up to performance level X of a current desktop-GPU, the then-most-recent desktop GPUs will be that much faster, again.\n\nIf you want a better experience in general, spend $3000 on a desktop pc and $1000 on a laptop, run your AI stuff on a real PC as a server when you're not at it and you get 10x the speed of an apple product plus a laptop that you don't have to plug in for 16 hours.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731678919.0,
                    "parent_id": "t1_lx75znz",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lx9i93y/"
                },
                {
                    "id": "lxazzd5",
                    "author": "donjulioanejo",
                    "body": "Please show on this Lenovo where the big, bad MacBook touched you..",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731695403.0,
                    "parent_id": "t1_lx9i93y",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxazzd5/"
                },
                {
                    "id": "lxd0gsl",
                    "author": "Whispering-Depths",
                    "body": "haha, if only you could use actual stats and something to prove that apple is somehow better, instead of resorting to sad insults directed at me.\n\nMac user response right here. Pure genius.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731719036.0,
                    "parent_id": "t1_lxazzd5",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxd0gsl/"
                },
                {
                    "id": "lxe0qx8",
                    "author": "donjulioanejo",
                    "body": "https://www.tomshardware.com/pc-components/cpus/apples-m4-max-is-the-single-core-performance-king-in-geekbench-6-m4-max-beats-the-core-ultra-9-285k-and-ryzen-9-9950x\n\nhttps://www.digitaltrends.com/computing/m4-max-chip-beats-nvidia-gpu/\n\nKeep in mind, this is a 3.5 pound laptop compared to a full desktop CPU.\n\nYes, these are synthetic benchmarks.  It simply hasn't been out long enough to get app-specific benchmarks like Lightroom, Premiere, gaming, Stable Diffusion, or for code compiling.\n\nARM in general is smoking x86 hard right now when looking at both raw performance, and performance per watt, though Linux/OSX app compatibility is (literally) years ahead of ARM compatibility for Windows.\n\n> and you get 10x the speed of an apple product plus a laptop that you don't have to plug in for 16 hours.\n\nLiterally not true unless you manage to get an A100 GPU or a $20k server CPU (and don't mind having a giant 2U blade sitting in your living room making jet engine sounds).\n\n> and is still useless sh!t, because it's apple\n\nFunny that every single tech company that isn't Microsoft (cause they make Windows) or IBM (lul are they even relevant?) uses Apple for their dev machines.\n\nIs Apple the right choice for everyone?  Of course not.  Finance guys live and die by their Excel.  Gaming is still 10x easier on Windows.  Most industrial and engineering programs are also Windows only.  But with the way Microsoft is going, it'll be a cold day in hell before I have Windows 11 running on anything.  My next PC will be either a full Linux build and I'll just have to commit to nVidia driver pain, or a pimped out Macbook Pro and I'll have to deal with only being able to play a quarter of my game library.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731733905.0,
                    "parent_id": "t1_lxd0gsl",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxe0qx8/"
                },
                {
                    "id": "lxe73nm",
                    "author": "Whispering-Depths",
                    "body": "You're comparing Apple's best chip to individual random cpu's and low tier nvidia gpu's.\n\nNow compare it to a 4090 - 10x speed on stable diffusion inference and training.\n\nRegardless of being slower, if it was faster it would still be crap as anything other than a server (and probably not even that because you'd probably be forced to install itunes on it as apple believes you are too stupid to know better how to use your own machine)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731737118.0,
                    "parent_id": "t1_lxe0qx8",
                    "link_id": "t3_1greme7",
                    "permalink": "/r/StableDiffusion/comments/1greme7/m4_pro_48gb_benchmarks_for_stable_diffusion/lxe73nm/"
                }
            ]
        },
        {
            "id": "1gre72l",
            "title": "How can I use local AI models like Stable Diffusion with my RX 6750 XT GPU? ",
            "author": "mahmudehmed",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 6,
            "created_utc": 1731615594.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/",
            "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/",
            "selftext": "I’m trying to get started with running some local AI models, like Stable Diffusion, on my machine. My GPU is an AMD RX 6750 XT (MECH 2). Most of the guides I find seem optimized for NVIDIA cards with CUDA, but I know that AMD GPUs can work with PyTorch using ROCm.\n\nDoes anyone have experience setting up PyTorch with ROCm on AMD GPUs?\n\nedit: I am using windows",
            "comments": [
                {
                    "id": "lx59km5",
                    "author": "omg_can_you_not",
                    "body": "To utilize ROCm, you'll need to install A1111 or Forge on Linux. Otherwise you can use [this](https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu) fork of A1111 which lets you use it with DirectML or zluda. It's gonna be slooooow though",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731616819.0,
                    "parent_id": "t3_1gre72l",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx59km5/"
                },
                {
                    "id": "lx5a6i5",
                    "author": "blobtrot",
                    "body": "Easy Diffusion has a Linux version [Easy Diffusion v3 | A simple 1-click way to create beautiful images on your computer, by installing Stable Diffusion. No dependencies or technical knowledge required](https://easydiffusion.github.io/)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731617003.0,
                    "parent_id": "t3_1gre72l",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx5a6i5/"
                },
                {
                    "id": "lx5cv5i",
                    "author": "mahmudehmed",
                    "body": "but what about windows",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731617820.0,
                    "parent_id": "t1_lx59km5",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx5cv5i/"
                },
                {
                    "id": "lx5ehtz",
                    "author": "omg_can_you_not",
                    "body": "The link I provided is compatible on windows.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731618320.0,
                    "parent_id": "t1_lx5cv5i",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx5ehtz/"
                },
                {
                    "id": "lx5lyyf",
                    "author": "mahmudehmed",
                    "body": "I tried that, but I keep getting a low VRAM error. I have 12GB of VRAM.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731620608.0,
                    "parent_id": "t1_lx5ehtz",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx5lyyf/"
                },
                {
                    "id": "lx6ndwm",
                    "author": "GreyScope",
                    "body": "Don't use directml, use zluda",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731632696.0,
                    "parent_id": "t1_lx5lyyf",
                    "link_id": "t3_1gre72l",
                    "permalink": "/r/StableDiffusion/comments/1gre72l/how_can_i_use_local_ai_models_like_stable/lx6ndwm/"
                }
            ]
        },
        {
            "id": "1grdh1i",
            "title": "Anyone have a trick for getting more adetailer tabs in Forge?",
            "author": "Datedman",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731613724.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grdh1i/anyone_have_a_trick_for_getting_more_adetailer/",
            "permalink": "/r/StableDiffusion/comments/1grdh1i/anyone_have_a_trick_for_getting_more_adetailer/",
            "selftext": "I got used to having a bunch in A1111, makes a big diff can use world/person/clothes/face/eyes and even run two different ones for eyes/face :)",
            "comments": [
                {
                    "id": "lx51gvj",
                    "author": "red__dragon",
                    "body": "Settings > Adetailer > Max tabs  (requires Reload UI)\n\nSet to your preferred number, apply setting, reload UI (or close Forge and the tab, and restart both).",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731614308.0,
                    "parent_id": "t3_1grdh1i",
                    "link_id": "t3_1grdh1i",
                    "permalink": "/r/StableDiffusion/comments/1grdh1i/anyone_have_a_trick_for_getting_more_adetailer/lx51gvj/"
                }
            ]
        },
        {
            "id": "1grd3s8",
            "title": "Is it possible to run Mochi on a Mac using the GPU?",
            "author": "fallingdowndizzyvr",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 2,
            "created_utc": 1731612769.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grd3s8/is_it_possible_to_run_mochi_on_a_mac_using_the_gpu/",
            "permalink": "/r/StableDiffusion/comments/1grd3s8/is_it_possible_to_run_mochi_on_a_mac_using_the_gpu/",
            "selftext": "When I try running Mochi on a Mac, I get that dreaded FP8 is not supported error. So I have to force it to use the CPU instead of MPS(GPU). That runs but it's so slow. Has anyone been able to run Mochi on a Mac using the GPU?",
            "comments": [
                {
                    "id": "lx64jgt",
                    "author": "a_beautiful_rhind",
                    "body": "Did you try a non fp8 quant?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731626422.0,
                    "parent_id": "t3_1grd3s8",
                    "link_id": "t3_1grd3s8",
                    "permalink": "/r/StableDiffusion/comments/1grd3s8/is_it_possible_to_run_mochi_on_a_mac_using_the_gpu/lx64jgt/"
                },
                {
                    "id": "lxb1bkh",
                    "author": "fallingdowndizzyvr",
                    "body": "I did. Nothing but black. And it still had to use the CPU.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731695797.0,
                    "parent_id": "t1_lx64jgt",
                    "link_id": "t3_1grd3s8",
                    "permalink": "/r/StableDiffusion/comments/1grd3s8/is_it_possible_to_run_mochi_on_a_mac_using_the_gpu/lxb1bkh/"
                }
            ]
        },
        {
            "id": "1grczfo",
            "title": "How to achieve consistency across images when there are multiple characters involved",
            "author": "Money-Chemist-6589",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731612467.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/",
            "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/",
            "selftext": "Hi, I tried both flux and Stable diffusion models, one thing i've noticed is, these models are struggling to maintain consistency when there is more than one character in the image, can anyone suggest if there's a way to achieve the consistency in images if there's more than one character in the image.\n\nThanks in advance",
            "comments": [
                {
                    "id": "lx4ysk2",
                    "author": "cosmicr",
                    "body": "Loras and Inpainting.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731613490.0,
                    "parent_id": "t3_1grczfo",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx4ysk2/"
                },
                {
                    "id": "lx54dry",
                    "author": "Same-Pizza-6724",
                    "body": "Things to try:\n\nRegional prompting add on\n\n(allows you to prompt in segments, for eg, left of image has blonde girl in dress, right of image has brunette in jeans)\n\nControlnet\n\n(Allows you to use a base image as a template, dictate poses, and other stuff.) \n\nCharacter lora\n\n(find or train a lora on the characters you want, probably best used with regional prompting for multiple characters) \n\nInpainting \n\n(send image to img2img inpaint, draw over bit you want to change, change prompt to required details, medium denoise)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731615214.0,
                    "parent_id": "t3_1grczfo",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx54dry/"
                },
                {
                    "id": "lx58thb",
                    "author": "littoralshores",
                    "body": "These regional attention nodes in comfy does it for me (see latest post on profile). The trick for me is to leave the settings at default and have the entire prompt and the same character prompt in the main prompt - and then each specific character as the prompt for each masked region. \n\nBut as others say inpainting is the backstop. \n\nhttps://github.com/ramyma/A8R8_ComfyUI_nodes",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731616586.0,
                    "parent_id": "t3_1grczfo",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx58thb/"
                },
                {
                    "id": "lx50zf7",
                    "author": "Money-Chemist-6589",
                    "body": "Hi, thanks for your suggestion!  \nActually my task is to generate images on the fly based on users inputs. Can i achieve with loras and inpainting??  \n  \nP.S: I'm a newbie",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731614159.0,
                    "parent_id": "t1_lx4ysk2",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx50zf7/"
                },
                {
                    "id": "lx5zhvi",
                    "author": "Money-Chemist-6589",
                    "body": "Thank you!  \nI'm accessing the models using Segmind API, and based on what you said I should probably try regional prompting and see if that works",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731624795.0,
                    "parent_id": "t1_lx54dry",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx5zhvi/"
                },
                {
                    "id": "lx5zpv1",
                    "author": "Money-Chemist-6589",
                    "body": "I'm using segmind's API to access the models, and me being a newbie I'm not sure how to work with comfi UI, but thanks for your suggestions.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731624867.0,
                    "parent_id": "t1_lx58thb",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx5zpv1/"
                },
                {
                    "id": "lx78kw2",
                    "author": "blank0007",
                    "body": "Use regional prompting + Lora + Inpainting",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731639918.0,
                    "parent_id": "t1_lx50zf7",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx78kw2/"
                },
                {
                    "id": "lx63vzc",
                    "author": "Same-Pizza-6724",
                    "body": "Yeah if you're trying to \"one shot\" your images then regional prompting is definitely worth a go.\n\nI'm not aware of Segmind, I use forge on my home laptop, but if it can do \"controlnet canny\", then that's honestly worth your time learning.\n\nFor eg, you can take a grey canvas, paste a cut out picture of a naked person, draw clothes on them with ms paint, literally being as sloppy as you want, and as long as you get the settings right and prompt correctly, then it does the rest.\n\nIts not perfect, requires a bit of experimenting and won't always produce what you want, but, well, it's essentially magic when you get it right.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731626207.0,
                    "parent_id": "t1_lx5zhvi",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx63vzc/"
                },
                {
                    "id": "lx680wf",
                    "author": "littoralshores",
                    "body": "Ah right. If you have a computer powerful enough to run offline models you have a ton more control with the different interfaces. Good luck!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731627564.0,
                    "parent_id": "t1_lx5zpv1",
                    "link_id": "t3_1grczfo",
                    "permalink": "/r/StableDiffusion/comments/1grczfo/how_to_achieve_consistency_across_images_when/lx680wf/"
                }
            ]
        },
        {
            "id": "1grcywi",
            "title": "Flux dev FP16 is faster than all other quants on dual GPU",
            "author": "g33khub",
            "score": 23,
            "upvotes": 23,
            "downvotes": 0,
            "num_comments": 35,
            "created_utc": 1731612430.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/",
            "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/",
            "selftext": "So I am noticing for a long time (about a month now) that the default [flux1.dev](https://huggingface.co/black-forest-labs/FLUX.1-dev/tree/main) model at 16 bits is faster on my 3090 than the fp8 quant, [8bit gguf ](https://huggingface.co/city96/FLUX.1-dev-gguf)quant and even 6bit gguf. Q5 is faster but at a big loss of quality so pointless. Is this behaviour normal? Can this be due to the BF16 support on Nvidia 3xxx, 4xxx?\n\nDefault 16 bit model: 1.15 s/it  \nFP8 quant (bad quality): 1.22 s/it  \n8bit gguf  (as good as default): 1.32 s/it  \n6bit gguf (worse quality): 1.2 s/it\n\n  \nNote: I do have a second GPU (4060Ti 16GB) which lets me load the t5\\_xxl and vae on it. The 3090 runs headless and I can fit the full model \\~23.54 GB. VRAM scales down in a normal way when I load the smaller quantized models but the speed of generation decreases :O",
            "comments": [
                {
                    "id": "lx4yez0",
                    "author": "red__dragon",
                    "body": "It's faster if you can fit the whole model in your VRAM. GGUFs are \"faster\" if you cannot, because while they load slower, they run without extra slowdowns from the CPU offloading different parts of the full model that would otherwise occur. \n\nIf you're getting <2s/its from the fp16 model on your GPU, then you aren't in need of the GGUFs. Those are for lower VRAM GPUs, like 12 GB and below. Use the right tool for the right job.",
                    "score": 32,
                    "upvotes": 32,
                    "downvotes": 0,
                    "created_utc": 1731613374.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx4yez0/"
                },
                {
                    "id": "lx4zxo8",
                    "author": "aikitoria",
                    "body": "It takes extra instructions to dequant the model, and flux is mostly compute bound. So a quant will make it slower.\n\nOnly exception is if you use fp8 on a 4090 and above as those GPUs have explicit fp8 instructions to speed it up.",
                    "score": 9,
                    "upvotes": 9,
                    "downvotes": 0,
                    "created_utc": 1731613839.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx4zxo8/"
                },
                {
                    "id": "lx53b45",
                    "author": "artificial_genius",
                    "body": "Have you been running it with lora's like that? Does it hit the 24gb limit on your's when you add lora's down the line? I'm pretty sure I was having the issue when I ran it fp16 that if I added loras it would hit my 24gb limit and crash.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731614880.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx53b45/"
                },
                {
                    "id": "lx5p6cc",
                    "author": "RO4DHOG",
                    "body": "I'm finding that an initial resolution like 960x540 with 20+ steps and then Hires upscaling 4x with 10 steps, produces good quality 4K images with 24GB VRAM in a minute or two, depending on the Sampler (DPM, Euler, or Huern, using Simple, Normal, or Karras).\n\nhttps://preview.redd.it/5uh4hv60wx0e1.png?width=1920&format=png&auto=webp&s=509f544285f64fe23ef9daffed04697e28bee853\n\nor 1280x720 and 3x upscale.",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731621589.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5p6cc/"
                },
                {
                    "id": "lx67cjc",
                    "author": "faffingunderthetree",
                    "body": "The gguf and nf4 and all that stuff isnt for you. I dont mean that in a rude way lol, but just that If you rocking a 3090 4090 etc, then they arent really relevant to you most the time. \nIt's for poors like me with 12gb or 16gb vram, and some even work well on 8gb, the nf4 is great for that",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731627340.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx67cjc/"
                },
                {
                    "id": "lx5o8jx",
                    "author": "a_beautiful_rhind",
                    "body": "It's BF16 but yea. Full model gives the fastest speeds. The only things that come close are quants that use custom cuda kernels, i.e awq marlin. The dev of that won't reply how he quantized the weights and never implemented lora. An 8-bit AWQ with kernel would probably equal speed/quality.\n\nIf GGUF was able to use some of the inference stuff from llama.cpp, like it's universal flash attention, then maybe it would be faster too. As of now, I think it only reads the format and users regular pytorch. All quants are slower for me. Q8 only slightly.\n\nNF4 was fairly fast too, but the quality was bad and nobody wanted to implement lora support either.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731621302.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5o8jx/"
                },
                {
                    "id": "lx66rv9",
                    "author": "faffingunderthetree",
                    "body": "How do you load the clip and vae to ram or other gpus in forge or is it a comfy only option",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731627149.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx66rv9/"
                },
                {
                    "id": "lx7iw8y",
                    "author": "wzwowzw0002",
                    "body": "0.1~0.2 sec mean no different for me",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731643571.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx7iw8y/"
                },
                {
                    "id": "lx8a86d",
                    "author": "jib_reddit",
                    "body": "It is known. I have a 3090 but run fp8 Flux just because if I have a few youtube tabs open in my browser it spills into system ram. I run the T5 Clip on the CPU.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731656521.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx8a86d/"
                },
                {
                    "id": "lx9s89l",
                    "author": "Additional-Song6292",
                    "body": "i have 4070 ti 12gb and like 300 browser tabs open and still bf16 is the fastest for me, little bit faster than fp8, and a quite faster than all of the ggufs. bf16 \\~1.20 s/it, fp8 is like 1.35s/it",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731682288.0,
                    "parent_id": "t3_1grcywi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx9s89l/"
                },
                {
                    "id": "lx5nx1s",
                    "author": "xSnoozy",
                    "body": "wait so gguf is actually slower if you can run at full precision?",
                    "score": 7,
                    "upvotes": 7,
                    "downvotes": 0,
                    "created_utc": 1731621205.0,
                    "parent_id": "t1_lx4yez0",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5nx1s/"
                },
                {
                    "id": "lx5ooac",
                    "author": "a_beautiful_rhind",
                    "body": "Depends on the lora. You can turn off cuda malloc, don't use highvram and use smaller res than 1024x1024.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731621436.0,
                    "parent_id": "t1_lx53b45",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5ooac/"
                },
                {
                    "id": "lx5wztg",
                    "author": "g33khub",
                    "body": "I could somehow fit 1 lora on the 3090 (23.8 GB) but my question above contain details all without any lora. 1024x1024  \nIf anything the 16 bit model would hit the memory limit and slow down (if offloaded to system ram). I was surprised that the 8 bits were slower while using \\~12GB. Anyway looks like this is due to the GPU architecture and \"less work to do while running native model\".  \nThey only reason I can get away with the full model is because of headless and Ubuntu maybe. Windows eat up some more idle vram.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731624012.0,
                    "parent_id": "t1_lx53b45",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5wztg/"
                },
                {
                    "id": "lx5lptt",
                    "author": "MMAgeezer",
                    "body": "Yes, you do not have much headroom with 24GB.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731620532.0,
                    "parent_id": "t1_lx53b45",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5lptt/"
                },
                {
                    "id": "lx7wtz2",
                    "author": "Igot1forya",
                    "body": "I've been getting around the LORA + Flux memory limits by merging my LORA into the Flux.d model. So I have a folder full of merged models that I choose from. The quality appears to be the same as calling out the LORA separately, at least for all the LORAs I author. It seems to never exceed 22GB even with 4 monitors on my desktop. Prior I was hitting 42GB with LORAs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731649485.0,
                    "parent_id": "t1_lx53b45",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx7wtz2/"
                },
                {
                    "id": "lx66z6p",
                    "author": "faffingunderthetree",
                    "body": "What the hell is this UI lol, reminds me of 2004 steam",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731627215.0,
                    "parent_id": "t1_lx5p6cc",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx66z6p/"
                },
                {
                    "id": "lx629o9",
                    "author": "narkelo",
                    "body": "Is this forgeUI?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731625686.0,
                    "parent_id": "t1_lx5p6cc",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx629o9/"
                },
                {
                    "id": "lx5zh3s",
                    "author": "g33khub",
                    "body": "are there any image models with AWQ?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731624788.0,
                    "parent_id": "t1_lx5o8jx",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5zh3s/"
                },
                {
                    "id": "lxa1m7a",
                    "author": "Perfect-Campaign9551",
                    "body": "I believe Comfy has a node to do it",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731685192.0,
                    "parent_id": "t1_lx66rv9",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxa1m7a/"
                },
                {
                    "id": "lxaxlel",
                    "author": "g33khub",
                    "body": "I'm doing it in comfy using a custom node which can set the model, lora, t5, vae to any device I choose.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731694701.0,
                    "parent_id": "t1_lx66rv9",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxaxlel/"
                },
                {
                    "id": "lx8daf3",
                    "author": "4lt3r3go",
                    "body": "how you choose to run t5 on cpu?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731658279.0,
                    "parent_id": "t1_lx8a86d",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx8daf3/"
                },
                {
                    "id": "lxc2tti",
                    "author": "g33khub",
                    "body": "how did you accomodate flux dev bf16? the model takes around 22 GB vram",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731707210.0,
                    "parent_id": "t1_lx9s89l",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxc2tti/"
                },
                {
                    "id": "lx5w4oi",
                    "author": "Old_System7203",
                    "body": "Yes. Using a gguf is like using a .zip file. It’s smaller, but it has to be decompressed when used. So it’s only faster if the size makes the difference to fitting in VRAM",
                    "score": 6,
                    "upvotes": 6,
                    "downvotes": 0,
                    "created_utc": 1731623742.0,
                    "parent_id": "t1_lx5nx1s",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5w4oi/"
                },
                {
                    "id": "lx5w8u4",
                    "author": "Samurai_zero",
                    "body": "Depends on wether you can fit the whole model in VRAM or not. IF you cannot, using a quant that fits in your VRAM will most likely be faster, but you trade precision (quality) for it. Also, some quants will be slower than others or slower than the full model in VRAM, because they are simply not as optimized.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731623778.0,
                    "parent_id": "t1_lx5nx1s",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5w8u4/"
                },
                {
                    "id": "lx5xomo",
                    "author": "g33khub",
                    "body": "I guess with 30 series yea. 40xx would perhaps be faster at 8bit too and the upcoming 50xx at 4 bit.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731624226.0,
                    "parent_id": "t1_lx5nx1s",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx5xomo/"
                },
                {
                    "id": "lx7u8oh",
                    "author": "artificial_genius",
                    "body": "I was kinda hoping someone had figured out how to offload them to another card or something. I've got these crazy big lora's like 5gb and it would be cool to run them full fp16 because of the two cards I have but it seems I can really only offload the t5 and clip but the checkpoint has to have the lora applied to it. No biggy because it's hard to tell the difference between 8bit and full fp16.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731648274.0,
                    "parent_id": "t1_lx5ooac",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx7u8oh/"
                },
                {
                    "id": "lxb9frr",
                    "author": "artificial_genius",
                    "body": "Very interesting, if I had more HD space I'd be doing it for a few of them. I've been fine-tuning them to rip the lora off, it didn't change the checkpoint size either.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731698211.0,
                    "parent_id": "t1_lx7wtz2",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxb9frr/"
                },
                {
                    "id": "lx6pv3m",
                    "author": "RO4DHOG",
                    "body": "[GitHub - anapnoe/stable-diffusion-webui-ux: Stable Diffusion web UI UX](https://github.com/anapnoe/stable-diffusion-webui-ux)",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731633549.0,
                    "parent_id": "t1_lx66z6p",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx6pv3m/"
                },
                {
                    "id": "lx63sry",
                    "author": "a_beautiful_rhind",
                    "body": "The previous marlin flux and now someone made this: https://github.com/mit-han-lab/nunchaku\n\nIts sad tho that the only people writing kernels in the SD community don't give a sh1t about compatibility and do ampere/ada only. Their paper does cite nvidia...\n\nalso, reddit has a swear filter now? https://i.imgur.com/AyLeXL2.png",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731626178.0,
                    "parent_id": "t1_lx5zh3s",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx63sry/"
                },
                {
                    "id": "lx8rus0",
                    "author": "jib_reddit",
                    "body": "In Comfyui It's called Force/Set CLIP Device from ExtraModels nodes:  \n[https://github.com/city96/ComfyUI\\_ExtraModels](https://github.com/city96/ComfyUI_ExtraModels)\n\nYou put it after the CLIP Loader\n\nhttps://preview.redd.it/zjnugk7hn11e1.png?width=1799&format=png&auto=webp&s=99339f1745e8a66215039b375b09504aa81850ed",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731667171.0,
                    "parent_id": "t1_lx8daf3",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx8rus0/"
                },
                {
                    "id": "lx8r80v",
                    "author": "stddealer",
                    "body": "> Using a gguf is like using a .zip file.\n\nThat's only true when the inference engine uses them as such. GGML is absolutely able to run most operations using gguf blocks directly, without needing to \"decompress\" it at all. That's how llama.cpp (and stable-diffusion.cpp) run them, and it's still slower than using native types like FP16, but not by much.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731666791.0,
                    "parent_id": "t1_lx5w4oi",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx8r80v/"
                },
                {
                    "id": "lx75dza",
                    "author": "Vaughn",
                    "body": "The 4090 is faster at fp8 than fp16, yeah, although the difference isn't huge. Though GGUF quants are again slower than fp8 *and* fp16.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731638810.0,
                    "parent_id": "t1_lx5xomo",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx75dza/"
                },
                {
                    "id": "lx8weqy",
                    "author": "a_beautiful_rhind",
                    "body": "Me too. A real multi-gpu would be nice.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731669712.0,
                    "parent_id": "t1_lx7u8oh",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lx8weqy/"
                },
                {
                    "id": "lxbwdqx",
                    "author": "Old_System7203",
                    "body": "I believe (but am happy to be corrected) that ggml is still having to decompress before doing matmul. It’s just doing it in cuda ops rather than c or python. I’m not aware of any matmul that work directly on quants other than 8 or 16 bit",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731705237.0,
                    "parent_id": "t1_lx8r80v",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxbwdqx/"
                },
                {
                    "id": "lxc4dq9",
                    "author": "stddealer",
                    "body": "The default GGML backend is written entirely in c++, there is no Cuda involved. And by glancing at this c++ code, I couldn't find an explicit conversion from quantized types to classic types in the function that computes matmul. But maybe I just missed it.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731707693.0,
                    "parent_id": "t1_lxbwdqx",
                    "link_id": "t3_1grcywi",
                    "permalink": "/r/StableDiffusion/comments/1grcywi/flux_dev_fp16_is_faster_than_all_other_quants_on/lxc4dq9/"
                }
            ]
        },
        {
            "id": "1grcozo",
            "title": "KeyError: 'created_at'",
            "author": "mapg10",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731611737.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grcozo/keyerror_created_at/",
            "permalink": "/r/StableDiffusion/comments/1grcozo/keyerror_created_at/",
            "selftext": "After upgrading the Browser +, I got this error message.\n\nAlready went into the file (config\\_states.py) and commented out that line, but didn't worked. is there a way to by-pass/Fix this?\n\n\\*\\*\\*\\*\\*\n\nFile \"C:\\\\ai\\\\stable-diffusion-webui\\\\modules\\\\config\\_states.py\", line 36, in <lambda>\n\nconfig\\_states = sorted(config\\_states, key=lambda cs: cs\\[\"created\\_at\"\\], reverse=True)\n\nKeyError: 'created\\_at'\n\n\\*\\*\\*\\*\\*",
            "comments": [
                {
                    "id": "lx4twnu",
                    "author": "mapg10",
                    "body": "I was able to figure it out:\n\nIn case someone else has this issue:\n\nGo to: \\\\stable-diffusion-webui\\\\config\\_states\n\nOpen the backup created, and paste it on the file: civitai\\_subfolders.json",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731611995.0,
                    "parent_id": "t3_1grcozo",
                    "link_id": "t3_1grcozo",
                    "permalink": "/r/StableDiffusion/comments/1grcozo/keyerror_created_at/lx4twnu/"
                }
            ]
        },
        {
            "id": "1grbqkr",
            "title": "I’m thinking of upgrading from a 7 year old 2gb vram gpu but….",
            "author": "B4N35P1R17",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 39,
            "created_utc": 1731609303.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/",
            "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/",
            "selftext": "My laptop is old and I want a new one specifically to run SD for generation and training models and LoRAs I’m fully aware of the hardware required and costs involved with such hardware, this is not a problem. \n\nMy problem comes when I read about people complaining that they get OOM errors and slow generations with 24gb vram gpu rigs. How is this possible? Are they trying to do too much with a generation or have they got their generation settings cranked up too high? \n\nI don’t want to shell out 4K or more for a laptop with an RTX4090 or something only to find that simple software gremlins inside SD prevent me from making full use of its capabilities. \n\nAs a basic SD enthusiast making simple image generations, not anything with insane scale, am I going to be making a good purchase or will it be overkill or just not worth it for something that high end?\n\nBelow I just wanted to include a little background on my SD adventure so people get an idea where I’ve come from. It’s not part of the question so it’s skipable lol.\n\nSo I installed SD a1111 on my potato 2gb vram gpu laptop as a bit of a joke just to see if it would run and if it did if I’d like it. Turns out it does run and that I’m utterly infatuated with it. \n\nI’ve gotten used to it taking 1-2 minutes to generate a single 768x512 image from a larger model. I’m used to setting up batch of 10 images while I’m sleeping as that can take up to an hour.\n\nI don’t run “medvram” or “lowvram” my testing shows that there’s no speed difference for how I use SD so it’s not worth it.\n\nI’ve got “xformers” in my args but I doubt it’s set up right because images take the same amount of time to generate with or without it. \n\nI mainly stick to smaller anime themed models and have merging turned up to max with an image size of 512x512 to get the fastest generations of around 30-40 seconds. I then put the ones I like into hires fix upscale while I’m asleep as that can take hour(s) depending on how big and pretty I want the end result.\n\nThe reason I want a better GPU is to make basic image generation faster, way faster! If I can generate 1 1024x1024 in seconds, see the results of my promotion until I get the results I want then upscale and batch generate in seconds or minutes that would be a dream come true.",
            "comments": [
                {
                    "id": "lx4m19g",
                    "author": "thevictor390",
                    "body": "Honestly a laptop for high powered compute tasks is both expensive and disappointing. It would be both cheaper and more powerful to build/buy a kickass desktop and buy normal laptop to operate it remotely. Or use an online service to rent GPU power.",
                    "score": 29,
                    "upvotes": 29,
                    "downvotes": 0,
                    "created_utc": 1731609593.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4m19g/"
                },
                {
                    "id": "lx4xgsl",
                    "author": "dkpc69",
                    "body": "Buy a second hand 2021 asus rog scar 17 with a rtx 3080 they have 16gb vram which is perfect for sd, flux takes 30-40 seconds per image, another option is a second hand Lenovo legion with a 16gb vram rtx 3080",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731613082.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4xgsl/"
                },
                {
                    "id": "lx4n53n",
                    "author": "a_beautiful_rhind",
                    "body": "Buy desktop and connect to it from your laptop over lan.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731609929.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4n53n/"
                },
                {
                    "id": "lx4pvd6",
                    "author": "DemoEvolved",
                    "body": "Hey so look you will do better with a new laptop, but laptop diffusion is not at all where it’s at. You have all sorts of limitations like heat throttling, and Eve though the number on the chip is the same, laptop chips are not parity with desktop chips of the same number, not by a lot. So yeah, upgrading will help your situation but honestly I must counsel you to go desktop if you want to do stable diffusion and especially if you want to do video diffusion",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731610757.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4pvd6/"
                },
                {
                    "id": "lx53xrn",
                    "author": "moofunk",
                    "body": "Out of all that, you probably can get a laptop that will give you 4x the performance, but not more than that, if your finances and mobility are so particularly restricted.\n\nAnother alternative is to get a server account, like RunPod, where you pay a little bit for access to top end hardware to run Stable Diffusion on.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731615076.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx53xrn/"
                },
                {
                    "id": "lx5bvwo",
                    "author": "mv_squared",
                    "body": "Use AWS. Ec2 instance with any range of gpus you want. It’ll cost you like a dollar an hour or something. You can keep upgrading your gpu as the tech progresses.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731617523.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5bvwo/"
                },
                {
                    "id": "lx5cfo3",
                    "author": "_roblaughter_",
                    "body": "If all you want to do is generate images, 8 or 10 GB of VRAM should be enough for most models if you have enough RAM to offload components. My desktop is a 3080 with 10 GB VRAM and 64 GB RAM, and I can generate images with any current gen model. \n\nThe questions are:\n\n1. You mention training LoRAs. You can technically do it on cards with less VRAM with quantization, but it’s far slower. If you HAVE TO train your LoRAs locally, you’re going to want higher VRAM. Personally, I just spin up a GPU on Runpod if I have a high VRAM application. \n\n2. Anything other than images. If you want to run video models, LLMs, etc, they’re far hungrier than image models. You’ll want as much VRAM as possible. \n\n3. Future models. Current models are pushing the limits of current gen mid-range specs. The jump from SDXL to SD 3.5/Flux was substantial. If you’re investing now and want to plan for the future, you may want more VRAM. \n\nAs others have mentioned, desktops are more cost effective and more powerful than their mobile equivalents, and it’s stupid simple to set up a Comfy instance on a home PC and connect either with Remote Desktop or, my preference, using a free Tailscale VPN.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731617690.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5cfo3/"
                },
                {
                    "id": "lx5e5ez",
                    "author": "Starkeeper2000",
                    "body": "I'm using a laptop with 4070 rtx which has 8GB vram and upgraded the ram to 64gb. it's working good with flux and sd and I can train flux Lora too without problems.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731618215.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5e5ez/"
                },
                {
                    "id": "lx5fqlt",
                    "author": "AgentTin",
                    "body": "If you're set on a laptop, have you considered an external GPU enclosure? You could have a full size dedicated 4090 sitting on your desk",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731618698.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5fqlt/"
                },
                {
                    "id": "lx5pbe2",
                    "author": "LyriWinters",
                    "body": "If you just want to generate images...  \nGet a scrap yard 4770K for nothing.  \nPut in a 3080 or a 3090 in it.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731621632.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5pbe2/"
                },
                {
                    "id": "lx7e929",
                    "author": "Botoni",
                    "body": "I use a 3070 8gb laptop and for images is fine even with flux, for video is more limited.\n\nAlso, I think that 16gb vram is the maximum you can have in a laptop, even with a 4090 mobile, unless you buy a quadro card, which are totally overpriced.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731641914.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx7e929/"
                },
                {
                    "id": "lx4mczv",
                    "author": "Specific_Virus8061",
                    "body": "My 8GB vram laptop handles 20 batches of 512x768 in 2min. So 20 1024x1024 would probably take you 4 min if you don't OOM.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731609693.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4mczv/"
                },
                {
                    "id": "lx4nvye",
                    "author": "ang_mo_uncle",
                    "body": "Basically the new models (FLUX and SD3.5) are huge. FLUX is 23.8gb as fp16, and that's without VAE and text encoders.\n\n\nWith quantization you can get the memory required down, but anything less than 16 GB ain't fun.\n\n\nThree general words of advice:\n- both Nvidia and AMD are expected to release new GPU generations mid January. So prices on older generations will drop and I'd expect more VRAM to be available.\n- laptop is not the way to go for image generation - laptop GPUs are weaker, more expensive, and thermals are bad. Get a desktop pc and if you don't feel like working on that machine you can remotely access it without issues.\n- AMD tends to give more VRAM for lower tier cards, but older GPU generations weren't that great for AI. This has somewhat changed with the 7xxx generation, so Jan might bring a pleasant surprise.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731610156.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4nvye/"
                },
                {
                    "id": "lx4u7gs",
                    "author": "Pretend_Potential",
                    "body": "if you want to use your machine for generative AI, you do not want a laptop. laptops are not designed for heavy graphics use. you want a beefy desktop with a good nvidia GPU and an intel CPU. you want at least 12 gig of VRAM on the gpu, but 16 is better. however - nvidia is expected to release their new GPUS early next year and the prices of 4090s and below will drop - so you might want to wait.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731612085.0,
                    "parent_id": "t3_1grbqkr",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4u7gs/"
                },
                {
                    "id": "lx4n0al",
                    "author": "B4N35P1R17",
                    "body": "Thanks for the input! I work on the road so I’m never at home, a laptop is an essential piece of my kit and price isn’t really a problem as most of the time it’s a work expense. Having said that I’m not against the idea of buying a home PC and using it remotely but I’ve no idea how to do that, I don’t always have a decent internet connection on the road if I’m remote and if I buy a PC the entire cost will be out of my own pocket.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731609889.0,
                    "parent_id": "t1_lx4m19g",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4n0al/"
                },
                {
                    "id": "lx57kkk",
                    "author": "B4N35P1R17",
                    "body": "So in your opinion of my situation is that I’d benefit greatly upgrading to a 16gb vram GPU machine? There’s no real need for me to go all out on a 24gb vram GPU machine as it wouldn’t be worth it for what I’m using it for? \n\nDo you happen to know how much faster 16gb will make image generation with a1111, like what’s an average time for a 1024x1024 image using a hefty model with a lot of weight?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731616199.0,
                    "parent_id": "t1_lx4xgsl",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx57kkk/"
                },
                {
                    "id": "lx56sx9",
                    "author": "B4N35P1R17",
                    "body": "As much as I’d love to do something like this, I’m not even sure what to do to accomplish that. The biggest factor for me is that I’m never home so a laptop is my primary go to device. Plus I don’t pay for my laptops, I’d have to pay for a desktop pc. The other constraint is that I’m not always able to connect to the internet or the internet available is slow and patchy sometimes for days or weeks depending where I am.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731615961.0,
                    "parent_id": "t1_lx4n53n",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx56sx9/"
                },
                {
                    "id": "lx4spx9",
                    "author": "B4N35P1R17",
                    "body": "Thank you for your reply! My only reason for the laptop over the desktop is that I am on the road for work constantly and a laptop is something I can write off as a work expense. I’m not really tech savvy so remote accessing my pc on the road isn’t something I know how to do and I’m also without an internet connection a lot of the time when I’m regional/remote.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731611632.0,
                    "parent_id": "t1_lx4pvd6",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4spx9/"
                },
                {
                    "id": "lx6abiy",
                    "author": "B4N35P1R17",
                    "body": "I hadn’t considered that but now I know it’s a thing that might be fun to experiment with. Thank you!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731628327.0,
                    "parent_id": "t1_lx5fqlt",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx6abiy/"
                },
                {
                    "id": "lx8dltj",
                    "author": "B4N35P1R17",
                    "body": "That’s good to know, thank you! What kind of image scale to time generation are we talking? Do you use large models with multiple LoRA? How does it handle that?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731658465.0,
                    "parent_id": "t1_lx7e929",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx8dltj/"
                },
                {
                    "id": "lx4naj1",
                    "author": "B4N35P1R17",
                    "body": "Are you saying on a 24gb vram GPU?",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731609975.0,
                    "parent_id": "t1_lx4mczv",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4naj1/"
                },
                {
                    "id": "lx57ubr",
                    "author": "B4N35P1R17",
                    "body": "Good to know thank you! With only a few months left in the year I may just wait to see what 2025 brings in terms of price drops in the current market.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731616283.0,
                    "parent_id": "t1_lx4u7gs",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx57ubr/"
                },
                {
                    "id": "lx5az9b",
                    "author": "Enshitification",
                    "body": "Fellow road warrior here. I have a laptop with 8gb of VRAM, but even that is a little tight. I tried the eGPU route, but desktop cards just aren't built for rough road environments. Right now, I have a 4090 at home and connect remotely. As you mentioned, we don't always have good, if any, bandwidth in remote areas. If I was buying another laptop for image diffusion today, I'd probably go with the Dream Machines RX4080-17NA35 on Newegg right now. It has a 4080 with 16GB of VRAM. The price is $2299, but that's cheap for a laptop with 16gb of VRAM.    \nEdit: It looks like the Newegg description for that laptop is mixed with the Dream Machines RX4090-17NA35. The 4080 version has 12GB VRAM. The 4090 version is $2799.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731617249.0,
                    "parent_id": "t1_lx4n0al",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5az9b/"
                },
                {
                    "id": "lx4vzit",
                    "author": "9_Taurus",
                    "body": "Get a 3090 TI (even a used one, if it's a safe buy) then you can build a monster of a PC for less than 2k if the CGU is second hand. You can buy a cheap Mac Book Air from 2019 (for the conveniency of Apple's good screens and battery, also the laptop is very thin) for a few hundred bucks. You can turn on you home PC remotely, shut it down, and use it for this kind of work without any delay with remote control. \n\nI use Parsec for that (installed on both my home PC and the Mac). Idk if it's available on Windows but you can definitely find an alternative if you want to use your old laptop. You just need to setup a Wake-on-Lan thing on your home PC (I use my Alexa speaker for that, and an ethernet cable). As the other said, you should avoid a \"high end\" laptop.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731612624.0,
                    "parent_id": "t1_lx4n0al",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4vzit/"
                },
                {
                    "id": "lx7vf97",
                    "author": "dkpc69",
                    "body": "Well the 2021 rog scar 7 and the Lenovo legion 7 rtx 3080 models are portable as they are laptops and they are cheaper than the 2024 laptop versions the 4090 is the only one with one with 16gb vram 4080 and lower only have 12gb vram! Unless portability is not a problem get a pc with either a rtx 4060ti 16gb or second hand rtx 3090 if money is no problem get a 4090 or wait for the 5090 vram is king",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731648822.0,
                    "parent_id": "t1_lx57kkk",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx7vf97/"
                },
                {
                    "id": "lx7vqu2",
                    "author": "dkpc69",
                    "body": "And yes if you’ll benefit greatly upgrading! My rog laptop does sdxl images 1024x1024 in about 10 seconds and flux dev would be roughly 40 seconds an image and the nf4 flux dev is roughly 20 seconds! Pretty good for a laptop, I could maybe change some stuff to speed it up but I’m not too cluey on all that stuff",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731648972.0,
                    "parent_id": "t1_lx57kkk",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx7vqu2/"
                },
                {
                    "id": "lx5cbop",
                    "author": "a_beautiful_rhind",
                    "body": "Can go the external GPU route. Buy a gpu and a dock for it, then connect to a compatible laptop. It will take a longer time to load but your gens will be fast.\n\nIf you're getting free devices, convincing them to get you a premium GPU version might be a tougher sell. Not to mention that mobile chips are always worse and short of vram.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731617657.0,
                    "parent_id": "t1_lx56sx9",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5cbop/"
                },
                {
                    "id": "lx4svks",
                    "author": "DemoEvolved",
                    "body": "Best wishes",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731611681.0,
                    "parent_id": "t1_lx4spx9",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4svks/"
                },
                {
                    "id": "lx54u5j",
                    "author": "Raidan_187",
                    "body": "Everyone that says desktop over laptop is an elitist in my opinion. I have a 4090 16GB vram for £2500 / $3100, i9 Ada chip with 24 cores - it’s smooth as butter. Lora training takes a little longer but I’m really happy with how fast it is for a batch of images using control nets and loras at 1024 x 1024 on large sxdl models. I knew it would be slower than a desktop on some tasks but I needed the portability so I’m super happy.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731615356.0,
                    "parent_id": "t1_lx4spx9",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx54u5j/"
                },
                {
                    "id": "lxdhucd",
                    "author": "Botoni",
                    "body": "With flux dev fp16, a 1024x1024 image, 5.77s/it. With the flux dev nf4 model 2.99s/it. That's with comfyui. Forge might be equal or slightly faster, a1111 would be much slower.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731725860.0,
                    "parent_id": "t1_lx8dltj",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lxdhucd/"
                },
                {
                    "id": "lx4udra",
                    "author": "Specific_Virus8061",
                    "body": "No, I'm too poor for a 24GB vram laptop. 8GB is where most mid-range ($1000-1500) gaming laptops are priced at.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731612139.0,
                    "parent_id": "t1_lx4naj1",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx4udra/"
                },
                {
                    "id": "lx6csmk",
                    "author": "B4N35P1R17",
                    "body": "Nice one, thank you! I can literally just send my office the bill for a blown out rtx 4090 24gb vram gpu laptop and they will pay it. If I say I need it for work they won’t even question it. \n\nHaving said that though I’m gonna have a look into the eGPU as well, as  it’s been said, desktop GPUs are definitely better than their laptop equipment. I just need to do a little digging on which laptops are compatible and how I go about setting it up.\n\nI can pack it all away safely until I get to my destination and then I’m usually settled in until the jobs done so it won’t be in a position to get damaged.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731629146.0,
                    "parent_id": "t1_lx5az9b",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx6csmk/"
                },
                {
                    "id": "lx5pswe",
                    "author": "LyriWinters",
                    "body": "Thought the 4090 was 24gb vram :)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731621781.0,
                    "parent_id": "t1_lx54u5j",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5pswe/"
                },
                {
                    "id": "lx58pn5",
                    "author": "B4N35P1R17",
                    "body": "That’s good to know. I’m mainly looking for speed. Honestly I just use it like a toy, I’m not interested in doing ultra high end mega scale images, I just love mucking around and having fun. The problem I have is that with even the most basic and rudimentary image generation taking 1- 2 minutes on the fastest settings and 5-10 minutes when I’m using better settings and bigger models, I’m very limited to how much I can do in a short space of time which limits my exploration of SD and all it’s facets. If I could generate simple yet quality images *fast* I’d be able to play around way more with prompting and scale etc.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731616553.0,
                    "parent_id": "t1_lx54u5j",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx58pn5/"
                },
                {
                    "id": "lx593t1",
                    "author": "B4N35P1R17",
                    "body": "Oh so which GPU are you saying will do 20 1024x1024 images in 4 minutes? Cause that would be a dream!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731616674.0,
                    "parent_id": "t1_lx4udra",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx593t1/"
                },
                {
                    "id": "lx6e5p6",
                    "author": "Enshitification",
                    "body": "I had my eGPU shock-mounted pretty well. The problem in my case was that while I could attenuate most of the constant frequency vibrations, the hard jolts would loosen the card. Your vehicle might be a smoother ride than mine though. The other issue is the Thunderbolt connector. It's kind of delicate and daily insertion/removal cycles tends to wear it out faster than a regular USB-C. Still, while it did work, it worked quite well. I think ASUS is still selling a 4090 in an eGPU case for about $2000. It's almost like getting the enclosed eGPU case for free with the card. Since you aren't traveling daily, it might be the best option.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731629604.0,
                    "parent_id": "t1_lx6csmk",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx6e5p6/"
                },
                {
                    "id": "lx5hhqt",
                    "author": "maciejhd",
                    "body": "If you are using some turbo/lighting (4-8 steps) models then you can get such images even faster on rtx 3090. It should take about 2-4 seconds per image.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731619233.0,
                    "parent_id": "t1_lx593t1",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx5hhqt/"
                },
                {
                    "id": "lx8dy1l",
                    "author": "B4N35P1R17",
                    "body": "Interesting. I’ll do some more reading on that. It definitely sounds like it might be a viable option",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731658669.0,
                    "parent_id": "t1_lx6e5p6",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx8dy1l/"
                },
                {
                    "id": "lx6bh8e",
                    "author": "B4N35P1R17",
                    "body": "Thank you, that sounds promising! Can you suggest some turbo/lightning (4-8 step) models? I’d be interested in giving them a crack in my potato to see how it handles them. As I said in my post, I try my best to stick to tiny models and mostly anime themed stuff only because they typically have much fatter generation times. I’d love to branch into photo realistic stuff but it can take 45-60 minutes for a single small scale low weight image to generate",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731628708.0,
                    "parent_id": "t1_lx5hhqt",
                    "link_id": "t3_1grbqkr",
                    "permalink": "/r/StableDiffusion/comments/1grbqkr/im_thinking_of_upgrading_from_a_7_year_old_2gb/lx6bh8e/"
                }
            ]
        },
        {
            "id": "1grblto",
            "title": "TripoSR input",
            "author": "hrrlvitta",
            "score": 2,
            "upvotes": 2,
            "downvotes": 0,
            "num_comments": 7,
            "created_utc": 1731608978.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grblto/triposr_input/",
            "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/",
            "selftext": "Hi, does it only take 512x512px image?  \nAlso can anyone suggest a way to make the model much simlper and less polygons? \n\nSo far it creates way too much polygons and it's very hard and complicated to clean up in Blender.\n\nthanks!",
            "comments": [
                {
                    "id": "lx5ozul",
                    "author": "dasomen",
                    "body": "have you tried Stable Zero123 ? https://comfyanonymous.github.io/ComfyUI_examples/3d/",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731621534.0,
                    "parent_id": "t3_1grblto",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx5ozul/"
                },
                {
                    "id": "lx69gxf",
                    "author": "Most_Way_9754",
                    "body": "Adding this to the list of suggestions:\n\nhttps://github.com/Tencent/Hunyuan3D-1\n\nReddit users tested to work on 24gb GPUs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731628045.0,
                    "parent_id": "t3_1grblto",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx69gxf/"
                },
                {
                    "id": "lx5pxf0",
                    "author": "hrrlvitta",
                    "body": "This is interesting. I will definitely try it out.\n\nJust for my goal I would like to have an actually 3D model for me to manipulate materials in blender or even export it for 3D print.\n\nMaybe this can help to generate 4 sides of the image and get a better model using tripoSR?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731621820.0,
                    "parent_id": "t1_lx5ozul",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx5pxf0/"
                },
                {
                    "id": "lx6pdtz",
                    "author": "hrrlvitta",
                    "body": "thanks, but i noticed that, even I have installed Comfy3D, lots of the nodes used in these workflows are missing. can anyone advice pls?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731633384.0,
                    "parent_id": "t1_lx69gxf",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx6pdtz/"
                },
                {
                    "id": "lx5qyoo",
                    "author": "dasomen",
                    "body": "Give this one a try online, it's the latest from Stability.ai\n\nhttps://huggingface.co/spaces/stabilityai/stable-fast-3d",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731622136.0,
                    "parent_id": "t1_lx5pxf0",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx5qyoo/"
                },
                {
                    "id": "lx6pw74",
                    "author": "Most_Way_9754",
                    "body": "Use manager to check for missing nodes?\n\nIs the 3d pack dependencies installed properly and the package loading on start-up?\n\nIf you're on windows, you can get the pre built dependencies from here:\n\nhttps://github.com/MrForExample/Comfy3D_Pre_Builds",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731633560.0,
                    "parent_id": "t1_lx6pdtz",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx6pw74/"
                },
                {
                    "id": "lx5rwwc",
                    "author": "hrrlvitta",
                    "body": "Thanks, I was trying it yesterday, but it keeps giving me an error. But I figured it might be some bad nodes conflicting as I have had problems with other models and generation too. And fixed after I removed Mixlab.\n\n\nWill give this one a go again. Cheers.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731622432.0,
                    "parent_id": "t1_lx5qyoo",
                    "link_id": "t3_1grblto",
                    "permalink": "/r/StableDiffusion/comments/1grblto/triposr_input/lx5rwwc/"
                }
            ]
        },
        {
            "id": "1grayjy",
            "title": "Laptop recommendations ",
            "author": "Z3r0_Code",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 26,
            "created_utc": 1731607358.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1grayjy/laptop_recommendations/",
            "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/",
            "selftext": "I want to buy a laptop on which I can find tune sd models and create loras as well as use flux to a reasonable rate.\nBudget is arround 1800 usd.\nPlease help me find one.",
            "comments": [
                {
                    "id": "lx4omao",
                    "author": "Enshitification",
                    "body": "The cheapest 4080 laptop I know of is the Dream Machines RX4080-17NA35 on Newegg right now. It has a 4080 with 16GB of VRAM and I'm a bit astounded the price is only $2299. I would get it today if I needed another laptop. That will do what you are asking for.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731610378.0,
                    "parent_id": "t3_1grayjy",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4omao/"
                },
                {
                    "id": "lx4xvhd",
                    "author": "DariusZahir",
                    "body": "get a desktop pc and any laptop, use the laptop to connect remotely to the desktop pc?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731613208.0,
                    "parent_id": "t3_1grayjy",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4xvhd/"
                },
                {
                    "id": "lxcsgbh",
                    "author": "artificial_genius",
                    "body": "For training you will want a used 3090 (800$) and any motherboard/CPU combo. It won't happen on a laptop. Could get away with a 12gb card too but you know less space. Could also just rent runpod/mass compute for way cheaper 20c an hour for 3090) and use any bad laptop with that or do the 3090 idea headless and have a cheap laptop that you ssh into the PC with and control it. Lots of ways around it. Don't spend big bucks on a laptop though.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731716047.0,
                    "parent_id": "t3_1grayjy",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lxcsgbh/"
                },
                {
                    "id": "lx61yk1",
                    "author": "SmokinTuna",
                    "body": "You can't on a laptop. Trust me. Spend the money on a very strong desktop and then remotely access it.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731625585.0,
                    "parent_id": "t3_1grayjy",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx61yk1/"
                },
                {
                    "id": "lx4jhw5",
                    "author": "Pretend_Potential",
                    "body": "you won't be doing that on a laptop, sorry to break the news to you. you want a desktop, it needs a beefy nvidia gpu and an intel cpu",
                    "score": -4,
                    "upvotes": -4,
                    "downvotes": 0,
                    "created_utc": 1731608824.0,
                    "parent_id": "t3_1grayjy",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4jhw5/"
                },
                {
                    "id": "lx5ykil",
                    "author": "shtorm2005",
                    "body": "That Laptop has wrong description. 4080 mobile has 12 GB VRAM.\n\nBtw mobile 4080 is equal to desktop 3070.\n\nThat's weak what you get for 2300$",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731624506.0,
                    "parent_id": "t1_lx4omao",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx5ykil/"
                },
                {
                    "id": "lx4uf1f",
                    "author": "Pretend_Potential",
                    "body": "newegg has better desktops for cheaper though. laptops are always going to be a lot more expensive than a desktop jsut because they are portable",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731612149.0,
                    "parent_id": "t1_lx4omao",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4uf1f/"
                },
                {
                    "id": "lx74uys",
                    "author": "PappaBear-905",
                    "body": "The GPUs in laptops have the same cores as the desktop chips but they are so limited by the thermal dissipation I think their clock speeds are very crippled. \n\nHave you looked into the portable GPUs like the Asus ROG XG 4090? It's actually cheaper than a desktop 4090 and it comes with its own power supply. I don't have any experience with it to know how well it works with AI applications though.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731638628.0,
                    "parent_id": "t1_lx4omao",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx74uys/"
                },
                {
                    "id": "lx4y8xv",
                    "author": "Z3r0_Code",
                    "body": "Normal people have a budget to keep in mind 😞.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731613323.0,
                    "parent_id": "t1_lx4xvhd",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4y8xv/"
                },
                {
                    "id": "lx56b2e",
                    "author": "acedelgado",
                    "body": "Intel cpu? 🤨\n\n\nCpu's don't matter that much with SD style models. And Intel's been screwing up a lot lately with all the damaged 13/14 series chips they wont warranty. I'd avoid them for another year or two and see if there's any long term issues with their newer core ultras. Ryzen with an Nvidia GPU is the way to go at the moment.",
                    "score": 4,
                    "upvotes": 4,
                    "downvotes": 0,
                    "created_utc": 1731615809.0,
                    "parent_id": "t1_lx4jhw5",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx56b2e/"
                },
                {
                    "id": "lx62mxj",
                    "author": "Enshitification",
                    "body": "I think you're right. The product description on Newegg lists it as both a 4080 and a 4090 with 16GB VRAM. It looks like they mixed up the description with the Dream Machines RX4090-17NA35 hwich has a 4090 with 16GB VRAM. It's priced at $2799, which is still pretty good for a 4090 laptop.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731625805.0,
                    "parent_id": "t1_lx5ykil",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx62mxj/"
                },
                {
                    "id": "lx4v0zx",
                    "author": "Z3r0_Code",
                    "body": "So if I were to spend 1800 it is better to build a pc than get a laptop.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731612334.0,
                    "parent_id": "t1_lx4uf1f",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4v0zx/"
                },
                {
                    "id": "lx4w46t",
                    "author": "Enshitification",
                    "body": "OP is asking for a laptop that can do what they are asking, not a desktop. Not everyone has the luxury of working from home.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731612664.0,
                    "parent_id": "t1_lx4uf1f",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4w46t/"
                },
                {
                    "id": "lx78irt",
                    "author": "Enshitification",
                    "body": "That particular eGPU is pretty much a laptop board in an external case. It might perform a little better than the same in a laptop because the better heat dissipation, but it is still limited by the 16GB VRAM. I figure if someone is going to go with an eGPU, might as well get a desktop card.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731639896.0,
                    "parent_id": "t1_lx74uys",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx78irt/"
                },
                {
                    "id": "lx87ro7",
                    "author": "OniNoOdori",
                    "body": "\\>The GPUs in laptops have the same cores as the desktop chips\n\nActually, they don't, at least not in the way you'd expect. For instance, the mobile 4090 actually uses the same architecture as the desktop 4080 and performs closer to a 4070.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731655147.0,
                    "parent_id": "t1_lx74uys",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx87ro7/"
                },
                {
                    "id": "lx75omo",
                    "author": "IamTotallyWorking",
                    "body": "I don't know much about computers, but I'm guessing a 1500 desktop and a 300 laptop will suit your needs better than a 1800 laptop.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731638910.0,
                    "parent_id": "t1_lx4y8xv",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx75omo/"
                },
                {
                    "id": "lx5dr83",
                    "author": "Pretend_Potential",
                    "body": "yes intel. because AMD loves to try to take over and try to do the GPU's job. so it's a battle that's avoided by just using an intel cpu",
                    "score": -3,
                    "upvotes": -3,
                    "downvotes": 0,
                    "created_utc": 1731618091.0,
                    "parent_id": "t1_lx56b2e",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx5dr83/"
                },
                {
                    "id": "lx4wcd1",
                    "author": "Enshitification",
                    "body": "Definitely. You will get more bang for the buck with a desktop if you don't absolutely need the portability of a laptop.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731612734.0,
                    "parent_id": "t1_lx4v0zx",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4wcd1/"
                },
                {
                    "id": "lx4xhkw",
                    "author": "Pretend_Potential",
                    "body": "and not everyone realizes that a laptop just can't do everything. they're in the mindset of laptop is the only computer that exists. it doesn't hurt at all to tell them what they need isn't a laptop.\n\nmuch you be argumentative every time you post?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731613089.0,
                    "parent_id": "t1_lx4w46t",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4xhkw/"
                },
                {
                    "id": "lx7pakm",
                    "author": "Z3r0_Code",
                    "body": "So what cpu and GPU would you recommend if a put the 1800 in a pc.",
                    "score": 3,
                    "upvotes": 3,
                    "downvotes": 0,
                    "created_utc": 1731646099.0,
                    "parent_id": "t1_lx75omo",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx7pakm/"
                },
                {
                    "id": "lx5ixds",
                    "author": "acedelgado",
                    "body": "Haven't had that happen one time on my 7950x. Just never install the Adrenaline drivers for the iGPU and it's a non issue.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731619671.0,
                    "parent_id": "t1_lx5dr83",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx5ixds/"
                },
                {
                    "id": "lxcg893",
                    "author": "bridge1999",
                    "body": "You have a messed up configuration that is trying to use both GPUs",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731711620.0,
                    "parent_id": "t1_lx5dr83",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lxcg893/"
                },
                {
                    "id": "lx4xpc8",
                    "author": "Enshitification",
                    "body": "Must you delete posts that don't actually go against the rules?",
                    "score": -1,
                    "upvotes": -1,
                    "downvotes": 0,
                    "created_utc": 1731613155.0,
                    "parent_id": "t1_lx4xhkw",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx4xpc8/"
                },
                {
                    "id": "lx7rk3v",
                    "author": "IamTotallyWorking",
                    "body": "Honestly, no clue. Like I said, I don't really know anything. But, I am considering buying a computer to do AI photos locally. If I do, I'm going to buy from Newegg, and just buy the cheapest set up after sorting by a decent CPU, and then the biggest VRAM Nvidia I can find in my price range. \n\nThat said, I'm probably going to stick with cheap hardware, and just pay for API use. Everything is advancing so rapidly that I don't want to bother having to keep my hardware up to date. For my needs, it's probably better to end up paying a little more in the long run but be able to just use someone else's processing power. Especially since that valuation assumes that I'm doing everything right. I just need one time of buying the wrong video card and then it is way cheaper to just go the API route. \n\nBut again, I really don't know what I'm talking about.",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731647068.0,
                    "parent_id": "t1_lx7pakm",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx7rk3v/"
                },
                {
                    "id": "lxcglek",
                    "author": "Pretend_Potential",
                    "body": "AMD comes with integrated GPU and people normally just install the drivers that turn it on. and when that happens, then it does the GPUs job rather than just being the CPU. and since cpu doesn't matter nearly as much as GPU for this sort of work, it's recommended to go with intel not amd",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731711750.0,
                    "parent_id": "t1_lxcg893",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lxcglek/"
                },
                {
                    "id": "lx7zwxj",
                    "author": "Z3r0_Code",
                    "body": "Okh, any suggestions for any online platforms to use for model and lora training or just generating images.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731650995.0,
                    "parent_id": "t1_lx7rk3v",
                    "link_id": "t3_1grayjy",
                    "permalink": "/r/StableDiffusion/comments/1grayjy/laptop_recommendations/lx7zwxj/"
                }
            ]
        },
        {
            "id": "1gr970t",
            "title": "Looking for best image to video model for 24GB Vram.",
            "author": "Suimeileo",
            "score": 5,
            "upvotes": 5,
            "downvotes": 0,
            "num_comments": 8,
            "created_utc": 1731602959.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/",
            "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/",
            "selftext": "Title.\n\nThere's been quite a few releases in the past month. I just installed Comfy UI as other UIs seems to be lacking in this department. SO I wanna know which is best for image to video.\n\nplease share workflow/model link and such, I'm unfamiliar with the players in this field so no clue where to find them etc..\n\nLast I tried was stable diffusion video. So anything better then that for 3090.",
            "comments": [
                {
                    "id": "lx424ea",
                    "author": "NoIntention4050",
                    "body": "Wait a few more days for CogVideoX1.5 I2V. In the meantime, you have EasyAnimateV5 and CogVideoX5B I2V, they quality is similar",
                    "score": 12,
                    "upvotes": 12,
                    "downvotes": 0,
                    "created_utc": 1731603545.0,
                    "parent_id": "t3_1gr970t",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx424ea/"
                },
                {
                    "id": "lx6cu8g",
                    "author": "aesethtics",
                    "body": "Like NoIntention said, CogVideoX1.5 for Comfy* is likely to land soon.\n\nTry CogVideoXWrapper nodes and get familiar with KJNodes etc until then\n\nhttps://github.com/kijai/ComfyUI-CogVideoXWrapper\n\n(*thanks for all your efforts and thanks in advance Kijai!)",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731629161.0,
                    "parent_id": "t3_1gr970t",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx6cu8g/"
                },
                {
                    "id": "lx4z7c8",
                    "author": "niksat_99",
                    "body": "Mochi is also good",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731613616.0,
                    "parent_id": "t1_lx424ea",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx4z7c8/"
                },
                {
                    "id": "lx4z99a",
                    "author": "NoIntention4050",
                    "body": "he said image to video",
                    "score": 5,
                    "upvotes": 5,
                    "downvotes": 0,
                    "created_utc": 1731613632.0,
                    "parent_id": "t1_lx4z7c8",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx4z99a/"
                },
                {
                    "id": "lx4zq1t",
                    "author": "niksat_99",
                    "body": "my bad 😔",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731613774.0,
                    "parent_id": "t1_lx4z99a",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx4zq1t/"
                },
                {
                    "id": "lx573f1",
                    "author": "Ken-g6",
                    "body": "Mochi can do image-to-video.  Not sure it's that great, though. [https://www.reddit.com/r/StableDiffusion/comments/1gmn2og/rudimentary\\_imagetovideo\\_with\\_mochi\\_on\\_3060\\_12gb/](https://www.reddit.com/r/StableDiffusion/comments/1gmn2og/rudimentary_imagetovideo_with_mochi_on_3060_12gb/)",
                    "score": -2,
                    "upvotes": -2,
                    "downvotes": 0,
                    "created_utc": 1731616051.0,
                    "parent_id": "t1_lx4z99a",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx573f1/"
                },
                {
                    "id": "lx577f3",
                    "author": "NoIntention4050",
                    "body": "that's not image to video. it will come, but that's not it",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731616086.0,
                    "parent_id": "t1_lx573f1",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx577f3/"
                },
                {
                    "id": "lx6bwc8",
                    "author": "aesethtics",
                    "body": "At this time, Mochi needs a lot of denoising to add motion… too much to be considered image2video, as we know it. It’s basically text2video with extra steps. Fun results though!",
                    "score": 0,
                    "upvotes": 0,
                    "downvotes": 0,
                    "created_utc": 1731628846.0,
                    "parent_id": "t1_lx573f1",
                    "link_id": "t3_1gr970t",
                    "permalink": "/r/StableDiffusion/comments/1gr970t/looking_for_best_image_to_video_model_for_24gb/lx6bwc8/"
                }
            ]
        },
        {
            "id": "1gr83kx",
            "title": "Best PC for photo and video editing with lots of storage and working memory?",
            "author": "Cheetah259",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731600144.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr83kx/best_pc_for_photo_and_video_editing_with_lots_of/",
            "permalink": "/r/StableDiffusion/comments/1gr83kx/best_pc_for_photo_and_video_editing_with_lots_of/",
            "selftext": "Hello out there,\n\nFinally have some money (let's say up to 3K for now) to afford something good, and sick and tired of cheap PCs that can't handle photo and video editing.  Can folks recommend the best system for these things?  I'm trying to avoid sending all of my media to cloud drives and external AIs, but is an external AI the only way to quickly enhance videos of up to ten minutes or more?  Right now it seems that way but I'm not up to date on the latest.  The one time I did a free trial online (HitPaw video enhancer), it was going to take a godawful amount of time (like 16 hours or something) to enhance a 1 minute video. Then there's the storage needs for a lifetime of photos and videos...also sick of multiple external drives and figure I need a 4 TB SSD most likely.  Any systems out there that cover all of this without having to build my own?",
            "comments": [
                {
                    "id": "lx882mh",
                    "author": "Big-Note-508",
                    "body": "check out r/pcmasterrace and r/buildapc",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731655316.0,
                    "parent_id": "t3_1gr83kx",
                    "link_id": "t3_1gr83kx",
                    "permalink": "/r/StableDiffusion/comments/1gr83kx/best_pc_for_photo_and_video_editing_with_lots_of/lx882mh/"
                }
            ]
        },
        {
            "id": "1gr1010",
            "title": "How do I learn to train cogvideo's lora",
            "author": "IamGGbond",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 0,
            "created_utc": 1731576062.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr1010/how_do_i_learn_to_train_cogvideos_lora/",
            "permalink": "/r/StableDiffusion/comments/1gr1010/how_do_i_learn_to_train_cogvideos_lora/",
            "selftext": "Is there any platform that can support me to train Cogvideo's Lora online? My computer is too weak",
            "comments": []
        },
        {
            "id": "1gr7y1j",
            "title": "setting up ComfyUI with and online gpu, renting a gpu",
            "author": "HeightSensitive1845",
            "score": 3,
            "upvotes": 3,
            "downvotes": 0,
            "num_comments": 7,
            "created_utc": 1731599744.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/",
            "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/",
            "selftext": "how do i get ComfyUI to run on some kind of service online with affordable GPU rentals. Any suggestions are very appreciated!",
            "comments": [
                {
                    "id": "lx4dg6i",
                    "author": "Pretend_Potential",
                    "body": "you could use this one [https://comfyuiweb.com/](https://comfyuiweb.com/)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731606992.0,
                    "parent_id": "t3_1gr7y1j",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4dg6i/"
                },
                {
                    "id": "lx4ouaz",
                    "author": "Apprehensive_Sky892",
                    "body": "You can run ComfyUI on tensor. art\n\nThis is probably the cheapest option ($60/year, 300 credits per day for about 150 Flux images at 25 steps)\n\nThe limitation is that you cannot install your own custom node, you must use whatever nodes that have been provided and request any missing ones.\n\nYou can upload your own models.",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731610445.0,
                    "parent_id": "t3_1gr7y1j",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4ouaz/"
                },
                {
                    "id": "lxdjqep",
                    "author": "Major_Defect_0",
                    "body": "check out vast.ai they have some ComfyUI templates",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731726610.0,
                    "parent_id": "t3_1gr7y1j",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lxdjqep/"
                },
                {
                    "id": "lx4rfgd",
                    "author": "HeightSensitive1845",
                    "body": "i wanna make some image to video using CogVideoX my gpu is garbage 3070 rtx, will it let me run CogvideoX models?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731611234.0,
                    "parent_id": "t1_lx4dg6i",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4rfgd/"
                },
                {
                    "id": "lx4ry12",
                    "author": "HeightSensitive1845",
                    "body": "So i can't use Image to video?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731611394.0,
                    "parent_id": "t1_lx4ouaz",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4ry12/"
                },
                {
                    "id": "lx4thzv",
                    "author": "Pretend_Potential",
                    "body": "cogvideo runs in comfy, there's a node for it - but you might have to get hold of the site owners and get them to put that node in. otherwise, there's always [vast.ai](http://vast.ai)",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731611871.0,
                    "parent_id": "t1_lx4rfgd",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4thzv/"
                },
                {
                    "id": "lx4u7le",
                    "author": "HeightSensitive1845",
                    "body": "Will have to do a research on how to set it up then. Thank you so much",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731612087.0,
                    "parent_id": "t1_lx4thzv",
                    "link_id": "t3_1gr7y1j",
                    "permalink": "/r/StableDiffusion/comments/1gr7y1j/setting_up_comfyui_with_and_online_gpu_renting_a/lx4u7le/"
                }
            ]
        },
        {
            "id": "1gr6vxz",
            "title": "Confusion about LoRa and Kohya_ss training dynamics",
            "author": "palmuvehka",
            "score": 1,
            "upvotes": 1,
            "downvotes": 0,
            "num_comments": 9,
            "created_utc": 1731596992.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/",
            "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/",
            "selftext": "Hey,\n\nI am trying to train a custom character LoRa on Kohya\\_ss platform with sdxl-base-1.0 as base model. I have a hard time understanding the batch sizes in this image. Why is the `num batches per epoch` double the `num train images * repeats` ? Shouldn't the `num batches per epoch` be the same as `num train images * repeats` if I am using a batch size of 1 and no gradient accumulation? Running single GPU and otherwise default settings. \n\nhttps://preview.redd.it/1vgzbvoitv0e1.png?width=571&format=png&auto=webp&s=1748da02396bf398d6154c071b1bf8b66b526935\n\n",
            "comments": [
                {
                    "id": "lx3wcy5",
                    "author": "Dezordan",
                    "body": "Weird, why would it double to begin with? If you were using a higher batch size, it would've dived it instead (not sure about gradient accumulation).\n\nAfter some reading, I came across information ([here](https://github.com/kohya-ss/sd-scripts/issues/366)) by kohya that \"Yes, the reg images are repeated until the number of the training images, to balance the numbers\" - I think it is a required thing for reg images. Seems like that's the answer.\n\n  \nBy the way, isn't that a lot of images, and reg images on top of it, for just a character LoRA? It migh not even train all that good.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731601779.0,
                    "parent_id": "t3_1gr6vxz",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx3wcy5/"
                },
                {
                    "id": "lx4ecc3",
                    "author": "No-Educator-249",
                    "body": "Your number of steps are too high. How many source images do you have in your dataset?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731607260.0,
                    "parent_id": "t3_1gr6vxz",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx4ecc3/"
                },
                {
                    "id": "lx4f819",
                    "author": "palmuvehka",
                    "body": "Thanks for the answer, that seems to be the reason. And yeah I had 40 repeats of 67 training images, which is probably too much. Training for single epoch took way too much time. I am now running 10 repeats with the same datasets. It's my first time training so we'll see how it turns out. \n\nI thought having a lot of training images is better in general, to make the model generalize better and avoid overfitting. I want the LoRa to be able to handle different outfits, poses and environments.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731607527.0,
                    "parent_id": "t1_lx3wcy5",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx4f819/"
                },
                {
                    "id": "lx4jggc",
                    "author": "palmuvehka",
                    "body": "What do you mean by source images? I have 67 training images of the subject (the person I am trying to create the LoRa for) and 501 regularization images. Thanks.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731608812.0,
                    "parent_id": "t1_lx4ecc3",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx4jggc/"
                },
                {
                    "id": "lx4jt9u",
                    "author": "Dezordan",
                    "body": "While it is true that a high amount of images can make it generalize better, it can also make it not learn at all - depends on dataset. Your case is bit different, you have a lot of repeats of repeats - it may actually learn all you need in 1 epoch, perhaps even overfit. For LoRA character something around 20 would be enough, but 67 is a good amount too.\n\nTo put it in perspective, when I trained multiple characters in one LoRA (more than 10, each had around 50 images) - I balanced it out in a way that it resulted in around 1000 batches per epoch, while yours is 5360 for 1 character.\n\n  \nIf AI knows the concept, you don't really need reg images.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731608919.0,
                    "parent_id": "t1_lx4f819",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx4jt9u/"
                },
                {
                    "id": "lx502c3",
                    "author": "spacepxl",
                    "body": "Repeats are only needed if you're training multiple concepts with different numbers of images and you want to balance them out. Otherwise there is no difference between 10 repeats * 10 epochs vs 1 repeat * 100 epochs. Repeats do not actually increase the number of images in your training dataset.\n\nAnd don't listen to people who say X number of images is too many. A few good images is better than many bad images, but many good images will always be better than few good images. A lora trained on 200 images for 5 epochs will be more flexible and generalize better than one trained on 20 images for 50 epochs.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731613879.0,
                    "parent_id": "t1_lx4f819",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx502c3/"
                },
                {
                    "id": "lx5zw81",
                    "author": "No-Educator-249",
                    "body": "It's the training images. 67 pictures should be enough. Try using the settings I suggested and see how your training run goes. \n\n\nI also recently trained a person in SDXL. I found the best results by using a single tag in the captions. Just make sure it's not a single word. It's not strictly necessary to use 'ohwx' or whatever. I personally use the name of the person and a number, for example: 'Jane1'. \n\n\nKeep us posted on your results. And post your full training settings too so we can compare results.",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731624923.0,
                    "parent_id": "t1_lx4jggc",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx5zw81/"
                },
                {
                    "id": "lx4lxr6",
                    "author": "palmuvehka",
                    "body": "Interesting, thanks for the insight. Generally I would think that having a bigger dataset with less variance image-to-image would be better than a smaller dataset with high variance between images, but then again I am completely new to diffusion models and LoRas. Do you know any good papers/other resources about LoRas and finetuning diffusion models?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731609563.0,
                    "parent_id": "t1_lx4jt9u",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx4lxr6/"
                },
                {
                    "id": "lx8pejo",
                    "author": "Dezordan",
                    "body": "When I was beginning, I read this one: [https://rentry.org/59xed3](https://rentry.org/59xed3) \\- although the amount of images bit is detived from my experience and some other articles.  \nBut it's pretty old now (not that many things has changed. Also, OneTrainer's wiki can be beneficial too: [https://github.com/Nerogar/OneTrainer/wiki](https://github.com/Nerogar/OneTrainer/wiki)",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731665682.0,
                    "parent_id": "t1_lx4lxr6",
                    "link_id": "t3_1gr6vxz",
                    "permalink": "/r/StableDiffusion/comments/1gr6vxz/confusion_about_lora_and_kohya_ss_training/lx8pejo/"
                }
            ]
        },
        {
            "id": "1gr6uzm",
            "title": "ı can't find this node anyone help ??",
            "author": "StydArc",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 1,
            "created_utc": 1731596919.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr6uzm/ı_cant_find_this_node_anyone_help/",
            "permalink": "/r/StableDiffusion/comments/1gr6uzm/ı_cant_find_this_node_anyone_help/",
            "selftext": "https://preview.redd.it/shhy2z5kuv0e1.png?width=1654&format=png&auto=webp&s=40b529dbe81a1ea279b1a8faf1303479ba9bd8ae\n\n",
            "comments": [
                {
                    "id": "lx3rj3c",
                    "author": "Pretend_Potential",
                    "body": "double left click on an empty spot on your comfy desktop and type in clip. search through the list. That's just an encoder node. you should have several different ones. Where did you get this workflow?",
                    "score": 2,
                    "upvotes": 2,
                    "downvotes": 0,
                    "created_utc": 1731600266.0,
                    "parent_id": "t3_1gr6uzm",
                    "link_id": "t3_1gr6uzm",
                    "permalink": "/r/StableDiffusion/comments/1gr6uzm/ı_cant_find_this_node_anyone_help/lx3rj3c/"
                }
            ]
        },
        {
            "id": "1gr6snd",
            "title": "Flux-webui in Pinokio out of memory error",
            "author": "IcyMind2993",
            "score": 0,
            "upvotes": 0,
            "downvotes": 0,
            "num_comments": 8,
            "created_utc": 1731596740.0,
            "url": "https://www.reddit.com/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/",
            "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/",
            "selftext": "Whenever i try to generate an image it gives this error:  \ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 18.43 GiB is allocated by PyTorch, and 266.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH\\_CUDA\\_ALLOC\\_CONF=expandable\\_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
            "comments": [
                {
                    "id": "lx3p504",
                    "author": "omg_can_you_not",
                    "body": "You're better off installing Forge and downloading the NF4 version of flux",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731599514.0,
                    "parent_id": "t3_1gr6snd",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3p504/"
                },
                {
                    "id": "lx3svfm",
                    "author": "Available-Body-9719",
                    "body": "you have 12 gb of vram and the model needs 20gb",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600689.0,
                    "parent_id": "t3_1gr6snd",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3svfm/"
                },
                {
                    "id": "lx3qoxy",
                    "author": "IcyMind2993",
                    "body": "I am currently installing forge but why does it give that error?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600001.0,
                    "parent_id": "t1_lx3p504",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3qoxy/"
                },
                {
                    "id": "lx3rx3l",
                    "author": "IcyMind2993",
                    "body": "and which model is the best for high quality?",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600389.0,
                    "parent_id": "t1_lx3qoxy",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3rx3l/"
                },
                {
                    "id": "lx3tgsl",
                    "author": "Available-Body-9719",
                    "body": "It gives you that error because the model needs 20 GB free of Vram and you only have 12 in total, Pinokio comes with that 16-bit version of Flux and it cannot be changed, that's why they ask you to install another program where it can be changed for one quantized version of the flux model, which occupies less vram",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600877.0,
                    "parent_id": "t1_lx3qoxy",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3tgsl/"
                },
                {
                    "id": "lx3svzd",
                    "author": "omg_can_you_not",
                    "body": "I'm not very smart but it appears like it's trying to load the entire 18gb model into your VRAM instead of splitting some of it with your normal ram. I just use the normal Flux dev NF4 model here: https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/tree/main \n\nShould fit into your 12gb vram with no issue",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600695.0,
                    "parent_id": "t1_lx3rx3l",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3svzd/"
                },
                {
                    "id": "lx3zwai",
                    "author": "IcyMind2993",
                    "body": "Oh okay, thank you!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731602869.0,
                    "parent_id": "t1_lx3tgsl",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3zwai/"
                },
                {
                    "id": "lx3t8co",
                    "author": "IcyMind2993",
                    "body": "Alright, thanks for the information!",
                    "score": 1,
                    "upvotes": 1,
                    "downvotes": 0,
                    "created_utc": 1731600802.0,
                    "parent_id": "t1_lx3svzd",
                    "link_id": "t3_1gr6snd",
                    "permalink": "/r/StableDiffusion/comments/1gr6snd/fluxwebui_in_pinokio_out_of_memory_error/lx3t8co/"
                }
            ]
        }
    ]
}